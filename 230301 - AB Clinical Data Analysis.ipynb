{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulbempu/ApneBoot-Clinical-Data-Analysis/blob/main/230301%20-%20AB%20Clinical%20Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-07-23 - I updated it so it loads logs and creates df_s and df_d faster. Also includes Log Source File. Works for Zug, need to check for nonin. \n",
        "Actual and Preset are slightly different because:\n",
        "- Preset mode number shows up at the start of the apnea, Stim shows at start of stim +1 (instead of 5s it looks like 6 sec+1. This may be a rounding issue. Would be nice if they were on the same line but ok. \n",
        "- This rounding issue may also cause different apnea stimulation lengths by a second or two.\n",
        "\n",
        "\n",
        "22-09-03 - \n",
        "- Added code to convert table to pdf\n",
        "\n",
        "22-09-10 -\n",
        "- Fix Smoothing Issue\n",
        "- Add Thresholds \n",
        "\n",
        "22-19-18\n",
        "Todo:\n",
        "- X make individual plots ouput to pdf\n",
        "- X - Good Enough - make summary table cleaner\n",
        "  - reduce number of columns\n",
        "  - increase overall font size\n",
        "- X test with custom thresholds\n",
        "- test and fix for nonin\n",
        "- combine relevent pdfs into a report.\n",
        "- test with Clinical Data\n",
        "\n",
        "23-03-01\n",
        "- want table with name, total time monitored, total time below X condition calculated), total stimulations, total stimulation time, total time under Y condition, total errorenous data. \n",
        "\n",
        "23-03-15\n",
        "- check against Mona's numbers\n",
        "- \n",
        "\n"
      ],
      "metadata": {
        "id": "COmxc45t43_s"
      },
      "id": "COmxc45t43_s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2P7Ld8v0Zf"
      },
      "source": [
        "## **Initialize**"
      ],
      "id": "VY2P7Ld8v0Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Folder Name"
      ],
      "metadata": {
        "id": "s14DGNWX59Me"
      },
      "id": "s14DGNWX59Me"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Find Folders"
      ],
      "metadata": {
        "id": "KR-D_OFUQ4mK"
      },
      "id": "KR-D_OFUQ4mK"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "outputId": "4e379bbd-0142-449d-9202-b7ff40a157d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n432-4cQ4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (67.6.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "Imports done\n",
            "time: 2.84 ms (started: 2023-03-23 11:30:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import fileinput\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "import linecache\n",
        "from pathlib import Path\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "print (\"Imports done\")"
      ],
      "id": "6n432-4cQ4mR"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "outputId": "49ea5ce7-a5a5-4f62-b83d-8dc2681a6985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-ikFo4Q4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 9min 46s (started: 2023-03-23 11:30:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "aF-ikFo4Q4mR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Folders List"
      ],
      "metadata": {
        "id": "wu1Ny53mRFbR"
      },
      "id": "wu1Ny53mRFbR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "def list_folders(startpath):\n",
        "    list_path = []\n",
        "    list_folder = []\n",
        "    log = \"log\"\n",
        "    LOG = \"LOG\"\n",
        "    is_data_dir = 0;\n",
        "    previous_name_path = \"\"\n",
        "    for root, subdirs, files in os.walk(startpath):\n",
        "        is_data_dir = 0\n",
        "        for filename in files:\n",
        "            current_name_path = os.path.join(root)\n",
        "            if ((log in filename) | (LOG in filename)) & (previous_name_path != current_name_path):\n",
        "                full_path = os.path.join(root,filename)\n",
        "                list_folder.insert (0, os.path.basename (current_name_path))\n",
        "                list_path.insert(0, root)\n",
        "                previous_name_path = current_name_path\n",
        "\n",
        "    return list_path, list_folder\n"
      ],
      "metadata": {
        "id": "z6m2mfEt8Smu",
        "outputId": "631adce7-9377-4aad-be6f-4de2f0f468bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z6m2mfEt8Smu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.5 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Initialize Folders"
      ],
      "metadata": {
        "id": "PTpOGQud6Max"
      },
      "id": "PTpOGQud6Max"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQuN0Iql7AUK"
      },
      "source": [
        "## **Convert Files to Data Frames**"
      ],
      "id": "LQuN0Iql7AUK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers for Different Logger Versions"
      ],
      "metadata": {
        "id": "7VpeZHhf7O2V"
      },
      "id": "7VpeZHhf7O2V"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "header = \"\"\n",
        "settings_header = \"\" \n",
        "AB_Model = \"default_string\"\n",
        "number_of_commas = 0\n",
        "\n",
        "\n",
        "def decideDataLoggerVersion (df):\n",
        "  # Read the third line's header and decide which data logger version is used\n",
        "  # Assumes that the third line is unique for each data logger version\n",
        "  # I need to check with Sourabh if the third line correlates with versions for the St. John's studies.\n",
        "  global header\n",
        "  global settings_header\n",
        "  global AB_Model\n",
        "  global number_of_commas\n",
        "  \n",
        "  raw_logfile_data_table_headers = [\"default\"]\n",
        "  settings_table_headers = [\"\"]\n",
        "  data_table_headers = [\"\"]\n",
        "  settings_columns_rename_dict = [\"\"]\n",
        "  settings_columns_to_drop = [\"\"]\n",
        "  version = \"unknown data code version\"\n",
        "\n",
        "  ZUG_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,PI,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Battery voltage;\"\n",
        "  NONIN_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\"\n",
        "  CLINICAL_SETTINGS_HEADER_INTERVENTION = \"dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\"\n",
        "  CLINICAL_SETTINGS_HEADER_PLACEBO = \"dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\"\n",
        "\n",
        "  settings_header = df.iat[0,0]\n",
        "  header = df.iat[2,0]\n",
        "  number_of_commas = header.count (',')\n",
        "  print (settings_header)\n",
        "  print (header)\n",
        "\n",
        "  if header == ZUG_DATA_HEADER:\n",
        "    version = \"ZUG Circa April 2022\"\n",
        "    # print (\"Detected Zug\")\n",
        "  elif (header == NONIN_DATA_HEADER):\n",
        "      if (settings_header == CLINICAL_SETTINGS_HEADER_INTERVENTION):\n",
        "          version = \"Clinical M3-Intervention (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Intervention\"\n",
        "      elif (settings_header == CLINICAL_SETTINGS_HEADER_PLACEBO):\n",
        "          version = \"Clinical M3-Placebo (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Placebo\"\n",
        "      else:\n",
        "          version = \"NONIN Circa April 2022\"\n",
        "    # print (\"Detected Nonin\")\n",
        "  elif number_of_commas == 5:\n",
        "      version = \"Clinical M1 (Nonin, Tuhin) 2019\"\n",
        "      AB_Model = \"M1\"\n",
        "  elif number_of_commas == 9:\n",
        "      version = \"Clinical M2 (Nonin, Satish) 2019\"\n",
        "      AB_Model = \"M2\"\n",
        "  else:\n",
        "    print (\"Not able to Detect Nonin Nor Zug\")\n",
        "    AB_Model = \"Unable to detect AB Model\"\n",
        "  \n",
        "  print (version)\n",
        "\n",
        "  if version == \"ZUG Circa April 2022\":\n",
        "    AB_Model = \"ZUG Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "            \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "                \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",   \n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Data Date-Time\": 'datetime64[ns]',\n",
        "                \"Data Date\": 'datetime64[ns]',\n",
        "                \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "                \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float\n",
        "                #,\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Settings Date-Time\": str,\n",
        "                \"Settings Date\": str,\n",
        "                'Settings Time':str,\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str}\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"PI\":\"HR Threshold\",\n",
        "            \"Status\":\"AND/OR\",\n",
        "            \"Pulse-ox mode\":\"Duration\",\n",
        "            \"Threshold Met\":\"Stimulator Intensity\",\n",
        "            \"Stimulator Error\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    \n",
        "    settings_columns_to_drop = [\"Stimulator ON/OFF\",\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\"]\n",
        "\n",
        "  if version == \"NONIN Circa April 2022\":\n",
        "    AB_Model = \"NONIN Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"Status\":\"HR Threshold\",\n",
        "            \"Pulse-ox mode\":\"AND/OR\",\n",
        "            \"Threshold Met\":\"Duration\",\n",
        "            \"Stimulator Error\":\"Stimulator Intensity\",\n",
        "            \"Stimulator ON/OFF\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "  if version == \"Clinical M1 (Nonin, Tuhin) 2019\":\n",
        "\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"Status\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [    \n",
        "                    \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",        \n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "  if version == \"Clinical M2 (Nonin, Satish) 2019\":\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Status\",\n",
        "            \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Unused Column 4\",\n",
        "             # <-- need to double check which column is stim off/on\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [            \n",
        "        \"HR\",\t\"SPO2\",\t\"Status\",\"Stimulator ON/OFF\",\n",
        "        \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Unused Column 4\",\n",
        "            ]\n",
        "\n",
        "################ M3 ###########\n",
        "  if ((version == \"Clinical M3-Intervention (Nonin) 2019\") | (version == \"Clinical M3-Placebo (Nonin) 2019\")):\n",
        "  \n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    ## Settings rename dictionary is different \n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Intervention or Placebo\", \n",
        "            \"HR\" : \"Stimulator Intensity\",\n",
        "            \"Status\":\"Alarm intensity\",\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "\n",
        "  return raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict"
      ],
      "metadata": {
        "id": "-OMUDW4FZpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a492fc-e3bd-4635-d097-9527459db651"
      },
      "id": "-OMUDW4FZpEd",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.4 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile & Split Log Files to df_d and df_s"
      ],
      "metadata": {
        "id": "kns3IrBcDkdb"
      },
      "id": "kns3IrBcDkdb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Reference here: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
        "file_list = []\n",
        "\n",
        "def compileLogFiles (path):\n",
        "  global file_list\n",
        "#   print (path)\n",
        "  os.chdir(path)\n",
        "  file_list = sorted(glob.glob(\"*LOG*.csv\")) + sorted(glob.glob(\"*log*.csv\")) + sorted(glob.glob(\"*Log*.csv\")) + sorted(glob.glob(\"*LOG*.txt\")) + sorted(glob.glob(\"*log*.txt\")) + sorted(glob.glob(\"*Log*.txt\")) + sorted(glob.glob(\"*LOG*.TXT\")) + sorted(glob.glob(\"*log*.TXT\")) + sorted(glob.glob(\"*Log*.TXT\"))\n",
        "              # in 2019 clinical, some files are log and some are LOG\n",
        "#   file_list = sorted(glob.glob(\"*\"))\n",
        "  number_of_files = len(file_list)\n",
        "#   print(\"Number of Files:\" , len(file_list))\n",
        "  print (file_list)\n",
        "  li = []\n",
        "\n",
        "  for file_name in file_list:\n",
        "    # This could work faster potentially, but then the data logger identifier code for finding the zug/nonin code string has to be changed\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n', names=list(range(12)))\n",
        "    \n",
        "    # df = pd.read_csv(file_name, header=None)\n",
        "    df = pd.read_csv(file_name, header=None, sep='\\0')\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n')\n",
        "    # df = pd.read_csv(file_name, header=None, sep=',')\n",
        "    df['Source File'] = file_name\n",
        "    li.append (df)\n",
        "  \n",
        "  frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "_MMQAV31zaJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71a9f36-fb75-4d1b-e880-0dc912a8b4a2"
      },
      "id": "_MMQAV31zaJk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.44 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def splitToDataAndSettingsDF (df_LOGs):\n",
        "  \n",
        "  raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict = decideDataLoggerVersion (df_LOGs)    \n",
        "\n",
        "  df_raw = df_LOGs[0].str.split(',', expand=True)\n",
        "  #display (df_raw)\n",
        "   \n",
        "  df_raw.columns = raw_logfile_data_table_headers\n",
        "  df_raw[\"Source File\"] = df_LOGs [\"Source File\"]\n",
        "\n",
        "  # Extract Settings\n",
        "  df_raw_shift = df_raw.shift(periods=-1)\n",
        "  df_s = df_raw_shift[(df_raw.iloc[:,2]==\"Preset mode\") | (df_raw.iloc[:,2]==\"Intervention\") | (df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  # For the clinical data - just use the rows with a new source file to keep the time/date and file. \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == 'M2')):\n",
        "    df_s = df_raw.drop_duplicates(subset=[\"Source File\"], keep='first')\n",
        "\n",
        "\n",
        "  # Delete settings and settings headers\n",
        "  df_raw_shift = df_raw.shift(periods=1)                                        #shift down one row as a way to find one line below the settings header\n",
        "  rows_below_header = df_raw[(df_raw_shift.iloc[:,2]==\"Preset mode\") |(df_raw_shift.iloc[:,2]==\"Intervention\")|(df_raw_shift.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop(rows_below_header.index)                                 #Drop all the setttings data lines \n",
        "  rows_with_header = df_raw[(df_raw.iloc[:,2]==\"Preset mode\") |(df_raw.iloc[:,2]==\"Intervention\")|(df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the settings headers\n",
        "  rows_with_header = df_raw[df_raw.iloc[:,2]==\"SPO2\"]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the DATA headers\n",
        "  \n",
        "  # Format Settings Files\n",
        "  df_s.drop(settings_columns_to_drop, axis=1, inplace=True)                     # Drop extra columns\n",
        "  df_s.rename(columns=settings_columns_rename_dict, inplace=True)\n",
        "  if 'Alarm Intensity' in df_s.columns:\n",
        "    df_s['Alarm intensity'].apply(lambda v: v.rstrip(';'))\n",
        "  \n",
        "  #What's left of df_raw is now df_d for data\n",
        "  df_d = df_raw\n",
        "  if (AB_Model == \"NONIN Circa April 2022\"):\n",
        "    df_d.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "    #df_s.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "\n",
        "  # In the clinical, Tuhin put P for the devices that were placebo and would have stimulated but actually didn't.\n",
        "  # Replace those with the number 1\n",
        "  df_d[\"Stimulator ON/OFF\"].mask(df_d[\"Stimulator ON/OFF\"] == \" P\", 1, inplace= True)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  if (AB_Model == \"M1\"):\n",
        "    format_day = '%d-%MM-%yyyy'\n",
        "    format_time = '%H:%m:%s'\n",
        "  else:\n",
        "    format_day = '%d/%m/%y'\n",
        "    format_time = '%H:%M:%S'\n",
        "    \n",
        "\n",
        "#   if (AB_Model == \"M1\"):\n",
        "#       try:\n",
        "#         display (df_s)\n",
        "#         display (df_d)\n",
        "#         # df_s.head()\n",
        "#         # df_d.head()\n",
        "        \n",
        "#         # print (df_d.columns)\n",
        "#         # print (\"df_s1 \" + df_s[\"Settings Date\"][3] + df_s[\"Settings Time\"][3])\n",
        "#         df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"df_d1 \" + df_d[\"Data Date\"][3] + df_d[\"Data Time\"][3])\n",
        "#         df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))   \n",
        "#         print (\"matched 1!\")\n",
        "#       except Exception as e:\n",
        "#           print (e)\n",
        "#           print (\"try alternate date format:\")\n",
        "#           display (df_s)\n",
        "#         #   print (df_d.columns)\n",
        "#           try:\n",
        "#             # df_s.drop (\"Settings Date-Time\")\n",
        "#             # df_d.drop (\"Data Date-Time\")\n",
        "#             # df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             # df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))  \n",
        "#             print (\"matched 2!\")\n",
        "#           except Exception as e2:\n",
        "#             print (e2)\n",
        "#             print (\"no more date formats to try!\")       \n",
        " \n",
        "\n",
        "#   else:\n",
        "#     df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#     df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#   print (\"inserting with \"+format_day + \" \" + format_time)\n",
        "#   display (df_s)\n",
        "\n",
        "#   print (\"df_s insert done, here's what it looks like\")\n",
        "#   display (df_s)\n",
        "#   display (df_d)\n",
        "\n",
        "#   print (\"df_d coerce done and now df_d looks like:\")\n",
        "#   display (df_d)\n",
        "#   print (\"inserts done\")\n",
        "\n",
        "# MARCH 9, 2023 - These two lines below work (infer_datetime_format=True needs to be checked bc some columns may have multiple date Time formats?) \n",
        "# but it's still slow so I'm commenting them out for now and replacing them with the two below\n",
        "\n",
        "#   df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "#   df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "\n",
        "  df_s.insert(loc=0, column=\"Settings Date-Time\", value=df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"])\n",
        "  df_d.insert(loc=0, column=\"Data Date-Time\", value=df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"])\n",
        "\n",
        "  \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == \"M2\") | (AB_Model == \"M3-Placebo\") | (AB_Model == \"M3-Intervention\")):\n",
        "      df_s.insert(loc = 3, column=\"Preset mode\", value = 1)\n",
        "      df_s.insert(loc = 4, column=\"SPO2 Threshold\", value = 0)\n",
        "      df_s.insert(loc = 5, column=\"HR Threshold\", value = 0)\n",
        "      df_s.insert(loc = 6, column=\"AND/OR\", value = 0)\n",
        "      df_s.insert(loc = 7, column=\"Duration\", value = 0)\n",
        "      if ((AB_Model == \"M1\") | (AB_Model == \"M2\")):\n",
        "        df_s.insert(loc = 8, column=\"Stimulator Intensity\", value = 0)\n",
        "        df_s.insert(loc = 9, column=\"Alarm intensity\", value = 0)\n",
        "\n",
        "  #Cleanup NaNs\n",
        "  df_d = df_d.fillna(0)\n",
        "  df_s = df_s.fillna(0)\n",
        "\n",
        "  #Convert to best datatypes\n",
        "\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format='%d/%m/%y')\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format='%H:%M:%S')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format='%d/%m/%y')\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format='%H:%M:%S')#.dt.time\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format=format_day)\n",
        "#   print (\"Settings Date Updated done\")\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Settings Time Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format=format_day)\n",
        "#   print (\"Data Date Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Data Time Updated done\")\n",
        "  \n",
        "## For Clinical Analysis I am not going to do these, since they are already done above when combined. \n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"])\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"], errors = 'coerce')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"])\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"], errors = 'coerce')#.dt.time\n",
        "  df_s.drop(columns = \"Settings Date\", axis = 1, inplace=True)\n",
        "  df_s.drop(columns = \"Settings Time\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Date\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Time\", axis = 1, inplace=True)\n",
        "  df_s=df_s.astype(settings_convert_dict, errors='raise')\n",
        "  df_d=df_d.astype(data_convert_dict, errors='raise')\n",
        "\n",
        "  #df_d = ResolveMidnightDateIssue (df_d) \n",
        "\n",
        "#  df_d[\"Data Date-Time\"]=pd.to_datetime(df_d[\"Data Date-Time\"],format='%d/%m/%y %H:%M:%S')\n",
        "\n",
        "  # For Settings Table delete the confusing default numbers left in place when \"preset\" condition is on.\n",
        "# \n",
        "  df_s = DeleteThresholdsForRowsUsingPresetConditions(df_s)\n",
        "  df_s, df_d = addSettingsIndex (df_s,df_d)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "_jiazNDlz1Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78b00b5-dcd0-4136-856d-d1cd6e9e204b"
      },
      "id": "_jiazNDlz1Dp",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.76 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XH-EgNxkPi",
        "outputId": "2a09e678-35ab-4f05-a2dc-9c1a5fd2b6b0"
      },
      "id": "T9XH-EgNxkPi",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 22.3 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It was observed with Zug that for the first ~30 seconds after midnight, the date does not change. This needs to be fixed or \"smoothed\" with the code below.\n",
        "#import calendar\n",
        "\n",
        "#### This function is not finished.\n",
        "def ResolveMidnightDateIssue (df_above):\n",
        "  print (\"in the smooth\")\n",
        "  df_diff = pd.DataFrame ()\n",
        "  df_below = pd.DataFrame ()\n",
        "\n",
        "  df_below[\"Data Date-Time\"] = df_above[\"Data Date-Time\"].shift (periods=1, fill_value=0)\n",
        "  #df_below[\"Data Date\"] = df_above[\"Data Date\"].shift (periods=1, fill_value=0)\n",
        "  df_below [\"Date Diff\"] = df_above[\"Data Date-Time\"] < df_below[\"Data Date-Time\"]\n",
        "  df_below [\"Date Diff Num\"] = (df_above[\"Data Date-Time\"] - df_below[\"Data Date-Time\"]).dt.total_seconds()\n",
        "  print (df_below [\"Date Diff Num\"].dtype)\n",
        "  \n",
        "\n",
        "  # display(df_above)\n",
        "  # display(df_below)\n",
        "  # display (df_below[df_below[\"Date Diff\"]==1])\n",
        "  df_midnight_bounds = df_below[df_below[\"Date Diff Num\"].abs()>1000]\n",
        "  #display (df_midnight_bounds)\n",
        "  # for i in df_midnight_bounds.index:\n",
        "  #   print (i)\n",
        "\n",
        "\n",
        "\n",
        "  #display (df_below[df_below[\"Date Diff Num\"]!=1])\n",
        "  \n",
        "  print (\"Sum is: \" + df_below[\"Date Diff\"].astype(int).sum().astype(str))\n",
        "  \n",
        "  return df_above\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2noyZAXZNuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9176c99-0b4d-483a-df3a-74140e2af838"
      },
      "id": "J2noyZAXZNuk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.28 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def addSettingsIndex (df_s,df_d):\n",
        "  #df_s[\"Settings Index\"] = np.arange(len(df_s))\n",
        "  df_s.insert(loc=0, column=\"Settings Index\", value=np.arange(len(df_s))+1)\n",
        "  df_d = pd.merge_asof (df_d,df_s[\"Settings Index\"],left_index=True, right_index=True)\n",
        "  SettingsIndexCol = df_d.pop('Settings Index')\n",
        "  df_d.insert(0, 'Settings Index', SettingsIndexCol)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "SeN4pRpcmoTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30a0ee5-dbd1-443d-a141-9abbb827aa16"
      },
      "id": "SeN4pRpcmoTt",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.19 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4921b0d4-518c-4132-af8d-e511d2cd5dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.24 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def DeleteThresholdsForRowsUsingPresetConditions (settings_table):\n",
        "    # display(settings_table)\n",
        "    for ind in settings_table.index:\n",
        "        if settings_table[\"Preset mode\"][ind] == 1:\n",
        "            settings_table[\"SPO2 Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"HR Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"AND/OR\"][ind] = np.NaN\n",
        "            settings_table[\"Duration\"][ind] = np.NaN\n",
        "                       #Preset mode\tSPO2 Threshold\tHR Threshold\tAND/OR\tDuration\n",
        "    return settings_table\n"
      ],
      "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dPG9_2xoX3"
      },
      "source": [
        "## **Analyze Thresholds**"
      ],
      "id": "T3dPG9_2xoX3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Only Valid Data\n",
        "This filters data based on device status. "
      ],
      "metadata": {
        "id": "YxecqEFREEhV"
      },
      "id": "YxecqEFREEhV"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b547f0-dee6-4e98-ea32-a45b754bab32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.74 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def GetIsValidColumn (df):\n",
        "    is_valid = pd.DataFrame ()\n",
        "    is_valid [\"valid_vitals\"] = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff) & (df[\"HR\"] !=255) & (df[\"SPO2\"] !=127))\n",
        "    # print (\"Num IsValid Vitals True:\")\n",
        "    # print (is_valid[\"valid_vitals\"].sum())\n",
        "    # print (is_valid [\"valid_vitals\"])\n",
        "    # is_valid['valid_vitals'].value_counts()\n",
        "    # print (\"num valid vitals: \" + is_valid [is_valid[\"valid_vitals\"]==True].count)\n",
        "\n",
        "    # Determine if status scale is 0-6 or 0-255...\n",
        "    max_status = df[\"Status\"].max()\n",
        "    print (\"about to check valid_status\")\n",
        "    display (df)\n",
        "    # if (AB_Model == \"M1\"):\n",
        "    if (max_status < 7):\n",
        "        print (\"eval status for 0-6 status\")\n",
        "        is_valid [\"valid_status\"] = (df['Status'] == 0);\n",
        "    elif (max_status >= 7):\n",
        "        print (\"eval status for 0-255 status\")\n",
        "        is_valid [\"valid_status\"] = ((df['Status'] == 129) | (df['Status'] == 131));  \n",
        "    \n",
        "    # print (\"Num IsValid Status True:\")\n",
        "    # print (is_valid[\"valid_status\"].sum())\n",
        "    \n",
        "    is_valid['Is_Valid_Data'] = np.where((is_valid['valid_status'] == True) & (is_valid[\"valid_vitals\"] == True), True, False)\n",
        "    # is_valid [\"Is_Valid_Data\"] = ((is_valid['valid_vitals'] == True) & (is_valid ['valid_status'] == True))\n",
        "    # is_valid['Is_Valid_Data'].value_counts()\n",
        "    # print (\"Num IsValid True:\")\n",
        "    # print (is_valid[\"Is_Valid_Data\"].sum())\n",
        "    return is_valid [\"Is_Valid_Data\"]\n",
        "\n",
        "\n"
      ],
      "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Against Custom Thresholds\n",
        "This function returns what is expected in the custom mode the user selected. It should match with actual stimulations in custom mode."
      ],
      "metadata": {
        "id": "dm2RieFwTAjS"
      },
      "id": "dm2RieFwTAjS"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9abf27c-4108-4223-bdf9-ac06c31b7cdb",
        "id": "pndZJ_WATAja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.76 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def AnalyzeWithCustomThresholds (df):\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) & (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) | (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_result = (df[\"AND/OR\"]==0)*is_below_threshold_OR + (df[\"AND/OR\"]==1)*is_below_threshold_AND\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= df[\"Duration\"],0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "\n",
        "  df[Duration_Custom] = df_unmasked.mask(df_unmasked <= df[\"Duration\"],0)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "id": "pndZJ_WATAja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze With Preset Thresholds\n",
        "This function is useful to see how the system would have performed if it were operating in preset mode."
      ],
      "metadata": {
        "id": "c9pqOw4FnVYA"
      },
      "id": "c9pqOw4FnVYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "SPO2_threshold_AND_condition = 85\n",
        "HR_threshold_AND_condition = 100\n",
        "SP02_threshold_OR_condition = 75\n",
        "HR_threshold_OR_condition  = 90\n",
        "Preset_Mode_Duration = 5\n",
        "\n",
        "def AnalyzeWithPresetThresholds (df):\n",
        "  \n",
        "    \n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "  # is_below_threshold_result = ((df[\"AND/OR\"]==0))&(is_below_threshold_OR) | ((df[\"AND/OR\"]==1) &is_below_threshold_AND)\n",
        "  is_below_threshold_result = is_below_threshold_OR | is_below_threshold_AND\n",
        "  #print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "#   display (is_below_threshold_result)\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= Preset_Mode_Duration,0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  # print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "\n",
        "  # print (\"Total preset results are: \" + str(is_below_threshold_result.sum()))\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "  df[Duration_Preset] = df_unmasked.mask(df_unmasked <= Preset_Mode_Duration,0)\n",
        "\n",
        "  #print (\"Sum is:\" + str(sum(df[Duration_Preset])))\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "NFGvMndV_NLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452a0d2e-70e3-45d3-e116-bb1d643a95e2"
      },
      "id": "NFGvMndV_NLH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.97 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Actual Stimulations\n",
        "This function looks at Stim Off/On field and counts the apnea durations (assuming SPO2 & HR are not 0). It does not consider the Preset/Custom settings at all. "
      ],
      "metadata": {
        "id": "Ff704C-MwEsw"
      },
      "id": "Ff704C-MwEsw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Assumes it is being passed df_j\n",
        "def AddNumActualStimulations (df):\n",
        "  \n",
        "#   Valid_Stimulations = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff)*(df[\"HR\"]>Data_Cleanup_HR_LowCutOff)\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  Valid_Stimulations = df[\"Stimulator ON/OFF\"]*is_valid\n",
        "  df[Duration_Actual] = calcDurationsCrossedThreshold(pd.DataFrame(Valid_Stimulations))\n",
        "   \n",
        "  ## New code (22-07-23) - I later realized that with the new apnea duration counter, we don't need to \"Stimulation started column\" as it easily puts the apnea duration time where the stimulation started. \n",
        "  # df[\"Stimulator ON/OFF with Valid SPO2/HR\"] = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]!=0)*(df[\"HR\"]!=0) \n",
        "\n",
        "  # df_previousrow = df.shift(periods=1)\n",
        "  # isStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF with Valid SPO2/HR\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF with Valid SPO2/HR\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0)\n",
        "  #                         )  # This condition was added because there are some odd cases where the stimulator turns when HR/SPO2 are 0...\n",
        "\n",
        "  #This gives 408 rows, but the one above gives 411 rows. There are likely some times then the O2 or HR jumps to zero mid apnea but jumps back up and the stimulator is on the whole time? \n",
        "  # OldisStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0))\n",
        "\n",
        "  #Should be 408 Rows\n",
        "  \n",
        "  # df[\"Stimulation Triggered (Actual Stimulator ON Triggered)\"] = isStimulationStarted\n",
        "  # df[\"Actual - Stimulation Durations (s)\"] = calcDurationsCrossedThreshold(pd.DataFrame(df[\"Stimulator ON/OFF with Valid SPO2/HR\"]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "CI2GKzN15PZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7148c3-dfe8-4c9c-cc8e-80319393b0d3"
      },
      "id": "CI2GKzN15PZJ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.58 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Cross Duration\n",
        "This takes an array of \"threshold crossed\" or \"stimulation on\" (0,0,0,1,1,1,1,0..etc) and returns an array with the time in the first place the threshold is cross i.e. (0,0,0,4,0,0,0,0...)"
      ],
      "metadata": {
        "id": "4C39qoDxEcnt"
      },
      "id": "4C39qoDxEcnt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Input: A df with 0s and 1s representing cross thresholds\n",
        "# see this -  https://stackoverflow.com/questions/62615666/how-to-sum-variable-ranges-in-a-pandas-column-to-another-column\n",
        "def calcDurationsCrossedThreshold (df):\n",
        "  \n",
        "  df = df.iloc[::-1]\n",
        "  a = df.iloc[:,0]==0\n",
        "  blocks = a.cumsum()\n",
        "  \n",
        "  m = blocks.duplicated(keep='last')\n",
        "  \n",
        "  df['Sum'] = df.iloc[:,0].groupby(blocks).cumsum().mask(m)\n",
        "  df = df.iloc[::-1]\n",
        "  df_return = df ['Sum'].fillna(0)\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "HIOGli41rAgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b165324-84a8-4d35-f63b-cb531b930554"
      },
      "id": "HIOGli41rAgo",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.13 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Summary Tables**"
      ],
      "metadata": {
        "id": "vFvsiREGpJ-8"
      },
      "id": "vFvsiREGpJ-8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportApneaCountBySetting (df,df_s):\n",
        "  table = pd.pivot_table (df, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='sum')\n",
        "#   display (table)\n",
        "  table = table.rename (columns = {Duration_Actual:SumDuration_Actual, Duration_Preset:SumDuration_Preset, Duration_Custom:SumDuration_Preset})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "  \n",
        "\n",
        "  #Count function counts zeros too, so need to replace zeros with NAs for this to work.\n",
        "  df_nan = df.mask(df==0) # This will make all zeros into Nan\n",
        "  table = pd.pivot_table (df_nan, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='count')\n",
        "  \n",
        "  table = table.rename (columns = {Duration_Actual:Count_Actual, Duration_Preset:Count_Preset, Duration_Custom:Count_Custom})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "#   display (df_s)\n",
        "  \n",
        "  if (PRINT_TABLES == True):\n",
        "    df_s.to_excel (folder_name + \" - Summary of Events.xlsx\")\n",
        "    dataframe_to_pdf(df_s, folder_name + \" - Apnea Count By Setting\")\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McI1Xwv81qIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f967b9db-1d59-4bfe-fbb9-9638e20c6347"
      },
      "id": "McI1Xwv81qIh",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.04 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportIndividualActualApneas (df):\n",
        "  table_A = df[df[Duration_Actual]!=0]\n",
        "  table_P = df[df[Duration_Preset]!=0]\n",
        "  table_C = df[df[Duration_Custom]!=0]\n",
        "  table_A_P = df[ (df[\"Preset mode\"]==1 & (df[Duration_Actual]!=df[Duration_Preset]))]\n",
        "  table_A_C = df[ (df[\"Preset mode\"]==0 & (df[Duration_Actual]!=df[Duration_Custom]))]\n",
        "                   \n",
        "  if (PRINT_TABLES == True):\n",
        "    with pd.ExcelWriter(folder_name + \" - Individual Events.xlsx\") as writer:\n",
        "        table_A.to_excel (writer, sheet_name=\"Actual\")\n",
        "        table_P.to_excel (writer, sheet_name=\"Preset\")\n",
        "        table_C.to_excel (writer, sheet_name=\"Custom\")\n",
        "        table_A_P.to_excel (writer, sheet_name=\"Actual-Preset Discrepancy\")\n",
        "        table_A_C.to_excel (writer, sheet_name=\"Actual-Custom Discrepancey\")\n",
        "\n",
        "    dataframe_to_pdf(table_A, folder_name + \" - Individual Events (Actual)\")\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "IbdRSJx_MgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcdddd9-84c5-4a89-f086-5954b8443e07"
      },
      "id": "IbdRSJx_MgxZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.44 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def countApneas (df):\n",
        "   df_nan = df.mask(df==0)\n",
        "   count = np.sum(df_nan.count())\n",
        "   print (\"Num Apneas is:\" + str(count))\n",
        "   return count\n",
        "\n",
        "def sumApneaTime (df):\n",
        "    sum = df.sum(df)\n",
        "    print (\"Sum Apnea Time is:\" + str (sum))\n",
        "    return sum\n",
        "   "
      ],
      "metadata": {
        "id": "4SvGB35kvb-z"
      },
      "id": "4SvGB35kvb-z",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def convertDataframeToFigure (df):\n",
        "  display (df)\n",
        "  fig, ax =plt.subplots(figsize =(20,20))\n",
        "  #fig, ax =plt.subplots(figsize=(len(df),len(df.columns)))\n",
        "  ax.axis('tight')\n",
        "  ax.axis('off')\n",
        "  the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "  return fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qxv3-8-3lsTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798fb28a-6353-46c9-90f0-17c1fc5884be"
      },
      "id": "Qxv3-8-3lsTZ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.93 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ## Print Tables to PDF **\n",
        "This code enables printing tables to pdf."
      ],
      "metadata": {
        "id": "Sb6hldAxxaXX"
      },
      "id": "Sb6hldAxxaXX"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import textwrap as twp\n",
        "\n",
        "# #create column headers with long text and apply textwrap with \\n after defined lenght\n",
        "# columns=[twp.fill('this is a long column header text',25), twp.fill('...and this is an even longer column header text',25)]\n",
        "\n",
        "# https://predictivehacks.com/?all-tips=save-a-pandas-dataframe-as-an-image\n",
        "# pip install dataframe-image\n",
        "# import pandas as pd\n",
        "# import dataframe_image as dfi\n",
        " \n",
        "# dfi.export(df, 'dataframe.png')\n",
        "\n",
        "def _draw_as_table(df, pagesize):\n",
        "    alternating_colors = [['white'] * len(df.columns), ['lightgray'] * len(df.columns)] * len(df)\n",
        "    alternating_colors = alternating_colors[:len(df)]\n",
        "    fig, ax = plt.subplots(figsize=pagesize)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    # df=df.to_string(line_width=5)\n",
        "    # .str.wrap(5)\n",
        "    col_headers=list(df.columns.str.wrap(15)) #df.columns#.map(\"str\")\n",
        "    #display (col_headers)\n",
        "    #print (\"Cols is \" + len(df[0]))\n",
        "    #display (df)\n",
        "    the_table = ax.table(cellText=df.values,\n",
        "                        rowLabels=df.index,\n",
        "                        colLabels=col_headers,\n",
        "                        #colLabels=df.columns,\n",
        "                        rowColours=['lightblue']*len(df),\n",
        "                        colColours=['lightblue']*len(df.columns),\n",
        "                        cellColours=alternating_colors,\n",
        "                        loc='center')\n",
        "    the_table.auto_set_column_width(col=list(range(len(df.columns)))) # Provide integer list of columns to adjust\n",
        "\n",
        "    # the_table.auto_set_font_size(False)\n",
        "    # the_table.set_fontsize(12)\n",
        "    return fig\n",
        "  \n",
        "\n",
        "def dataframe_to_pdf(df, filename, numpages=(1, 1), pagesize=(11, 8.5)):\n",
        "  with PdfPages(filename) as pdf:\n",
        "    # display (df)\n",
        "    # nh, nv = numpages\n",
        "    # rows_per_page = len(df) // nh\n",
        "    # cols_per_page = len(df.columns) // nv\n",
        "\n",
        "    # nh, nv = numpages\n",
        "    rows_per_page = 30\n",
        "    cols_per_page = len(df.columns)\n",
        "    nv = 1\n",
        "    \n",
        "    if len(df) % rows_per_page == 0: \n",
        "      nh = int(len(df) / rows_per_page)\n",
        "    else:\n",
        "      nh = int(len(df) / rows_per_page) +1\n",
        "    \n",
        "    # print ('num cols is ' + str(len(df.columns)))\n",
        "    # print ('num rows is ' + str(len(df)) + \"nv is \" + str(nv))\n",
        "\n",
        "    for i in range(0, nh):\n",
        "        for j in range(0, nv):\n",
        "            # print (\"i is \" + str(i) + \"and j is \" + str(j))\n",
        "            page = df.iloc[(i*rows_per_page):min((i+1)*rows_per_page, len(df)),\n",
        "                           (j*cols_per_page):min((j+1)*cols_per_page, len(df.columns))]\n",
        "            # display (page)\n",
        "            fig = _draw_as_table(page, pagesize)\n",
        "            if nh > 1 or nv > 1:\n",
        "                # Add a part/page number at bottom-center of page\n",
        "                fig.text(0.5, 0.5/pagesize[0],\n",
        "                         \"Part-{}x{}: Page-{}\".format(i+1, j+1, i*nv + j + 1),\n",
        "                         ha='center', fontsize=8)\n",
        "            \n",
        "            pdf.savefig(fig, bbox_inches='tight')\n",
        "            # plt.show ()\n",
        "            plt.close()\n"
      ],
      "metadata": {
        "id": "BQDht-5kNQpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8566908-2917-46d3-92ae-c82221f2d818"
      },
      "id": "BQDht-5kNQpD",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 372 ms (started: 2023-03-23 11:40:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AZp6q5Z8Aq"
      },
      "source": [
        "## **Plots**"
      ],
      "id": "X_AZp6q5Z8Aq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot AB Data"
      ],
      "metadata": {
        "id": "1uadoNfrjZUt"
      },
      "id": "1uadoNfrjZUt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotApneBootData (df,plot_title,x_axis_start,x_axis_end):\n",
        "    #display (df)\n",
        "    \n",
        "    f, (ax, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 1]})\n",
        "\n",
        "    ax2 = df.plot(x=\"Data Date-Time\", y=\"Status\", rot=0,ax=ax2)\n",
        "    \n",
        "    plotSPO2AndHR(df,plot_title,x_axis_start,x_axis_end,ax)\n",
        "       \n",
        "    f.tight_layout()\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xxrNme8yvvkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b996faa9-a08a-498c-b839-dde22bd6d9c9"
      },
      "id": "xxrNme8yvvkW",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.29 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotSPO2AndHR (df,plot_title,x_axis_start,x_axis_end,ax):\n",
        "  df[\"Stimulator ON/OFF Plot\"] = df[\"Stimulator ON/OFF\"]*20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ax = df.plot(x=\"Data Date-Time\", y=\"SPO2\", \n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                            rot=0,\n",
        "                            #kind='scatter',\n",
        "                            color = 'red',\n",
        "                            label = \"SPO2\",\n",
        "                            linewidth=1, \n",
        "                            #s=2,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df.plot(x=\"Data Date-Time\", y=\"HR\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=True,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'blue',\n",
        "                          label = \"HR\",\n",
        "                          linewidth=1,\n",
        "                          #s=2,\n",
        "                          ax=ax)\n",
        "  \n",
        "  df.plot.line(x=\"Data Date-Time\", y=\"Stimulator ON/OFF Plot\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          linewidth=4,\n",
        "                          alpha=0.2,\n",
        "               \n",
        "                          #fmt ='+',\n",
        "                          color = 'Orange',\n",
        "                          label = \"Stim ON\",\n",
        "                          #s=30,\n",
        "                          ax=ax)\n",
        "                          \n",
        "  df_t = getThresholdTable (df)\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"SPO2 Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkRed',\n",
        "                          label = \"SPO2 Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dashed',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"HR Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkBlue',\n",
        "                          label = \"HR Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dotted',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  x_offset = (x_axis_end - x_axis_start)/10\n",
        "#   df_a = df[(df[Duration_Actual] > 0)]\n",
        "  df_a = df[(df[Duration_Preset] > 0)]\n",
        "  #df_a[\"Text X Position\"] = df_a[\"Data Date-Time\"][ind] - x_offset\n",
        "  df_a=df_a.reset_index(drop=True)\n",
        "  df_a[\"Arrow Offet\"] = df_a[\"Data Date-Time\"] - x_offset\n",
        "\n",
        "  for ind in df_a.index:\n",
        "    if df_a[\"Arrow Offet\"][ind] <= x_axis_start:\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than \" + str(x_axis_start))\n",
        "      df_a[\"Arrow Offet\"][ind] = df_a[\"Arrow Offet\"][ind] + x_offset*2\n",
        "      print (\"so we replace with: \" + str(df_a[\"Arrow Offet\"][ind]))\n",
        "    #print (ind)\n",
        "    # ax.annotate(\"Event For \" + df_a[Duration_Actual][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "    #         xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "    #         fontsize = 10, \n",
        "    #         xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "    #         arrowprops = dict(facecolor = 'yellow'),\n",
        "    #         color = 'black',\n",
        "    #         backgroundcolor='white')\n",
        "\n",
        "ax.annotate(\"Event For \" + df_a[Duration_Preset][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "            xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "            fontsize = 10, \n",
        "            xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "            arrowprops = dict(facecolor = 'yellow'),\n",
        "            color = 'black',\n",
        "            backgroundcolor='white')\n",
        "\n",
        "\n",
        "  #df.plot.annotate(df[Duration_Actual].str(), xy=\"Data Date-Time\", y=100, , fontsize = 10, color = 'g')\n",
        "\n",
        "  #### PRINT THresholds\n",
        "  \n",
        "  # ax.plot.line (x=df[\"Data Date-Time\"], y=df_t[\"HR Threshold\"], \n",
        "  #                         #figsize=(20,5),\n",
        "  #                         #title = current_date,\n",
        "  #                         #ylim=(-5,150),\n",
        "  #                         #xlim= (x_axis_start, x_axis_end),\n",
        "  #                         #grid=1 ,\n",
        "  #                         #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "  #                         #rot=1,\n",
        "  #                         #kind='scatter',\n",
        "  #                         color = 'Orange',\n",
        "  #                         label = \"HR Threshold\",\n",
        "  #                         linewidth=1,\n",
        "  #                         #s=2,\n",
        "  #                         ax=ax\n",
        "  #                         )\n",
        "\n",
        "\n",
        "\n",
        "  ax.grid('on', which='major')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "br-rk3f9_P2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a7d7ca-730b-4013-ba93-12e546db88f4"
      },
      "id": "br-rk3f9_P2G",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.8 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Threshold Table"
      ],
      "metadata": {
        "id": "qYEzi3M-S0K6"
      },
      "id": "qYEzi3M-S0K6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def getThresholdTable (df):\n",
        "  SPO2_threshold_AND_condition = 85\n",
        "  HR_threshold_AND_condition = 100\n",
        "  SP02_threshold_OR_condition = 75\n",
        "  HR_threshold_OR_condition  = 90\n",
        "  Preset_Mode_Duration = 5\n",
        "\n",
        "  df_t = pd.DataFrame()\n",
        "  #df_t = df\n",
        "  # df_t [\"HR Threshold\"] = 60\n",
        "  # df_t [\"SPO2 Threshold\"] = 64\n",
        "  df_t [\"Data Date-Time\"] = df[\"Data Date-Time\"]\n",
        "  df_t [\"HR Threshold\"] = df[\"Preset mode\"]*HR_threshold_OR_condition\n",
        "  df_t [\"SPO2 Threshold\"] = df[\"Preset mode\"]*SP02_threshold_OR_condition\n",
        "  df_t[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]=df[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]\n",
        "  df_t[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]=df[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]\n",
        "\n",
        "  # df_t [\"HR Custom\"] = df[\"HR Threshold\"]\n",
        "  # df[\"SPO2 Threshold\"].notna().astype(int)*df[\"SPO2 Threshold\"]\n",
        "  # display (df_t)\n",
        "\n",
        "  #is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  \n",
        "  #print (\"df_t is: \")\n",
        "  #display (df_t)\n",
        "\n",
        "  return df_t"
      ],
      "metadata": {
        "id": "oDhFqjhBjY20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d7bb9b-4778-464e-ec68-43ec6df8a4e9"
      },
      "id": "oDhFqjhBjY20",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.42 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot by Day"
      ],
      "metadata": {
        "id": "bHJA2jljjdc-"
      },
      "id": "bHJA2jljjdc-"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ea3a1SQZLQB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2754399d-f2b4-4fb4-87c1-8a9c9da02a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.59 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_plot=df_j\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "def plotByDay (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    length = len(date_list)\n",
        "\n",
        "    fname = folder_name + ' plot_by_day.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "        for i in range(length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "          \n",
        "          # x axis start and end\n",
        "          x_axis_start = current_date.replace(second = 1)\n",
        "          #print(x_axis_start)\n",
        "          x_axis_end = current_date.replace(hour = 23, minute=59, second = 59)\n",
        "          \n",
        "          \n",
        "          ##### Sept 7 - Not sure if this below has to be commented or fixed\n",
        "          # df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"].astype(str)).dt.time\n",
        "          # #df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"])\n",
        "          df_current_date[\"Data Time\"] = df_current_date[\"Data Time\"].dt.time\n",
        "          df_current_date.set_index('Data Time')\n",
        "          #display(df_current_date.dtypes)\n",
        "          #display (df_current_date)\n",
        "          \n",
        "          plotApneBootData (df_current_date,current_date_64,x_axis_start,x_axis_end)\n",
        "          pdf.savefig()\n",
        "          plt.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "2ea3a1SQZLQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot By Hour"
      ],
      "metadata": {
        "id": "eoiLSOJ3jfmj"
      },
      "id": "eoiLSOJ3jfmj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotByHour (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    df[\"Data Time\"] = pd.to_datetime(df[\"Data Time\"])\n",
        "    df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "    # display(df)\n",
        "    # return\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    date_length = len(date_list)\n",
        "    fname = folder_name + ' plot_by_hour.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "\n",
        "        firstPage = plt.figure(figsize=(11.69,8.27))\n",
        "        firstPage.clf()\n",
        "        txt = 'This is the title page'\n",
        "        firstPage.text(0.5,0.5,txt, transform=firstPage.transFigure, size=24, ha=\"center\")\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(date_length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "      \n",
        "          hour_list = np.unique(df_current_date[\"Data Time-Hour\"])\n",
        "          hour_length = len(hour_list)\n",
        "          #print (hour_list)\n",
        "\n",
        "          for j in range(hour_length):\n",
        "              current_hour_64 = hour_list[j]\n",
        "              #current_date=pd.to_datetime(current_date_64)\n",
        "              df_current_hour = df_current_date[(df_current_date[\"Data Time-Hour\"]==current_hour_64)]\n",
        "              x_start = current_date + pd.offsets.Hour(current_hour_64)\n",
        "              x_end = current_date + pd.offsets.Hour(current_hour_64+1)\n",
        "              df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              \n",
        "              # x_start = df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              title = str (current_date) + ' ' + str(x_start)\n",
        "              plotApneBootData (df_current_hour,x_start,x_start,x_end)\n",
        "              # plotApneBootData (df_current_hour,current_date,current_hour_64,current_hour_64+1)\n",
        "              pdf.savefig()\n",
        "              plt.close()\n"
      ],
      "metadata": {
        "id": "kNpgyduy7ulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5a53ef-4ac5-4605-a6cc-76d243d53745"
      },
      "id": "kNpgyduy7ulE",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.36 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubPlot Grids of Apnea Events "
      ],
      "metadata": {
        "id": "kPbeaF7WOonR"
      },
      "id": "kPbeaF7WOonR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "### Plot multiple subplots\n",
        "\n",
        "def PlotApneaEventsGrid (df):\n",
        "  \n",
        "  start_offset = dt.timedelta (seconds=15)\n",
        "  end_offset = dt.timedelta (seconds=45)\n",
        "  num_rows = 2\n",
        "  num_cols = 2\n",
        "  num_subplots = num_rows * num_cols\n",
        "\n",
        "#   df_list_of_apnea_events = df[(df[Duration_Actual] != 0)]\n",
        "  df_list_of_apnea_events = df[(df[Duration_Preset] != 0)]\n",
        "  \n",
        "  num_events = len(df_list_of_apnea_events)\n",
        "  # print (\"div \" + str(num_events/num_subplots))\n",
        "  # print (\"div \" + str(9/4))\n",
        "  # print (\"div \" + str(np.ceil(9/4)))\n",
        "  # #num_pages = int(num_events/num_subplots + 1)\n",
        "  num_pages = int(np.ceil(num_events/num_subplots))\n",
        "  #print (\"number of pages is \" + str (num_pages))\n",
        "  #print (\"number of events is \" + str (num_events))\n",
        "  current_page = 0\n",
        "  current_event = 0\n",
        " \n",
        "  fname = folder_name + ' plot_individual_events.pdf'\n",
        "  with PdfPages(fname) as pdf:\n",
        "    for page in range (num_pages):\n",
        "      fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols)\n",
        "      # print (axes.flat)\n",
        "      for ax in axes.flat:\n",
        "        if (current_event < num_events):\n",
        "          event_time = df_list_of_apnea_events.iloc[current_event].at[\"Data Date-Time\"]\n",
        "          plot_start = event_time - start_offset\n",
        "          plot_end = event_time + end_offset\n",
        "          df_event_data = df[((df[\"Data Date-Time\"] > plot_start) & (df[\"Data Date-Time\"] < plot_end))]\n",
        "          #print (\"Current Event Index is \" + str(current_event))\n",
        "          current_event = current_event + 1\n",
        "          plot_title = folder_name + \" Event \" + str(current_event) + \":  \" + str(event_time)\n",
        "          plotSPO2AndHR (df_event_data,plot_title,plot_start,plot_end,ax)\n",
        "    #   print (\"tight layout\")\n",
        "      fig.tight_layout()\n",
        "      pdf.savefig()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "C5DBtqMI2WTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a2b035-b5ee-4cc1-a7e2-acf951efacae"
      },
      "id": "C5DBtqMI2WTB",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.11 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4vbvlm-hsj"
      },
      "source": [
        "## **Create Tables & Plots Functions**"
      ],
      "id": "sm4vbvlm-hsj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Names"
      ],
      "metadata": {
        "id": "Y7x2w8JT2a_D"
      },
      "id": "Y7x2w8JT2a_D"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Global Variables\n",
        "### Column Names\n",
        "Duration_Actual = \"Event Duration (s) [Actual Data]\"\n",
        "Duration_Custom = \"Event Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "Duration_Preset = \"Event Duration (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "Count_Actual = \"Event Count [Actual Data]\"\n",
        "Count_Custom = \"Event Count [Using Custom Settings - Theoretical Calculation]\"\n",
        "Count_Preset = \"Event Count (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "SumDuration_Actual = \"Cumulative Duration (s) [Actual Data]\"\n",
        "SumDuration_Custom = \"Cumulative Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "SumDuration_Preset = \"Cumulative Duration (s) [Using Preset Settings - Theoretical Calculation]\""
      ],
      "metadata": {
        "id": "CgzuYBvt8zNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca160e6-d9cc-44c4-959f-56f3dc223971"
      },
      "id": "CgzuYBvt8zNI",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.45 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Tables"
      ],
      "metadata": {
        "id": "mcXFuo902gfD"
      },
      "id": "mcXFuo902gfD"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vsIRg70SdobY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb6b92f-e1db-43bd-e6fc-1f1cc547b2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.54 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def createDataTables (data_path):\n",
        "    df_LOGs = compileLogFiles (data_path)\n",
        "\n",
        "    df_s, df_d = splitToDataAndSettingsDF (df_LOGs)\n",
        "    # os.chdir(analysis_path)\n",
        "    # df_d.to_csv (folder_name + \" - Data.xlsx\")\n",
        "\n",
        "    # df_s.to_csv (folder_name + \" - Settings.xlsx\")\n",
        "    # dataframe_to_pdf(df_s, folder_name + \" - Settings\")\n",
        "\n",
        "    df_d[\"Is_Valid_Data\"] = GetIsValidColumn(df_d);\n",
        "\n",
        "    df_j = pd.merge (df_d,df_s, on='Settings Index')\n",
        "    # df_j = AddNumActualStimulations(df_j)\n",
        "    # df_j = AnalyzeWithCustomThresholds (df_j)\n",
        "    # df_j = AnalyzeWithPresetThresholds (df_j)\n",
        "    return df_j, df_d, df_s"
      ],
      "id": "vsIRg70SdobY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Plots"
      ],
      "metadata": {
        "id": "qINEVzl52lDl"
      },
      "id": "qINEVzl52lDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createPlots (df_j):\n",
        "    df_j.dtypes\n",
        "    plotByDay (df_j)\n",
        "    plotByHour (df_j)\n",
        "    PlotApneaEventsGrid (df_j)"
      ],
      "metadata": {
        "id": "AGgoCri491oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef5774a-9223-4ed4-cd52-51de120e5de2"
      },
      "id": "AGgoCri491oc",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.13 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Summary Tables"
      ],
      "metadata": {
        "id": "N_4X5RS92tGl"
      },
      "id": "N_4X5RS92tGl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createSummaryTables (df,df_s):\n",
        "  \n",
        "  df_s_columns_dropped = df_s.drop(['Settings Date','Settings Time','Alarm intensity'], axis=1)\n",
        "  \n",
        "  reportApneaCountBySetting (df,df_s_columns_dropped)\n",
        "  reportIndividualActualApneas (df)"
      ],
      "metadata": {
        "id": "Ihvpi8G2ze28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f8a54f-1bde-4cfc-9934-9b4f34913e80"
      },
      "id": "Ihvpi8G2ze28",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.25 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Summary"
      ],
      "metadata": {
        "id": "c1_bNt0BWjOt"
      },
      "id": "c1_bNt0BWjOt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "spo2_list = [85, 80, 75, 70, 65]\n",
        "hr_list = [110, 100, 90, 80]\n",
        "spo2_col_time_name_list = []\n",
        "hr_col_time_name_list = []\n",
        "\n",
        "spo2_col_percent_name_list = []\n",
        "hr_col_percent_name_list = []\n",
        "\n",
        "for spo2 in spo2_list:\n",
        "    spo2_col_time_name_list.append(\"Time SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "    spo2_col_percent_name_list.append(\"% SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "for hr in hr_list:\n",
        "    hr_col_time_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "    hr_col_percent_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "        \n",
        "\n",
        "\n",
        "def createClinicalSummaryTable (df_j, record_name):\n",
        "    num_seconds_per_data_point = 1;\n",
        "    if (AB_Model == \"M1\"):\n",
        "        num_seconds_per_data_point = 2; # Tuhin's model M1 measured every 2 seconds. \n",
        "    # df_j[\"Is_Valid_Data\"] = GetIsValidColumn (df_j)\n",
        "    df_is_valid_data = df_j[df_j[\"Is_Valid_Data\"] == True]\n",
        "    df_clinical_summary = pd.DataFrame ()\n",
        "    df_clinical_summary [\"Name\"] = [record_name]\n",
        "    df_clinical_summary [\"Time ApneBoot System Was On (hrs)\"] = round (len(df_j.index) / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"Time with valid vital and status readings (hrs)\"] = round (df_j[\"Is_Valid_Data\"].sum()/60/60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"SPO2 - Avg\"] = round (df_is_valid_data['SPO2'].mean(),1)\n",
        "    df_clinical_summary [\"SPO2 - Std\"] = round (df_is_valid_data['SPO2'].std(),2)\n",
        "    df_clinical_summary [\"HR - Avg\"] = round (df_is_valid_data['HR'].mean(),1)\n",
        "    df_clinical_summary [\"HR - Std\"] = round (df_is_valid_data['HR'].std(),2)\n",
        "    df_clinical_summary ['Num Events (Preset Threshold)'] = countApneas (df_is_valid_data[Duration_Preset])\n",
        "    df_clinical_summary ['Cumulative Event Duration (Preset Threshold)'] = sumApneaTime (df_is_valid_data[Duration_Preset])\n",
        "    \n",
        "    for spo2 in spo2_list:\n",
        "        # spo2_col_time_name_list.append([\"Time SPO2 < \"+str(spo2)+\" (hrs)\"])\n",
        "        # spo2_col_percent_name_list = spo2_col_percent_name_list.append(\"% SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "        \n",
        "        df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"] = round(df_is_valid_data.query ('SPO2 < '+str(spo2))['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "        df_clinical_summary [\"% SPO2 < \"+str(spo2)+\" (hrs)\"] = round(df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "    # df_clinical_summary [\"Time SPO2 < 85 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 85')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 80 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 80')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 75 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 75')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 70 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 70')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 65 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 65')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "\n",
        "    for hr in hr_list:\n",
        "        # hr_col_time_name_list.append([\"Time HR < \"+str(spo2)+\" (hrs)\"])\n",
        "        # hr_col_percent_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "        df_clinical_summary [\"Time HR < \"+str(spo2)+\" (hrs)\"] = round(df_is_valid_data.query ('HR < '+str(hr))['HR'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "        df_clinical_summary [\"% HR < \"+str(spo2)+\" (hrs)\"] = round(df_clinical_summary [\"Time HR < \"+str(spo2)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "\n",
        "    return df_clinical_summary\n",
        "#   df_s.insert(loc = 3, column=\"Preset mode\", value = 1)"
      ],
      "metadata": {
        "id": "uRiSHGwMw5XT"
      },
      "id": "uRiSHGwMw5XT",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "R0eILh2iyWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae44549-bf8d-419c-b34d-c61713be0629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 547 µs (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_j stands for df_joined\n",
        "# display (df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"] !=0])\n",
        "#df[\"Time (hours)\"]={len(df)*1/60/60)\n",
        "# df_j.to_csv (folder_name + \" All_Data_Joined_Table.csv\")\n",
        "# df_s.to_csv (folder_name + \" Settings_Index_Table.csv\")"
      ],
      "id": "R0eILh2iyWqc"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# display(df_j[df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]!= df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]])\n",
        "# display(df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"]==0])"
      ],
      "metadata": {
        "id": "k7sHLvRYA10J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0c7913-17ee-4de8-e71d-a7579b27bcfb"
      },
      "id": "k7sHLvRYA10J",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 565 µs (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkSqcl_eQfV_",
        "outputId": "fefe2927-8b8d-4dab-b432-8e8c2e9a0274"
      },
      "id": "YkSqcl_eQfV_",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14 ms (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aCjiZ7l3Qfyv"
      },
      "id": "aCjiZ7l3Qfyv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main FOR LOOP Code**\n",
        "\n"
      ],
      "metadata": {
        "id": "Nniyp_1baQUg"
      },
      "id": "Nniyp_1baQUg"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# folder_name = \"Geetha\"\n",
        "startpath = \"\" \n",
        "analysis_path = \"\"\n",
        "analysis_folder = \"\"\n",
        "\n",
        "Data_Cleanup_SP02_LowCutOff = 50  #If the SPO2 value at the time of APnea is below 60, it must be a bad data point. \n",
        "Data_Cleanup_HR_LowCutOff = 50\n",
        "\n",
        "\n",
        "def main_function ():\n",
        "    global startpath\n",
        "    global analysis_path\n",
        "    global analysis_folder\n",
        "    startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai\"\n",
        "\n",
        "    time = pd.Timestamp.now(tz=None)\n",
        "    import traceback\n",
        "\n",
        "    AB_Model = \" \"\n",
        "\n",
        "    paths, folder_names = list_folders(startpath)\n",
        "    print (paths)\n",
        "    print (folder_names)\n",
        "\n",
        "    PRINT_TABLES = False\n",
        "    SAVE_DFJ = False\n",
        "    READ_SAVED_DFJ = True\n",
        "\n",
        "    os.chdir(startpath)\n",
        "    # os.makedirs(str(time) + \" - Analysis_Files\", exist_ok=True)\n",
        "    # analysis_path = startpath + \"/\" + str(time) + \" - Analysis_Files\"\n",
        "\n",
        "    os.makedirs(\"Analysis_Files\", exist_ok=True)\n",
        "    analysis_path = startpath + \"/\" + \"Analysis_Files\"\n",
        "\n",
        "    os.chdir(analysis_path)\n",
        "    # errors = pd.DataFrame (columns = ['Folder Name',\"Model\",'Exception', \"filename\", \"lineno\", \"funcname\", \"text\"])\n",
        "    errors = pd.DataFrame ()\n",
        "    df_overall_clinical_summary = pd.DataFrame ()\n",
        "    df_overall_clinical_summary_detailed = pd.DataFrame ()\n",
        "\n",
        "    i = 0;\n",
        "    for path in paths:\n",
        "        folder_name = folder_names[i]\n",
        "        i += 1\n",
        "        print (\"on file \" + str(i) + ' of ' + str(len(paths)))\n",
        "        try:\n",
        "            print (\"Working on \" + folder_name)\n",
        "            \n",
        "            os.chdir(analysis_path)\n",
        "            analysis_folder = \"Analysis - \" + folder_name\n",
        "            \n",
        "            os.makedirs(analysis_folder, exist_ok=True)\n",
        "            current_analysis_folder_path = analysis_path+ '/' + analysis_folder\n",
        "            \n",
        "            os.chdir(current_analysis_folder_path)\n",
        "\n",
        "            # This code to save future time in creating df_j masterfile\n",
        "            if (READ_SAVED_DFJ == False):\n",
        "                df_j, df_d, df_s = createDataTables (path)\n",
        "            else:\n",
        "                os.chdir(current_analysis_folder_path)\n",
        "                # print (current_analysis_folder_path)\n",
        "                print (os.getcwd)\n",
        "                print ('files:')\n",
        "                print (os.listdir() )\n",
        "                df_j = pd.read_csv(folder_name + ' - df_j.csv')\n",
        "                # display(df_j)\n",
        "                # print (df_j.dtypes)\n",
        "\n",
        "                df_j['Settings Date-Time'] = getDateTimeColumn (df_j[[\"Settings Date-Time\"]])\n",
        "                df_j['Data Date-Time'] = getDateTimeColumn (df_j[[\"Data Date-Time\"]])\n",
        "\n",
        "            \n",
        "            if (SAVE_DFJ == True):\n",
        "                os.chdir(current_analysis_folder_path)\n",
        "                \n",
        "                df_j.to_csv (folder_name + ' - df_j.csv')\n",
        "\n",
        "            # print (\"df_j - main\")\n",
        "            # display (df_j)\n",
        "            AnalyzeWithPresetThresholds (df_j)\n",
        "            createPlots (df_j)\n",
        "            # createSummaryTables (df_j,df_s)\n",
        "            #####\n",
        "            \n",
        "            df_current_clinical_summary = pd.DataFrame ()\n",
        "            df_current_clinical_summary = createClinicalSummaryTable (df_j, folder_name)\n",
        "            df_current_clinical_summary[\"path\"] = path[-100:]\n",
        "            df_overall_clinical_summary = pd.concat([df_overall_clinical_summary, df_current_clinical_summary])\n",
        "            os.chdir(analysis_path)\n",
        "            \n",
        "            \n",
        "            #####\n",
        "            df_current_clinical_summary_detailed = df_current_clinical_summary\n",
        "            # df_current_clinical_summary_detailed[\"file_list\"] = file_list\n",
        "            df_current_clinical_summary_detailed[\"model\"] = AB_Model;\n",
        "            df_current_clinical_summary_detailed[\"data date-time\"] = df_j[\"Data Date-Time\"].iloc[0];\n",
        "            df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "\n",
        "            print (folder_name + \" success!\")\n",
        "\n",
        "        except Exception as exc: \n",
        "            print (\"ERROR FOR \" + folder_name + \":\")\n",
        "            filename, lineno, funcname, text = traceback.extract_tb(exc.__traceback__)[-1]\n",
        "            print (exc)\n",
        "            short_path = path[-100:]\n",
        "            current_error = pd.DataFrame (data = {'short_path': [short_path], 'Folder Name':[folder_name], \"Model\": [AB_Model], 'Exception':[exc], \"filename\": [filename], \"lineno\": [lineno], \"funcname\": [funcname], \"text\": [text], 'data header': [header], 'settings header': [settings_header], 'numcommas':[number_of_commas]})\n",
        "            errors = errors.append (current_error,ignore_index = True);\n",
        "            os.chdir(analysis_path)\n",
        "            errors.to_excel (\"Error Summary.xlsx\")\n",
        "        \n",
        "        break\n",
        "\n",
        "    df_overall_clinical_summary.to_excel (\"Overall Clinical Summary.xlsx\")\n",
        "    df_overall_clinical_summary_detailed.to_excel (\"Overall Clinical Summary - Detailed.xlsx\")\n",
        "    print (\"errors table:\")\n",
        "    display (errors)\n",
        "        \n",
        "main_function()\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "RtVUyZ_9ZcLO"
      },
      "id": "RtVUyZ_9ZcLO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clinical Analysis**"
      ],
      "metadata": {
        "id": "GXKhxms5QiML"
      },
      "id": "GXKhxms5QiML"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Match Table"
      ],
      "metadata": {
        "id": "PZ_oJn6SQmSJ"
      },
      "id": "PZ_oJn6SQmSJ"
    },
    {
      "cell_type": "code",
      "source": [
        "### Match Table\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "clinical_fn = \"Overall Clinical Summary - Detailed.xlsx\"\n",
        "# createClinicalSummaryTable()\n",
        "os.chdir(startpath)\n",
        "df_lookup = pd.read_csv(lookup_fn)\n",
        "os.chdir(analysis_path)\n",
        "df_clinical = pd.read_excel(clinical_fn)\n",
        "\n",
        "df_match = df_lookup.set_index('shortpath').join(df_clinical.set_index('path'))\n",
        "columns_to_keep = [\n",
        "# \"Order\",\n",
        "\"Unnamed: 1\",\n",
        "\"Baby of\",\n",
        "\"Start date of enrollment\",\n",
        "\"End date of enrollment\",\n",
        "\"Device_type\",\n",
        "\"Number of days of enrollment\",\n",
        "\"Birth weight (grams)\",\n",
        "\"GA\",\n",
        "\"Sub-Group\",\n",
        "# \"Total hypoxia duration (in secs)\",\n",
        "# \"Total hypoxia duration (in hh:mm:ss)\",\n",
        "\"Ventilation\",\n",
        "# \"86,400\",\n",
        "# \"Time Enrolled (S)\",\n",
        "# \"#Seconds in a day\",\n",
        "# \"% seconds in Hypoxia\",\n",
        "# \"Notes\",\n",
        "# \"Notes 2\",\n",
        "# \"Unnamed: 0\",\n",
        "# \"Name\",\n",
        "\"Time ApneBoot System Was On (hrs)\",\n",
        "\"Time with valid vital and status readings (hrs)\",\n",
        "\"SPO2 - Avg\",\n",
        "\"SPO2 - Std\",\n",
        "\"HR - Avg\",\n",
        "\"HR - Std\",\n",
        "\"model\",\n",
        "# \"data date-time\",\n",
        "]\n",
        "\n",
        "columns_to_keep = columns_to_keep + spo2_col_time_name_list + hr_col_time_name_list + spo2_col_percent_name_list + hr_col_percent_name_list\n",
        "print (columns_to_keep)\n",
        "df_match = df_match [columns_to_keep]\n",
        "for col in spo2_col_time_name_list:\n",
        "    df_match ['% ' + col] = df_match[col] / df_match [\"Time with valid vital and status readings (hrs)\"]\n",
        "display (df_match)\n",
        "\n",
        "\n",
        "df_match.to_excel (\"4 - Matched Table Summary.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7SYrEoQoApav",
        "outputId": "df4fa84a-8719-4318-b015-9422fd0ab4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "id": "7SYrEoQoApav",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-87c44b809954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_clinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclinical_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.43 s (started: 2023-03-23 11:40:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "Bd1xogoaB6F_"
      },
      "id": "Bd1xogoaB6F_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Plots"
      ],
      "metadata": {
        "id": "mOMYLLGgQ2pK"
      },
      "id": "mOMYLLGgQ2pK"
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "plot_opts = {\n",
        "    \"cutoff_val\": 5,\n",
        "    \"cutoff_type\": \"abs\",\n",
        "    \"label_fontsize\": \"small\",\n",
        "    \"label_rotation\": 30,\n",
        "}\n",
        "\n",
        "# exclude certain babies\n",
        "df_match = df_match[df_match['Baby of']!= 'Ramanamma']\n",
        "Manjula\n",
        "Shwetha 2\n",
        "Noor Fathima T-1\n",
        "\n",
        "#  display (df_match)\n",
        "df_melt = df_match.melt (id_vars = ['Device_type'],value_vars= spo2_col_percent_name_list, var_name = 'Group', value_name = 'SPO2 Level')\n",
        "# display (df_melt)\n",
        "# fig = plt.figure(10,10)\n",
        "# ax = fig.add_subplot(111)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.boxplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "# sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
        "sns.catplot(data=df_melt, col = 'SPO2 Level', x = 'Group', y = 'SPO2 Level', hue = 'Device_type', aspect=.5, ax = ax2)\n",
        "\n",
        "for col in spo2_col_percent_name_list:\n",
        "    df = df_match\n",
        "    placebo = df[df['Device_type']=='Placebo']\n",
        "    intervention = df[df['Device_type']=='Intervention']\n",
        "    print (\"col: \" + col)\n",
        "    print(ttest_ind(placebo[col], intervention[col]))\n",
        "\n",
        "#perform independent two sample t-test\n",
        "\n",
        "# sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', color = 'red')\n",
        "# sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# df_beanplot = pd.DataFrame ()\n",
        "# df_beanplot ['Baby of'] = df_match['Baby of']\n",
        "# # df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'][df_match['Device_type'] == 'Intervention']\n",
        "# df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Intervention')\n",
        "# df_beanplot['Placebo'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Placebo')\n",
        "# # plt.boxplot(df_match['Time SPO2 < 85(hrs)'])\n",
        "# # display (df_beanplot)\n",
        "# df_intervention = pd.DataFrame ()\n",
        "# df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "# # df_intervention['Intervention'] = df_beanplot['Intervention'].dropna();\n",
        "# # df_intervention = df_intervention.dropna ()\n",
        "# # df_placebo = pd.DataFrame ()\n",
        "# # df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "# # df_intervention = df_intervention.dropna ()\n",
        "# # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "# # sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "# display (df_match)\n",
        "# df_stack = df_match.stack()\n",
        "# display (df_stack)\n",
        "# # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "\n",
        "# # df_intervention = df_intervention [df_intervention['Intervention'].]\n",
        "# # display (df_intervention)\n",
        "# # plt.boxplot(df_intervention['Intervention'])\n",
        "\n",
        "# # plt.show()\n",
        "# # display (df_beanplot)\n",
        "# # data = sm.load_pandas()\n",
        "# # data = sm.load()\n",
        "\n",
        "# # sm.graphics.beanplot (df_beanplot., ax=ax, labels = ['Intervention', 'Placebo'], plot_opts=plot_opts)\n",
        "\n",
        "# # sm.graphics.beanplot(age, ax=ax, labels=labels, plot_opts=plot_opts)\n"
      ],
      "metadata": {
        "id": "hq6gb8jmW4af"
      },
      "id": "hq6gb8jmW4af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Calc Stats"
      ],
      "metadata": {
        "id": "ClRUJ1FstCgD"
      },
      "id": "ClRUJ1FstCgD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4fmuhFuf5k"
      },
      "source": [
        "# DRAFT - New Section"
      ],
      "id": "5E4fmuhFuf5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdo3Bol12w2"
      },
      "source": [
        "## ** Not Used Code**"
      ],
      "id": "Ntdo3Bol12w2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Send an unformatted clinical data column and returns a date-time column\n",
        "def getDateTimeColumn (df):\n",
        "    # df = pd.DataFrame(columns= ['Date-Time'], data = \n",
        "    # [\"27-06-2019  22:39:32\",\n",
        "    # \"16/07/19 08:47:45\",\n",
        "    # \"10/6/2019   19:54:9\",\n",
        "    # \"10/6/2019   17:25:12\",\n",
        "    # \"22-02-2019  19:4:23\",\n",
        "    # \"14/6/2019   12:52:23\",\n",
        "    # \"6/12/2019  19:35:57\",\n",
        "    # \"14/07/19 10:06:52\",\n",
        "    # \"7/2/19  14:4:5\",\n",
        "    # \"7/2/19  13:55:22\",\n",
        "    # \"03/12/14 00:34:45\",\n",
        "    # \"24/1/2019   10:45:34\",\n",
        "    # \"18/11/14 00:59:22\",\n",
        "    # \"14/6/2019   15:25:0\",\n",
        "    # \"10/07/19 16:33:05\",\n",
        "    # \"1/3/2019   16:2:4\",\n",
        "    # \"20/08/19 13:27:00\",\n",
        "    # \"12/6/2019   21:23:14\",\n",
        "    # \"28/5/2019   16:38:52\",\n",
        "    # \"10/07/19 16:33:05\",\n",
        "    # \"2/5/2019   18:7:29\",\n",
        "    # \"23/08/19 21:47:43\",\n",
        "    # \"21/11/14 23:49:28\",\n",
        "    # \"12/6/2019   21:23:14\",\n",
        "    # \"30/4/2019   16:29:54\",\n",
        "    # \"28/5/2019   16:38:52\",\n",
        "    # \"29/5/2019   22:58:28\",\n",
        "    # \"2/5/2019   18:7:29\",\n",
        "    # \"20/08/20 14:51:03\",\n",
        "    # \"20/08/20 14:51:03\",\n",
        "    # \"13/07/20 14:05:40\",\n",
        "    # \"03/09/20 11:52:01\",\n",
        "    # \"06/10/20 13:42:55\",\n",
        "    # \"14/09/20 17:05:47\",\n",
        "    # \"01/09/20 15:20:48\",\n",
        "    # \"14/08/20 16:27:39\",\n",
        "    # \"30/06/20 11:38:01\",\n",
        "    # \"15/07/20 17:00:25\",\n",
        "    # \"30/06/20 11:38:01\",\n",
        "    # \"26/08/19 14:31:54\",\n",
        "    # \"05/09/19 15:33:30\",\n",
        "    # \"01/10/19 12:08:48\",\n",
        "    # \"21/10/19 12:05:24\",\n",
        "    # \"27/08/19 23:04:48\",\n",
        "    # \"06/08/19 17:13:52\",\n",
        "    # \"07/12/19 18:00:55\",\n",
        "    # \"24/10/19 16:08:16\",\n",
        "    # \"23/11/19 11:52:06\",\n",
        "    # \"25/11/19 12:49:49\",\n",
        "    # \"23/09/19 16:39:59\",\n",
        "    # \"20/08/19 12:31:40\",\n",
        "    # \"29/08/19 13:59:22\",\n",
        "    # \"31/08/19 12:25:32\",\n",
        "    # \"06/11/19 13:55:39\",\n",
        "    # \"30/12/19 13:47:37\"])\n",
        "    print (\"just df1\")\n",
        "    display (df)\n",
        "    df2 = pd.DataFrame ()\n",
        "    # df[\"Date-Time\"] = df[\"Date-Time\"].str.replace('/',' ', n = 1)\n",
        "    df[df. columns[0]] = df[df. columns[0]].str.replace('/',' ').str.replace('-',' ').str.replace(':',' ')\n",
        "    # df[\"Date-Time\"] = df[\"Date-Time\"].str.replace('/',' ').str.replace('-',' ').str.replace(':',' ')\n",
        "    # .str.split(\" \", n = 1, expand = True)\n",
        "    print (\"just df2\")\n",
        "    display (df)\n",
        "    df[['Day','Month','Year','Hour','Minute','Second']] = df[df. columns[0]].str.split(expand = True)\n",
        "    df = df.drop([df. columns[0]], axis=1)\n",
        "    df=df.astype(int)\n",
        "    # df['Year'] = df[df['Year']<2000] \n",
        "    df['Year'].where(df[\"Year\"] > 2000, other = df[\"Year\"] + 2000, inplace = True)\n",
        "    print (\"just df3\")\n",
        "    display (df)\n",
        "    df2['Datetime'] = pd.to_datetime(df[['Day','Month','Year','Hour','Minute','Second']])\n",
        "    print (\"just df2 1 \")\n",
        "    display (df2)\n",
        "    return df2\n",
        "\n",
        "# dftest = pd.DataFrame ()\n",
        "# getDateTimeColumn (dftest)"
      ],
      "metadata": {
        "id": "zPPshOYtN8Aq",
        "outputId": "d0273fe0-9314-4fed-f890-ae0bad0998d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zPPshOYtN8Aq",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.14 ms (started: 2023-03-23 13:49:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #fname = \"Report.pdf\"\n",
        "# with PdfPages(fname) as pdf:\n",
        "#   print(\"This is a test of the print function\")\n",
        "#   pdf.savefig()"
      ],
      "metadata": {
        "id": "0EU2cARS1Lsy"
      },
      "id": "0EU2cARS1Lsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# usage_pv_data_table = pd.pivot_table(data_table, index =['Data Date',\"Settings Index\"],\n",
        "#                          aggfunc = 'count')\n",
        "\n",
        "# print(usage_pv_data_table)\n",
        "# usage_pv_data_table.to_csv('Usage_pv_data_table.csv',index=True)\n",
        "# usage_pv_data_table.to_excel(\"Usage_pv_data_table.xlsx\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJ1x3Bq8bbc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pd.reset_option(\"all\")\n",
        "#df = stimulation_results_table_with_all_thresholds\n",
        "#print(df)\n",
        "#pivot = pd.pivot_table(stimulation_results_table_with_all_thresholds,\n",
        "                       #values=[\"Status\"], \n",
        "#                       index=['Status'])\n",
        "                       #aggfunc={'Status': np.count,\n",
        "                       # 'HR': [min, max, np.mean]})\n",
        "\n",
        "#df = df.Status.value_counts()\n",
        "#print(pivot)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "# pd.set_option(\"precision\", 4)\n",
        "\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#print(len (stimulation_results_table_with_all_thresholds))\n",
        "#filtered_results_table_all = df[(df[\"Status\"]==129) | (df[\"Status\"]==131)]\n",
        "#print(len (filtered_results_table_all))\n",
        "\n",
        "#data_table = filtered_results_table_all\n",
        "\n",
        "# pivot = pd.pivot_table(data_table,\n",
        "#                        values=['SPO2','HR'], \n",
        "#                        index=['Data Date'],\n",
        "#                        aggfunc={'SPO2': np.mean,\n",
        "#                         'HR': [min, max, np.mean]})\n",
        "\n",
        "#print(pivot)\n",
        "#filtered_results_table_all.to_csv(\"Filtered_Results_Table_All.csv\")\n",
        "\n",
        "# 129    91112\n",
        "# 153    49477\n",
        "# 131    32220\n"
      ],
      "id": "WYJ1x3Bq8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBwS6cI9JH6"
      },
      "source": [
        "\n",
        "Want \n",
        "- Date\n",
        "- Setting Index\n",
        "- \n",
        "\n"
      ],
      "id": "qlBwS6cI9JH6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # !sudo apt-get install wkhtmltopdf\n",
        "# # !yum install wkhtmltopdf\n",
        "# !apt-get install wkhtmltopdf\n",
        "# import pandas as pd \n",
        "# df_apnea_summary_table.to_html('HTMLTest.html')  \n",
        "\n",
        "# import pdfkit \n",
        "\n",
        "# pdfkit.from_url('HTMLTest.html', 'HTMLTest.pdf')"
      ],
      "metadata": {
        "id": "k08O7_OMVpRX"
      },
      "id": "k08O7_OMVpRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df = pd.DataFrame({'Col': [1,4,5,6,7],\n",
        "                   'Col2': [1,4,5,6,7],\n",
        "                   })\n",
        "display (df)\n",
        "New_Col = \"Col3\"\n",
        "df [New_Col] = df[\"Col\"] +1\n",
        "\n",
        "display (df)\n",
        "display (df[New_Col])"
      ],
      "metadata": {
        "id": "1gwuIXkd74XG"
      },
      "id": "1gwuIXkd74XG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Create a pandas dataframe with demo data:\n",
        "#!pip install -e git+https://github.com/mindee/doctr.git#egg=python-doctr[torch]\n",
        "#!pip install weasyprint\n",
        "!pip install django-weasyprint\n",
        "import pandas as pd\n",
        "demodata_csv = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
        "df = pd.read_csv(demodata_csv)\n",
        "\n",
        "def dfToPDF (df):\n",
        "  # Pretty print the dataframe as an html table to a file\n",
        "  intermediate_html = '/tmp/intermediate.html'\n",
        "  to_html_pretty(df,intermediate_html,'Iris Data')\n",
        "  # if you do not want pretty printing, just use pandas:\n",
        "  # df.to_html(intermediate_html)\n",
        "\n",
        "  # Convert the html file to a pdf file using weasyprint\n",
        "  import weasyprint\n",
        "  out_pdf= '/tmp/demo.pdf'\n",
        "  weasyprint.HTML(intermediate_html).write_pdf(out_pdf)\n",
        "\n",
        "  # This is the table pretty printer used above:\n",
        "\n",
        "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
        "    '''\n",
        "    Write an entire dataframe to an HTML file\n",
        "    with nice formatting.\n",
        "    Thanks to @stackoverflowuser2010 for the\n",
        "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
        "    '''\n",
        "    ht = ''\n",
        "    if title != '':\n",
        "        ht += '<h2> %s </h2>\\n' % title\n",
        "    ht += df.to_html(classes='wide', escape=False)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)\n",
        "\n",
        "HTML_TEMPLATE1 = '''\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "  h2 {\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "  }\n",
        "  table { \n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "  }\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "    font-size: 90%;\n",
        "  }\n",
        "  table tbody tr:hover {\n",
        "    background-color: #dddddd;\n",
        "  }\n",
        "  .wide {\n",
        "    width: 90%; \n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "'''\n",
        "\n",
        "HTML_TEMPLATE2 = '''\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "_4nxBzcnuBex"
      },
      "id": "_4nxBzcnuBex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # PRINT TABLES & DATA\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# #https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
        "# #df_apnea_summary_table.plot()\n",
        "# #dfToPDF (df)\n",
        "# # fig = convertDataframeToFigure (apnea_summary_table)\n",
        "# # pdf = PdfPages(\"foo.pdf\")\n",
        "# # pdf.savefig(fig, bbox_inches='tight')\n",
        "# # pdf.close()\n",
        "# # !pip install -c conda-forge python-pdfkit\n",
        "# !pip3 install wkhtmltopdf\n",
        "# !pip3 install pdfkit\n",
        "\n",
        "# import pandas as pd\n",
        "# import pdfkit as pdf\n",
        "# import sqlite3\n",
        "\n",
        "# # con=sqlite3.connect(\"baza.db\")\n",
        "\n",
        "# # df=pd.read_sql_query(\"select * from dobit\", con)\n",
        "# #df_apnea_summary_table.datetime = pd.to_datetime(apnea_summary_table.datetime)\n",
        "# display(df_apnea_summary_table)\n",
        "\n",
        "# df_apnea_summary_table.to_html('apnea_summary_table.html')\n",
        "# nazivFajla='test.pdf'\n",
        "# config = pdf.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "# pdf.from_url('apnea_summary_table.html', nazivFajla, configuration=config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kb94aQAehXxh"
      },
      "id": "Kb94aQAehXxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "os.chdir(startpath)\n",
        "file_name = '12log5 - made from mona xls file.csv'\n",
        "file_name = 'Book2.csv'\n",
        "df = pd.read_csv(file_name, header=None)"
      ],
      "metadata": {
        "id": "Qmiv2ryWUynD"
      },
      "id": "Qmiv2ryWUynD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "3FuNu9FnVX5F"
      },
      "id": "3FuNu9FnVX5F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTpOGQud6Max",
        "7VpeZHhf7O2V",
        "T3dPG9_2xoX3",
        "c9pqOw4FnVYA",
        "Ff704C-MwEsw",
        "4C39qoDxEcnt",
        "vFvsiREGpJ-8",
        "1uadoNfrjZUt",
        "bHJA2jljjdc-",
        "eoiLSOJ3jfmj",
        "kPbeaF7WOonR",
        "Y7x2w8JT2a_D",
        "qINEVzl52lDl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}