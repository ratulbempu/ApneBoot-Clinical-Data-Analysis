{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulbempu/ApneBoot-Clinical-Data-Analysis/blob/main/230301%20-%20AB%20Clinical%20Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-07-23 - I updated it so it loads logs and creates df_s and df_d faster. Also includes Log Source File. Works for Zug, need to check for nonin. \n",
        "Actual and Preset are slightly different because:\n",
        "- Preset mode number shows up at the start of the apnea, Stim shows at start of stim +1 (instead of 5s it looks like 6 sec+1. This may be a rounding issue. Would be nice if they were on the same line but ok. \n",
        "- This rounding issue may also cause different apnea stimulation lengths by a second or two.\n",
        "\n",
        "\n",
        "22-09-03 - \n",
        "- Added code to convert table to pdf\n",
        "\n",
        "22-09-10 -\n",
        "- Fix Smoothing Issue\n",
        "- Add Thresholds \n",
        "\n",
        "22-19-18\n",
        "Todo:\n",
        "- X make individual plots ouput to pdf\n",
        "- X - Good Enough - make summary table cleaner\n",
        "  - reduce number of columns\n",
        "  - increase overall font size\n",
        "- X test with custom thresholds\n",
        "- test and fix for nonin\n",
        "- combine relevent pdfs into a report.\n",
        "- test with Clinical Data\n",
        "\n",
        "23-03-01\n",
        "- want table with name, total time monitored, total time below X condition calculated), total stimulations, total stimulation time, total time under Y condition, total errorenous data. \n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "COmxc45t43_s"
      },
      "id": "COmxc45t43_s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2P7Ld8v0Zf"
      },
      "source": [
        "## **Initialize**"
      ],
      "id": "VY2P7Ld8v0Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Folder Name"
      ],
      "metadata": {
        "id": "s14DGNWX59Me"
      },
      "id": "s14DGNWX59Me"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Find Folders"
      ],
      "metadata": {
        "id": "KR-D_OFUQ4mK"
      },
      "id": "KR-D_OFUQ4mK"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "outputId": "5ec3d501-f03c-4c14-d4e4-33cdbdadc506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n432-4cQ4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "Imports done\n",
            "time: 3.14 ms (started: 2023-03-14 08:52:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import fileinput\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "import linecache\n",
        "from pathlib import Path\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "print (\"Imports done\")"
      ],
      "id": "6n432-4cQ4mR"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "outputId": "24bda5ce-782b-4f5a-d4c1-e8de8ce93d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-ikFo4Q4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 45.1 s (started: 2023-03-14 08:52:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "aF-ikFo4Q4mR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Folders List"
      ],
      "metadata": {
        "id": "wu1Ny53mRFbR"
      },
      "id": "wu1Ny53mRFbR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "def list_folders(startpath):\n",
        "    list_path = []\n",
        "    list_folder = []\n",
        "    log = \"log\"\n",
        "    LOG = \"LOG\"\n",
        "    is_data_dir = 0;\n",
        "    previous_name_path = \"\"\n",
        "    for root, subdirs, files in os.walk(startpath):\n",
        "        is_data_dir = 0\n",
        "        for filename in files:\n",
        "            current_name_path = os.path.join(root)\n",
        "            if ((log in filename) | (LOG in filename)) & (previous_name_path != current_name_path):\n",
        "                full_path = os.path.join(root,filename)\n",
        "                list_folder.insert (0, os.path.basename (current_name_path))\n",
        "                list_path.insert(0, root)\n",
        "                previous_name_path = current_name_path\n",
        "\n",
        "    return list_path, list_folder\n"
      ],
      "metadata": {
        "id": "z6m2mfEt8Smu",
        "outputId": "552b2e63-4ca1-40fd-f6da-9c737d2ed615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z6m2mfEt8Smu",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.78 ms (started: 2023-03-14 08:53:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Initialize Folders"
      ],
      "metadata": {
        "id": "PTpOGQud6Max"
      },
      "id": "PTpOGQud6Max"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQuN0Iql7AUK"
      },
      "source": [
        "## **Convert Files to Data Frames**"
      ],
      "id": "LQuN0Iql7AUK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers for Different Logger Versions"
      ],
      "metadata": {
        "id": "7VpeZHhf7O2V"
      },
      "id": "7VpeZHhf7O2V"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "header = \"\"\n",
        "settings_header = \"\" \n",
        "AB_Model = \"default_string\"\n",
        "number_of_commas = 0\n",
        "\n",
        "\n",
        "def decideDataLoggerVersion (df):\n",
        "  # Read the third line's header and decide which data logger version is used\n",
        "  # Assumes that the third line is unique for each data logger version\n",
        "  # I need to check with Sourabh if the third line correlates with versions for the St. John's studies.\n",
        "  global header\n",
        "  global settings_header\n",
        "  global AB_Model\n",
        "  global number_of_commas\n",
        "  \n",
        "  raw_logfile_data_table_headers = [\"default\"]\n",
        "  settings_table_headers = [\"\"]\n",
        "  data_table_headers = [\"\"]\n",
        "  settings_columns_rename_dict = [\"\"]\n",
        "  settings_columns_to_drop = [\"\"]\n",
        "  version = \"unknown data code version\"\n",
        "\n",
        "  ZUG_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,PI,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Battery voltage;\"\n",
        "  NONIN_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\"\n",
        "  CLINICAL_SETTINGS_HEADER_INTERVENTION = \"dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\"\n",
        "  CLINICAL_SETTINGS_HEADER_PLACEBO = \"dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\"\n",
        "\n",
        "  settings_header = df.iat[0,0]\n",
        "  header = df.iat[2,0]\n",
        "  number_of_commas = header.count (',')\n",
        "  print (settings_header)\n",
        "  print (header)\n",
        "\n",
        "  if header == ZUG_DATA_HEADER:\n",
        "    version = \"ZUG Circa April 2022\"\n",
        "    # print (\"Detected Zug\")\n",
        "  elif (header == NONIN_DATA_HEADER):\n",
        "      if (settings_header == CLINICAL_SETTINGS_HEADER_INTERVENTION):\n",
        "          version = \"Clinical M3-Intervention (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Intervention\"\n",
        "      elif (settings_header == CLINICAL_SETTINGS_HEADER_PLACEBO):\n",
        "          version = \"Clinical M3-Placebo (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Placebo\"\n",
        "      else:\n",
        "          version = \"NONIN Circa April 2022\"\n",
        "    # print (\"Detected Nonin\")\n",
        "  elif number_of_commas == 5:\n",
        "      version = \"Clinical M1 (Nonin, Tuhin) 2019\"\n",
        "      AB_Model = \"M1\"\n",
        "  elif number_of_commas == 9:\n",
        "      version = \"Clinical M2 (Nonin, Satish) 2019\"\n",
        "      AB_Model = \"M2\"\n",
        "  else:\n",
        "    print (\"Not able to Detect Nonin Nor Zug\")\n",
        "    AB_Model = \"Unable to detect AB Model\"\n",
        "  \n",
        "  print (version)\n",
        "\n",
        "  if version == \"ZUG Circa April 2022\":\n",
        "    AB_Model = \"ZUG Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "            \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "                \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",   \n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Data Date-Time\": 'datetime64[ns]',\n",
        "                \"Data Date\": 'datetime64[ns]',\n",
        "                \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "                \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float\n",
        "                #,\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Settings Date-Time\": str,\n",
        "                \"Settings Date\": str,\n",
        "                'Settings Time':str,\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str}\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"PI\":\"HR Threshold\",\n",
        "            \"Status\":\"AND/OR\",\n",
        "            \"Pulse-ox mode\":\"Duration\",\n",
        "            \"Threshold Met\":\"Stimulator Intensity\",\n",
        "            \"Stimulator Error\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    \n",
        "    settings_columns_to_drop = [\"Stimulator ON/OFF\",\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\"]\n",
        "\n",
        "  if version == \"NONIN Circa April 2022\":\n",
        "    AB_Model = \"NONIN Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"Status\":\"HR Threshold\",\n",
        "            \"Pulse-ox mode\":\"AND/OR\",\n",
        "            \"Threshold Met\":\"Duration\",\n",
        "            \"Stimulator Error\":\"Stimulator Intensity\",\n",
        "            \"Stimulator ON/OFF\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "  if version == \"Clinical M1 (Nonin, Tuhin) 2019\":\n",
        "\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"Status\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [    \n",
        "                    \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",        \n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "  if version == \"Clinical M2 (Nonin, Satish) 2019\":\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Status\",\n",
        "            \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Unused Column 4\",\n",
        "             # <-- need to double check which column is stim off/on\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [            \n",
        "        \"HR\",\t\"SPO2\",\t\"Status\",\"Stimulator ON/OFF\",\n",
        "        \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Unused Column 4\",\n",
        "            ]\n",
        "\n",
        "################ M3 ###########\n",
        "  if ((version == \"Clinical M3-Intervention (Nonin) 2019\") | (version == \"Clinical M3-Placebo (Nonin) 2019\")):\n",
        "  \n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    ## Settings rename dictionary is different \n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Intervention or Placebo\", \n",
        "            \"HR\" : \"Stimulator Intensity\",\n",
        "            \"Status\":\"Alarm intensity\",\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "\n",
        "  return raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict"
      ],
      "metadata": {
        "id": "-OMUDW4FZpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9a8d15-4703-4d19-94e0-baa43d062651"
      },
      "id": "-OMUDW4FZpEd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.5 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile & Split Log Files to df_d and df_s"
      ],
      "metadata": {
        "id": "kns3IrBcDkdb"
      },
      "id": "kns3IrBcDkdb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Reference here: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
        "file_list = []\n",
        "\n",
        "def compileLogFiles (path):\n",
        "  global file_list\n",
        "#   print (path)\n",
        "  os.chdir(path)\n",
        "  file_list = sorted(glob.glob(\"*LOG*.csv\")) + sorted(glob.glob(\"*log*.csv\")) + sorted(glob.glob(\"*LOG*.txt\")) + sorted(glob.glob(\"*log*.txt\")) + sorted(glob.glob(\"*LOG*.TXT\")) + sorted(glob.glob(\"*log*.TXT\"))\n",
        "              # in 2019 clinical, some files are log and some are LOG\n",
        "#   file_list = sorted(glob.glob(\"*\"))\n",
        "  number_of_files = len(file_list)\n",
        "#   print(\"Number of Files:\" , len(file_list))\n",
        "  print (file_list)\n",
        "  li = []\n",
        "\n",
        "  for file_name in file_list:\n",
        "    # This could work faster potentially, but then the data logger identifier code for finding the zug/nonin code string has to be changed\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n', names=list(range(12)))\n",
        "  \n",
        "    df = pd.read_csv(file_name, header=None, sep='\\n')\n",
        "    #df = pd.read_csv(file_name, header=None, sep=',')\n",
        "    df['Source File'] = file_name\n",
        "    li.append (df)\n",
        "  \n",
        "  frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "_MMQAV31zaJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9af162e-2846-454d-d463-7449bf009d48"
      },
      "id": "_MMQAV31zaJk",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.93 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def splitToDataAndSettingsDF (df_LOGs):\n",
        "  \n",
        "  raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict = decideDataLoggerVersion (df_LOGs)    \n",
        "\n",
        "  df_raw = df_LOGs[0].str.split(',', expand=True)\n",
        "  #display (df_raw)\n",
        "   \n",
        "  df_raw.columns = raw_logfile_data_table_headers\n",
        "  df_raw[\"Source File\"] = df_LOGs [\"Source File\"]\n",
        "\n",
        "  # Extract Settings\n",
        "  df_raw_shift = df_raw.shift(periods=-1)\n",
        "  df_s = df_raw_shift[(df_raw.iloc[:,2]==\"Preset mode\") | (df_raw.iloc[:,2]==\"Intervention\") | (df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  # For the clinical data - just use the rows with a new source file to keep the time/date and file. \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == 'M2')):\n",
        "    df_s = df_raw.drop_duplicates(subset=[\"Source File\"], keep='first')\n",
        "\n",
        "\n",
        "  # Delete settings and settings headers\n",
        "  df_raw_shift = df_raw.shift(periods=1)                                        #shift down one row as a way to find one line below the settings header\n",
        "  rows_below_header = df_raw[(df_raw_shift.iloc[:,2]==\"Preset mode\") |(df_raw_shift.iloc[:,2]==\"Intervention\")|(df_raw_shift.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop(rows_below_header.index)                                 #Drop all the setttings data lines \n",
        "  rows_with_header = df_raw[(df_raw.iloc[:,2]==\"Preset mode\") |(df_raw.iloc[:,2]==\"Intervention\")|(df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the settings headers\n",
        "  rows_with_header = df_raw[df_raw.iloc[:,2]==\"SPO2\"]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the DATA headers\n",
        "  \n",
        "  # Format Settings Files\n",
        "  df_s.drop(settings_columns_to_drop, axis=1, inplace=True)                     # Drop extra columns\n",
        "  df_s.rename(columns=settings_columns_rename_dict, inplace=True)\n",
        "  if 'Alarm Intensity' in df_s.columns:\n",
        "    df_s['Alarm intensity'].apply(lambda v: v.rstrip(';'))\n",
        "  \n",
        "  #What's left of df_raw is now df_d for data\n",
        "  df_d = df_raw\n",
        "  if (AB_Model == \"NONIN Circa April 2022\"):\n",
        "    df_d.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "    #df_s.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "\n",
        "  # In the clinical, Tuhin put P for the devices that were placebo and would have stimulated but actually didn't.\n",
        "  # Replace those with the number 1\n",
        "  df_d[\"Stimulator ON/OFF\"].mask(df_d[\"Stimulator ON/OFF\"] == \" P\", 1, inplace= True)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  if (AB_Model == \"M1\"):\n",
        "    format_day = '%d-%MM-%yyyy'\n",
        "    format_time = '%H:%m:%s'\n",
        "  else:\n",
        "    format_day = '%d/%m/%y'\n",
        "    format_time = '%H:%M:%S'\n",
        "    \n",
        "\n",
        "#   if (AB_Model == \"M1\"):\n",
        "#       try:\n",
        "#         display (df_s)\n",
        "#         display (df_d)\n",
        "#         # df_s.head()\n",
        "#         # df_d.head()\n",
        "        \n",
        "#         # print (df_d.columns)\n",
        "#         # print (\"df_s1 \" + df_s[\"Settings Date\"][3] + df_s[\"Settings Time\"][3])\n",
        "#         df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"df_d1 \" + df_d[\"Data Date\"][3] + df_d[\"Data Time\"][3])\n",
        "#         df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))   \n",
        "#         print (\"matched 1!\")\n",
        "#       except Exception as e:\n",
        "#           print (e)\n",
        "#           print (\"try alternate date format:\")\n",
        "#           display (df_s)\n",
        "#         #   print (df_d.columns)\n",
        "#           try:\n",
        "#             # df_s.drop (\"Settings Date-Time\")\n",
        "#             # df_d.drop (\"Data Date-Time\")\n",
        "#             # df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             # df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))  \n",
        "#             print (\"matched 2!\")\n",
        "#           except Exception as e2:\n",
        "#             print (e2)\n",
        "#             print (\"no more date formats to try!\")       \n",
        " \n",
        "\n",
        "#   else:\n",
        "#     df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#     df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#   print (\"inserting with \"+format_day + \" \" + format_time)\n",
        "#   display (df_s)\n",
        "\n",
        "#   print (\"df_s insert done, here's what it looks like\")\n",
        "#   display (df_s)\n",
        "#   display (df_d)\n",
        "\n",
        "#   print (\"df_d coerce done and now df_d looks like:\")\n",
        "#   display (df_d)\n",
        "#   print (\"inserts done\")\n",
        "\n",
        "# MARCH 9, 2023 - These two lines below work (infer_datetime_format=True needs to be checked bc some columns may have multiple date Time formats?) \n",
        "# but it's still slow so I'm commenting them out for now and replacing them with the two below\n",
        "\n",
        "#   df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "#   df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "\n",
        "  df_s.insert(loc=0, column=\"Settings Date-Time\", value=df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"])\n",
        "  df_d.insert(loc=0, column=\"Data Date-Time\", value=df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"])\n",
        "\n",
        "\n",
        "\n",
        "  if ((AB_Model == \"M1\") | (AB_Model == \"M2\") | (AB_Model == \"M3-Placebo\") | (AB_Model == \"M3-Intervention\")):\n",
        "      df_s.insert(loc = 3, column=\"Preset mode\", value = 1)\n",
        "      df_s.insert(loc = 4, column=\"SPO2 Threshold\", value = 0)\n",
        "      df_s.insert(loc = 5, column=\"HR Threshold\", value = 0)\n",
        "      df_s.insert(loc = 6, column=\"AND/OR\", value = 0)\n",
        "      df_s.insert(loc = 7, column=\"Duration\", value = 0)\n",
        "      if ((AB_Model == \"M1\") | (AB_Model == \"M2\")):\n",
        "        df_s.insert(loc = 8, column=\"Stimulator Intensity\", value = 0)\n",
        "        df_s.insert(loc = 9, column=\"Alarm intensity\", value = 0)\n",
        "\n",
        "  #Cleanup NaNs\n",
        "  df_d = df_d.fillna(0)\n",
        "  df_s = df_s.fillna(0)\n",
        "\n",
        "  #Convert to best datatypes\n",
        "\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format='%d/%m/%y')\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format='%H:%M:%S')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format='%d/%m/%y')\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format='%H:%M:%S')#.dt.time\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format=format_day)\n",
        "#   print (\"Settings Date Updated done\")\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Settings Time Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format=format_day)\n",
        "#   print (\"Data Date Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Data Time Updated done\")\n",
        "  \n",
        "## For Clinical Analysis I am not going to do these, since they are already done above when combined. \n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"])\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"], errors = 'coerce')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"])\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"], errors = 'coerce')#.dt.time\n",
        "  df_s.drop(columns = \"Settings Date\", axis = 1, inplace=True)\n",
        "  df_s.drop(columns = \"Settings Time\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Date\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Time\", axis = 1, inplace=True)\n",
        "  df_s=df_s.astype(settings_convert_dict, errors='raise')\n",
        "  df_d=df_d.astype(data_convert_dict, errors='raise')\n",
        "\n",
        "  #df_d = ResolveMidnightDateIssue (df_d) \n",
        "\n",
        "#  df_d[\"Data Date-Time\"]=pd.to_datetime(df_d[\"Data Date-Time\"],format='%d/%m/%y %H:%M:%S')\n",
        "\n",
        "  # For Settings Table delete the confusing default numbers left in place when \"preset\" condition is on.\n",
        "# \n",
        "  df_s = DeleteThresholdsForRowsUsingPresetConditions(df_s)\n",
        "  df_s, df_d = addSettingsIndex (df_s,df_d)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "_jiazNDlz1Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be510c3-2e3b-4dde-c55d-f0fe29b6d79e"
      },
      "id": "_jiazNDlz1Dp",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.74 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XH-EgNxkPi",
        "outputId": "ec5da070-91a3-4606-ef2f-d9254e5bf87a"
      },
      "id": "T9XH-EgNxkPi",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 18.8 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It was observed with Zug that for the first ~30 seconds after midnight, the date does not change. This needs to be fixed or \"smoothed\" with the code below.\n",
        "#import calendar\n",
        "\n",
        "#### This function is not finished.\n",
        "def ResolveMidnightDateIssue (df_above):\n",
        "  print (\"in the smooth\")\n",
        "  df_diff = pd.DataFrame ()\n",
        "  df_below = pd.DataFrame ()\n",
        "\n",
        "  df_below[\"Data Date-Time\"] = df_above[\"Data Date-Time\"].shift (periods=1, fill_value=0)\n",
        "  #df_below[\"Data Date\"] = df_above[\"Data Date\"].shift (periods=1, fill_value=0)\n",
        "  df_below [\"Date Diff\"] = df_above[\"Data Date-Time\"] < df_below[\"Data Date-Time\"]\n",
        "  df_below [\"Date Diff Num\"] = (df_above[\"Data Date-Time\"] - df_below[\"Data Date-Time\"]).dt.total_seconds()\n",
        "  print (df_below [\"Date Diff Num\"].dtype)\n",
        "  \n",
        "\n",
        "  # display(df_above)\n",
        "  # display(df_below)\n",
        "  # display (df_below[df_below[\"Date Diff\"]==1])\n",
        "  df_midnight_bounds = df_below[df_below[\"Date Diff Num\"].abs()>1000]\n",
        "  #display (df_midnight_bounds)\n",
        "  # for i in df_midnight_bounds.index:\n",
        "  #   print (i)\n",
        "\n",
        "\n",
        "\n",
        "  #display (df_below[df_below[\"Date Diff Num\"]!=1])\n",
        "  \n",
        "  print (\"Sum is: \" + df_below[\"Date Diff\"].astype(int).sum().astype(str))\n",
        "  \n",
        "  return df_above\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2noyZAXZNuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5198cbb6-0187-4482-eccf-a861aab19e58"
      },
      "id": "J2noyZAXZNuk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.54 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def addSettingsIndex (df_s,df_d):\n",
        "  #df_s[\"Settings Index\"] = np.arange(len(df_s))\n",
        "  df_s.insert(loc=0, column=\"Settings Index\", value=np.arange(len(df_s))+1)\n",
        "  df_d = pd.merge_asof (df_d,df_s[\"Settings Index\"],left_index=True, right_index=True)\n",
        "  SettingsIndexCol = df_d.pop('Settings Index')\n",
        "  df_d.insert(0, 'Settings Index', SettingsIndexCol)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "SeN4pRpcmoTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ae677a-f837-4b03-fc61-4506da3b0559"
      },
      "id": "SeN4pRpcmoTt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.63 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd675dc2-0b70-43aa-efde-4c01fc130c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.67 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def DeleteThresholdsForRowsUsingPresetConditions (settings_table):\n",
        "    # display(settings_table)\n",
        "    for ind in settings_table.index:\n",
        "        if settings_table[\"Preset mode\"][ind] == 1:\n",
        "            settings_table[\"SPO2 Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"HR Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"AND/OR\"][ind] = np.NaN\n",
        "            settings_table[\"Duration\"][ind] = np.NaN\n",
        "                       #Preset mode\tSPO2 Threshold\tHR Threshold\tAND/OR\tDuration\n",
        "    return settings_table\n"
      ],
      "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dPG9_2xoX3"
      },
      "source": [
        "## **Analyze Thresholds**"
      ],
      "id": "T3dPG9_2xoX3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Only Valid Data\n",
        "This filters data based on device status. "
      ],
      "metadata": {
        "id": "YxecqEFREEhV"
      },
      "id": "YxecqEFREEhV"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe87540-d1fa-451e-de48-223afda3a7af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.1 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def GetIsValidColumn (df):\n",
        "    is_valid = pd.DataFrame ()\n",
        "    is_valid [\"valid_vitals\"] = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff) & (df[\"HR\"] !=255) & (df[\"SPO2\"] !=127))\n",
        "    # print (\"Num IsValid Vitals True:\")\n",
        "    # print (is_valid[\"valid_vitals\"].sum())\n",
        "    # print (is_valid [\"valid_vitals\"])\n",
        "    # is_valid['valid_vitals'].value_counts()\n",
        "    # print (\"num valid vitals: \" + is_valid [is_valid[\"valid_vitals\"]==True].count)\n",
        "\n",
        "    # Determine if status scale is 0-6 or 0-255...\n",
        "    max_status = df[\"Status\"].max()\n",
        "    print (\"about to check valid_status\")\n",
        "    display (df)\n",
        "    # if (AB_Model == \"M1\"):\n",
        "    if (max_status < 7):\n",
        "        print (\"eval status for 0-6 status\")\n",
        "        is_valid [\"valid_status\"] = (df['Status'] == 0);\n",
        "    elif (max_status >= 7):\n",
        "        print (\"eval status for 0-255 status\")\n",
        "        is_valid [\"valid_status\"] = ((df['Status'] == 129) | (df['Status'] == 131));  \n",
        "    \n",
        "    # print (\"Num IsValid Status True:\")\n",
        "    # print (is_valid[\"valid_status\"].sum())\n",
        "    \n",
        "    is_valid['Is_Valid_Data'] = np.where((is_valid['valid_status'] == True) & (is_valid[\"valid_vitals\"] == True), True, False)\n",
        "    # is_valid [\"Is_Valid_Data\"] = ((is_valid['valid_vitals'] == True) & (is_valid ['valid_status'] == True))\n",
        "    # is_valid['Is_Valid_Data'].value_counts()\n",
        "    # print (\"Num IsValid True:\")\n",
        "    # print (is_valid[\"Is_Valid_Data\"].sum())\n",
        "    return is_valid [\"Is_Valid_Data\"]\n",
        "\n",
        "\n"
      ],
      "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Against Custom Thresholds\n",
        "This function returns what is expected in the custom mode the user selected. It should match with actual stimulations in custom mode."
      ],
      "metadata": {
        "id": "dm2RieFwTAjS"
      },
      "id": "dm2RieFwTAjS"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770e7825-08af-4d03-874e-010c5b8d04d6",
        "id": "pndZJ_WATAja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.57 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def AnalyzeWithCustomThresholds (df):\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) & (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) | (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_result = (df[\"AND/OR\"]==0)*is_below_threshold_OR + (df[\"AND/OR\"]==1)*is_below_threshold_AND\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= df[\"Duration\"],0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "\n",
        "  df[Duration_Custom] = df_unmasked.mask(df_unmasked <= df[\"Duration\"],0)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "id": "pndZJ_WATAja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze With Preset Thresholds\n",
        "This function is useful to see how the system would have performed if it were operating in preset mode."
      ],
      "metadata": {
        "id": "c9pqOw4FnVYA"
      },
      "id": "c9pqOw4FnVYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "SPO2_threshold_AND_condition = 85\n",
        "HR_threshold_AND_condition = 100\n",
        "SP02_threshold_OR_condition = 75\n",
        "HR_threshold_OR_condition  = 90\n",
        "Preset_Mode_Duration = 5\n",
        "\n",
        "def AnalyzeWithPresetThresholds (df):\n",
        "  \n",
        "    \n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "  # is_below_threshold_result = ((df[\"AND/OR\"]==0))&(is_below_threshold_OR) | ((df[\"AND/OR\"]==1) &is_below_threshold_AND)\n",
        "  is_below_threshold_result = is_below_threshold_OR | is_below_threshold_AND\n",
        "  #print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "#   display (is_below_threshold_result)\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= Preset_Mode_Duration,0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  # print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "\n",
        "  # print (\"Total preset results are: \" + str(is_below_threshold_result.sum()))\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "  df[Duration_Preset] = df_unmasked.mask(df_unmasked <= Preset_Mode_Duration,0)\n",
        "\n",
        "  #print (\"Sum is:\" + str(sum(df[Duration_Preset])))\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "NFGvMndV_NLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b261730-3c0b-4662-93d4-58ce1036ba04"
      },
      "id": "NFGvMndV_NLH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.33 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Actual Stimulations\n",
        "This function looks at Stim Off/On field and counts the apnea durations (assuming SPO2 & HR are not 0). It does not consider the Preset/Custom settings at all. "
      ],
      "metadata": {
        "id": "Ff704C-MwEsw"
      },
      "id": "Ff704C-MwEsw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Assumes it is being passed df_j\n",
        "def AddNumActualStimulations (df):\n",
        "  \n",
        "#   Valid_Stimulations = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff)*(df[\"HR\"]>Data_Cleanup_HR_LowCutOff)\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  Valid_Stimulations = df[\"Stimulator ON/OFF\"]*is_valid\n",
        "  df[Duration_Actual] = calcDurationsCrossedThreshold(pd.DataFrame(Valid_Stimulations))\n",
        "   \n",
        "  ## New code (22-07-23) - I later realized that with the new apnea duration counter, we don't need to \"Stimulation started column\" as it easily puts the apnea duration time where the stimulation started. \n",
        "  # df[\"Stimulator ON/OFF with Valid SPO2/HR\"] = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]!=0)*(df[\"HR\"]!=0) \n",
        "\n",
        "  # df_previousrow = df.shift(periods=1)\n",
        "  # isStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF with Valid SPO2/HR\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF with Valid SPO2/HR\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0)\n",
        "  #                         )  # This condition was added because there are some odd cases where the stimulator turns when HR/SPO2 are 0...\n",
        "\n",
        "  #This gives 408 rows, but the one above gives 411 rows. There are likely some times then the O2 or HR jumps to zero mid apnea but jumps back up and the stimulator is on the whole time? \n",
        "  # OldisStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0))\n",
        "\n",
        "  #Should be 408 Rows\n",
        "  \n",
        "  # df[\"Stimulation Triggered (Actual Stimulator ON Triggered)\"] = isStimulationStarted\n",
        "  # df[\"Actual - Stimulation Durations (s)\"] = calcDurationsCrossedThreshold(pd.DataFrame(df[\"Stimulator ON/OFF with Valid SPO2/HR\"]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "CI2GKzN15PZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11f9c9a-c75a-418a-e7e4-d964dec48eb6"
      },
      "id": "CI2GKzN15PZJ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.39 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Cross Duration\n",
        "This takes an array of \"threshold crossed\" or \"stimulation on\" (0,0,0,1,1,1,1,0..etc) and returns an array with the time in the first place the threshold is cross i.e. (0,0,0,4,0,0,0,0...)"
      ],
      "metadata": {
        "id": "4C39qoDxEcnt"
      },
      "id": "4C39qoDxEcnt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Input: A df with 0s and 1s representing cross thresholds\n",
        "# see this -  https://stackoverflow.com/questions/62615666/how-to-sum-variable-ranges-in-a-pandas-column-to-another-column\n",
        "def calcDurationsCrossedThreshold (df):\n",
        "  \n",
        "  df = df.iloc[::-1]\n",
        "  a = df.iloc[:,0]==0\n",
        "  blocks = a.cumsum()\n",
        "  \n",
        "  m = blocks.duplicated(keep='last')\n",
        "  \n",
        "  df['Sum'] = df.iloc[:,0].groupby(blocks).cumsum().mask(m)\n",
        "  df = df.iloc[::-1]\n",
        "  df_return = df ['Sum'].fillna(0)\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "HIOGli41rAgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e612df7-4426-4372-c25f-dc5e220b6398"
      },
      "id": "HIOGli41rAgo",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.89 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Summary Tables**"
      ],
      "metadata": {
        "id": "vFvsiREGpJ-8"
      },
      "id": "vFvsiREGpJ-8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportApneaCountBySetting (df,df_s):\n",
        "  table = pd.pivot_table (df, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='sum')\n",
        "#   display (table)\n",
        "  table = table.rename (columns = {Duration_Actual:SumDuration_Actual, Duration_Preset:SumDuration_Preset, Duration_Custom:SumDuration_Preset})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "  \n",
        "\n",
        "  #Count function counts zeros too, so need to replace zeros with NAs for this to work.\n",
        "  df_nan = df.mask(df==0) # This will make all zeros into Nan\n",
        "  table = pd.pivot_table (df_nan, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='count')\n",
        "  \n",
        "  table = table.rename (columns = {Duration_Actual:Count_Actual, Duration_Preset:Count_Preset, Duration_Custom:Count_Custom})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "#   display (df_s)\n",
        "  \n",
        "  if (PRINT_TABLES == True):\n",
        "    df_s.to_excel (folder_name + \" - Summary of Events.xlsx\")\n",
        "    dataframe_to_pdf(df_s, folder_name + \" - Apnea Count By Setting\")\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McI1Xwv81qIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e40097f-63d0-409d-ad09-c911c40af0e3"
      },
      "id": "McI1Xwv81qIh",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.72 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportIndividualActualApneas (df):\n",
        "  table_A = df[df[Duration_Actual]!=0]\n",
        "  table_P = df[df[Duration_Preset]!=0]\n",
        "  table_C = df[df[Duration_Custom]!=0]\n",
        "  table_A_P = df[ (df[\"Preset mode\"]==1 & (df[Duration_Actual]!=df[Duration_Preset]))]\n",
        "  table_A_C = df[ (df[\"Preset mode\"]==0 & (df[Duration_Actual]!=df[Duration_Custom]))]\n",
        "                   \n",
        "  if (PRINT_TABLES == True):\n",
        "    with pd.ExcelWriter(folder_name + \" - Individual Events.xlsx\") as writer:\n",
        "        table_A.to_excel (writer, sheet_name=\"Actual\")\n",
        "        table_P.to_excel (writer, sheet_name=\"Preset\")\n",
        "        table_C.to_excel (writer, sheet_name=\"Custom\")\n",
        "        table_A_P.to_excel (writer, sheet_name=\"Actual-Preset Discrepancy\")\n",
        "        table_A_C.to_excel (writer, sheet_name=\"Actual-Custom Discrepancey\")\n",
        "\n",
        "    dataframe_to_pdf(table_A, folder_name + \" - Individual Events (Actual)\")\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "IbdRSJx_MgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae27dbbd-4e0b-4cfe-9f7a-4ade26c36096"
      },
      "id": "IbdRSJx_MgxZ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.89 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def convertDataframeToFigure (df):\n",
        "  display (df)\n",
        "  fig, ax =plt.subplots(figsize =(20,20))\n",
        "  #fig, ax =plt.subplots(figsize=(len(df),len(df.columns)))\n",
        "  ax.axis('tight')\n",
        "  ax.axis('off')\n",
        "  the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "  return fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qxv3-8-3lsTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de37abfa-c00d-4986-fbcb-04808958e8df"
      },
      "id": "Qxv3-8-3lsTZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.88 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ## Print Tables to PDF **\n",
        "This code enables printing tables to pdf."
      ],
      "metadata": {
        "id": "Sb6hldAxxaXX"
      },
      "id": "Sb6hldAxxaXX"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import textwrap as twp\n",
        "\n",
        "# #create column headers with long text and apply textwrap with \\n after defined lenght\n",
        "# columns=[twp.fill('this is a long column header text',25), twp.fill('...and this is an even longer column header text',25)]\n",
        "\n",
        "# https://predictivehacks.com/?all-tips=save-a-pandas-dataframe-as-an-image\n",
        "# pip install dataframe-image\n",
        "# import pandas as pd\n",
        "# import dataframe_image as dfi\n",
        " \n",
        "# dfi.export(df, 'dataframe.png')\n",
        "\n",
        "def _draw_as_table(df, pagesize):\n",
        "    alternating_colors = [['white'] * len(df.columns), ['lightgray'] * len(df.columns)] * len(df)\n",
        "    alternating_colors = alternating_colors[:len(df)]\n",
        "    fig, ax = plt.subplots(figsize=pagesize)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    # df=df.to_string(line_width=5)\n",
        "    # .str.wrap(5)\n",
        "    col_headers=list(df.columns.str.wrap(15)) #df.columns#.map(\"str\")\n",
        "    #display (col_headers)\n",
        "    #print (\"Cols is \" + len(df[0]))\n",
        "    #display (df)\n",
        "    the_table = ax.table(cellText=df.values,\n",
        "                        rowLabels=df.index,\n",
        "                        colLabels=col_headers,\n",
        "                        #colLabels=df.columns,\n",
        "                        rowColours=['lightblue']*len(df),\n",
        "                        colColours=['lightblue']*len(df.columns),\n",
        "                        cellColours=alternating_colors,\n",
        "                        loc='center')\n",
        "    the_table.auto_set_column_width(col=list(range(len(df.columns)))) # Provide integer list of columns to adjust\n",
        "\n",
        "    # the_table.auto_set_font_size(False)\n",
        "    # the_table.set_fontsize(12)\n",
        "    return fig\n",
        "  \n",
        "\n",
        "def dataframe_to_pdf(df, filename, numpages=(1, 1), pagesize=(11, 8.5)):\n",
        "  with PdfPages(filename) as pdf:\n",
        "    # display (df)\n",
        "    # nh, nv = numpages\n",
        "    # rows_per_page = len(df) // nh\n",
        "    # cols_per_page = len(df.columns) // nv\n",
        "\n",
        "    # nh, nv = numpages\n",
        "    rows_per_page = 30\n",
        "    cols_per_page = len(df.columns)\n",
        "    nv = 1\n",
        "    \n",
        "    if len(df) % rows_per_page == 0: \n",
        "      nh = int(len(df) / rows_per_page)\n",
        "    else:\n",
        "      nh = int(len(df) / rows_per_page) +1\n",
        "    \n",
        "    # print ('num cols is ' + str(len(df.columns)))\n",
        "    # print ('num rows is ' + str(len(df)) + \"nv is \" + str(nv))\n",
        "\n",
        "    for i in range(0, nh):\n",
        "        for j in range(0, nv):\n",
        "            # print (\"i is \" + str(i) + \"and j is \" + str(j))\n",
        "            page = df.iloc[(i*rows_per_page):min((i+1)*rows_per_page, len(df)),\n",
        "                           (j*cols_per_page):min((j+1)*cols_per_page, len(df.columns))]\n",
        "            # display (page)\n",
        "            fig = _draw_as_table(page, pagesize)\n",
        "            if nh > 1 or nv > 1:\n",
        "                # Add a part/page number at bottom-center of page\n",
        "                fig.text(0.5, 0.5/pagesize[0],\n",
        "                         \"Part-{}x{}: Page-{}\".format(i+1, j+1, i*nv + j + 1),\n",
        "                         ha='center', fontsize=8)\n",
        "            \n",
        "            pdf.savefig(fig, bbox_inches='tight')\n",
        "            # plt.show ()\n",
        "            plt.close()\n"
      ],
      "metadata": {
        "id": "BQDht-5kNQpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac4bb0e-5561-48a0-fe2d-ac605685c346"
      },
      "id": "BQDht-5kNQpD",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 308 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AZp6q5Z8Aq"
      },
      "source": [
        "## **Plots**"
      ],
      "id": "X_AZp6q5Z8Aq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot AB Data"
      ],
      "metadata": {
        "id": "1uadoNfrjZUt"
      },
      "id": "1uadoNfrjZUt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotApneBootData (df,plot_title,x_axis_start,x_axis_end):\n",
        "    #display (df)\n",
        "    \n",
        "    f, (ax, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 1]})\n",
        "\n",
        "    ax2 = df.plot(x=\"Data Date-Time\", y=\"Status\", rot=0,ax=ax2)\n",
        "    \n",
        "    plotSPO2AndHR(df,plot_title,x_axis_start,x_axis_end,ax)\n",
        "       \n",
        "    f.tight_layout()\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xxrNme8yvvkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64314780-735a-4c07-b567-19e47e469114"
      },
      "id": "xxrNme8yvvkW",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.78 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotSPO2AndHR (df,plot_title,x_axis_start,x_axis_end,ax):\n",
        "  df[\"Stimulator ON/OFF Plot\"] = df[\"Stimulator ON/OFF\"]*20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ax = df.plot(x=\"Data Date-Time\", y=\"SPO2\", \n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                            rot=0,\n",
        "                            #kind='scatter',\n",
        "                            color = 'red',\n",
        "                            label = \"SPO2\",\n",
        "                            linewidth=1, \n",
        "                            #s=2,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df.plot(x=\"Data Date-Time\", y=\"HR\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=True,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'blue',\n",
        "                          label = \"HR\",\n",
        "                          linewidth=1,\n",
        "                          #s=2,\n",
        "                          ax=ax)\n",
        "  \n",
        "  df.plot.line(x=\"Data Date-Time\", y=\"Stimulator ON/OFF Plot\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          linewidth=4,\n",
        "                          alpha=0.2,\n",
        "               \n",
        "                          #fmt ='+',\n",
        "                          color = 'Orange',\n",
        "                          label = \"Stim ON\",\n",
        "                          #s=30,\n",
        "                          ax=ax)\n",
        "                          \n",
        "  df_t = getThresholdTable (df)\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"SPO2 Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkRed',\n",
        "                          label = \"SPO2 Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dashed',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"HR Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkBlue',\n",
        "                          label = \"HR Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dotted',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  x_offset = (x_axis_end - x_axis_start)/10\n",
        "  df_a = df[(df[Duration_Actual] > 0)]\n",
        "  #df_a[\"Text X Position\"] = df_a[\"Data Date-Time\"][ind] - x_offset\n",
        "  df_a=df_a.reset_index(drop=True)\n",
        "  df_a[\"Arrow Offet\"] = df_a[\"Data Date-Time\"] - x_offset\n",
        "\n",
        "  for ind in df_a.index:\n",
        "    if df_a[\"Arrow Offet\"][ind] <= x_axis_start:\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than \" + str(x_axis_start))\n",
        "      df_a[\"Arrow Offet\"][ind] = df_a[\"Arrow Offet\"][ind] + x_offset*2\n",
        "      print (\"so we replace with: \" + str(df_a[\"Arrow Offet\"][ind]))\n",
        "    #print (ind)\n",
        "    ax.annotate(\"Event For \" + df_a[Duration_Actual][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "            xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "            fontsize = 10, \n",
        "            xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "            arrowprops = dict(facecolor = 'yellow'),\n",
        "            color = 'black',\n",
        "            backgroundcolor='white')\n",
        "    \n",
        "  #df.plot.annotate(df[Duration_Actual].str(), xy=\"Data Date-Time\", y=100, , fontsize = 10, color = 'g')\n",
        "\n",
        "  #### PRINT THresholds\n",
        "  \n",
        "  # ax.plot.line (x=df[\"Data Date-Time\"], y=df_t[\"HR Threshold\"], \n",
        "  #                         #figsize=(20,5),\n",
        "  #                         #title = current_date,\n",
        "  #                         #ylim=(-5,150),\n",
        "  #                         #xlim= (x_axis_start, x_axis_end),\n",
        "  #                         #grid=1 ,\n",
        "  #                         #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "  #                         #rot=1,\n",
        "  #                         #kind='scatter',\n",
        "  #                         color = 'Orange',\n",
        "  #                         label = \"HR Threshold\",\n",
        "  #                         linewidth=1,\n",
        "  #                         #s=2,\n",
        "  #                         ax=ax\n",
        "  #                         )\n",
        "\n",
        "\n",
        "\n",
        "  ax.grid('on', which='major')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "br-rk3f9_P2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0301ed18-6162-4a36-bdaa-54d2c9a701f0"
      },
      "id": "br-rk3f9_P2G",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.65 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Threshold Table"
      ],
      "metadata": {
        "id": "qYEzi3M-S0K6"
      },
      "id": "qYEzi3M-S0K6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def getThresholdTable (df):\n",
        "  SPO2_threshold_AND_condition = 85\n",
        "  HR_threshold_AND_condition = 100\n",
        "  SP02_threshold_OR_condition = 75\n",
        "  HR_threshold_OR_condition  = 90\n",
        "  Preset_Mode_Duration = 5\n",
        "\n",
        "  df_t = pd.DataFrame()\n",
        "  #df_t = df\n",
        "  # df_t [\"HR Threshold\"] = 60\n",
        "  # df_t [\"SPO2 Threshold\"] = 64\n",
        "  df_t [\"Data Date-Time\"] = df[\"Data Date-Time\"]\n",
        "  df_t [\"HR Threshold\"] = df[\"Preset mode\"]*HR_threshold_OR_condition\n",
        "  df_t [\"SPO2 Threshold\"] = df[\"Preset mode\"]*SP02_threshold_OR_condition\n",
        "  df_t[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]=df[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]\n",
        "  df_t[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]=df[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]\n",
        "\n",
        "  # df_t [\"HR Custom\"] = df[\"HR Threshold\"]\n",
        "  # df[\"SPO2 Threshold\"].notna().astype(int)*df[\"SPO2 Threshold\"]\n",
        "  # display (df_t)\n",
        "\n",
        "  #is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  \n",
        "  #print (\"df_t is: \")\n",
        "  #display (df_t)\n",
        "\n",
        "  return df_t"
      ],
      "metadata": {
        "id": "oDhFqjhBjY20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9905fc-38b9-4345-f149-f09283c142e9"
      },
      "id": "oDhFqjhBjY20",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.72 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot by Day"
      ],
      "metadata": {
        "id": "bHJA2jljjdc-"
      },
      "id": "bHJA2jljjdc-"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2ea3a1SQZLQB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5607e569-7c4c-43aa-ac85-0c807caf4c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.45 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_plot=df_j\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "def plotByDay (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    length = len(date_list)\n",
        "\n",
        "    fname = folder_name + ' plot_by_day.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "        for i in range(length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "          \n",
        "          # x axis start and end\n",
        "          x_axis_start = current_date.replace(second = 1)\n",
        "          #print(x_axis_start)\n",
        "          x_axis_end = current_date.replace(hour = 23, minute=59, second = 59)\n",
        "          \n",
        "          \n",
        "          ##### Sept 7 - Not sure if this below has to be commented or fixed\n",
        "          # df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"].astype(str)).dt.time\n",
        "          # #df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"])\n",
        "          df_current_date[\"Data Time\"] = df_current_date[\"Data Time\"].dt.time\n",
        "          df_current_date.set_index('Data Time')\n",
        "          #display(df_current_date.dtypes)\n",
        "          #display (df_current_date)\n",
        "          \n",
        "          plotApneBootData (df_current_date,current_date_64,x_axis_start,x_axis_end)\n",
        "          pdf.savefig()\n",
        "          plt.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "2ea3a1SQZLQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot By Hour"
      ],
      "metadata": {
        "id": "eoiLSOJ3jfmj"
      },
      "id": "eoiLSOJ3jfmj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotByHour (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    df[\"Data Time\"] = pd.to_datetime(df[\"Data Time\"])\n",
        "    df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "    # display(df)\n",
        "    # return\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    date_length = len(date_list)\n",
        "    fname = folder_name + ' plot_by_hour.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "\n",
        "        firstPage = plt.figure(figsize=(11.69,8.27))\n",
        "        firstPage.clf()\n",
        "        txt = 'This is the title page'\n",
        "        firstPage.text(0.5,0.5,txt, transform=firstPage.transFigure, size=24, ha=\"center\")\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(date_length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "      \n",
        "          hour_list = np.unique(df_current_date[\"Data Time-Hour\"])\n",
        "          hour_length = len(hour_list)\n",
        "          #print (hour_list)\n",
        "\n",
        "          for j in range(hour_length):\n",
        "              current_hour_64 = hour_list[j]\n",
        "              #current_date=pd.to_datetime(current_date_64)\n",
        "              df_current_hour = df_current_date[(df_current_date[\"Data Time-Hour\"]==current_hour_64)]\n",
        "              x_start = current_date + pd.offsets.Hour(current_hour_64)\n",
        "              x_end = current_date + pd.offsets.Hour(current_hour_64+1)\n",
        "              df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              \n",
        "              # x_start = df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              title = str (current_date) + ' ' + str(x_start)\n",
        "              plotApneBootData (df_current_hour,x_start,x_start,x_end)\n",
        "              # plotApneBootData (df_current_hour,current_date,current_hour_64,current_hour_64+1)\n",
        "              pdf.savefig()\n",
        "              plt.close()\n"
      ],
      "metadata": {
        "id": "kNpgyduy7ulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36af500f-ac1e-4590-f628-31387311ab92"
      },
      "id": "kNpgyduy7ulE",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.56 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubPlot Grids of Apnea Events "
      ],
      "metadata": {
        "id": "kPbeaF7WOonR"
      },
      "id": "kPbeaF7WOonR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "### Plot multiple subplots\n",
        "\n",
        "def PlotApneaEventsGrid (df):\n",
        "  \n",
        "  start_offset = dt.timedelta (seconds=15)\n",
        "  end_offset = dt.timedelta (seconds=45)\n",
        "  num_rows = 2\n",
        "  num_cols = 2\n",
        "  num_subplots = num_rows * num_cols\n",
        "\n",
        "  df_list_of_apnea_events = df[(df[Duration_Actual] != 0)]\n",
        "  \n",
        "  num_events = len(df_list_of_apnea_events)\n",
        "  # print (\"div \" + str(num_events/num_subplots))\n",
        "  # print (\"div \" + str(9/4))\n",
        "  # print (\"div \" + str(np.ceil(9/4)))\n",
        "  # #num_pages = int(num_events/num_subplots + 1)\n",
        "  num_pages = int(np.ceil(num_events/num_subplots))\n",
        "  #print (\"number of pages is \" + str (num_pages))\n",
        "  #print (\"number of events is \" + str (num_events))\n",
        "  current_page = 0\n",
        "  current_event = 0\n",
        " \n",
        "  fname = folder_name + ' plot_individual_events.pdf'\n",
        "  with PdfPages(fname) as pdf:\n",
        "    for page in range (num_pages):\n",
        "      fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols)\n",
        "      # print (axes.flat)\n",
        "      for ax in axes.flat:\n",
        "        if (current_event < num_events):\n",
        "          event_time = df_list_of_apnea_events.iloc[current_event].at[\"Data Date-Time\"]\n",
        "          plot_start = event_time - start_offset\n",
        "          plot_end = event_time + end_offset\n",
        "          df_event_data = df[((df[\"Data Date-Time\"] > plot_start) & (df[\"Data Date-Time\"] < plot_end))]\n",
        "          #print (\"Current Event Index is \" + str(current_event))\n",
        "          current_event = current_event + 1\n",
        "          plot_title = folder_name + \" Event \" + str(current_event) + \":  \" + str(event_time)\n",
        "          plotSPO2AndHR (df_event_data,plot_title,plot_start,plot_end,ax)\n",
        "    #   print (\"tight layout\")\n",
        "      fig.tight_layout()\n",
        "      pdf.savefig()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "C5DBtqMI2WTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a49254-4eac-45fc-8694-94e1c8d3fd79"
      },
      "id": "C5DBtqMI2WTB",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.95 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4vbvlm-hsj"
      },
      "source": [
        "## **Create Tables & Plots Functions**"
      ],
      "id": "sm4vbvlm-hsj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Names"
      ],
      "metadata": {
        "id": "Y7x2w8JT2a_D"
      },
      "id": "Y7x2w8JT2a_D"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Global Variables\n",
        "### Column Names\n",
        "Duration_Actual = \"Event Duration (s) [Actual Data]\"\n",
        "Duration_Custom = \"Event Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "Duration_Preset = \"Event Duration (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "Count_Actual = \"Event Count [Actual Data]\"\n",
        "Count_Custom = \"Event Count [Using Custom Settings - Theoretical Calculation]\"\n",
        "Count_Preset = \"Event Count (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "SumDuration_Actual = \"Cumulative Duration (s) [Actual Data]\"\n",
        "SumDuration_Custom = \"Cumulative Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "SumDuration_Preset = \"Cumulative Duration (s) [Using Preset Settings - Theoretical Calculation]\""
      ],
      "metadata": {
        "id": "CgzuYBvt8zNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77bbd0d7-3d8e-48ca-938e-434dffe6650f"
      },
      "id": "CgzuYBvt8zNI",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.32 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Tables"
      ],
      "metadata": {
        "id": "mcXFuo902gfD"
      },
      "id": "mcXFuo902gfD"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vsIRg70SdobY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26a1be8-f9e7-4c4f-e126-c6740f49a168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.97 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def createDataTables (data_path):\n",
        "    df_LOGs = compileLogFiles (data_path)\n",
        "\n",
        "    df_s, df_d = splitToDataAndSettingsDF (df_LOGs)\n",
        "    # os.chdir(analysis_path)\n",
        "    # df_d.to_csv (folder_name + \" - Data.xlsx\")\n",
        "\n",
        "    # df_s.to_csv (folder_name + \" - Settings.xlsx\")\n",
        "    # dataframe_to_pdf(df_s, folder_name + \" - Settings\")\n",
        "\n",
        "    df_d[\"Is_Valid_Data\"] = GetIsValidColumn(df_d);\n",
        "\n",
        "    df_j = pd.merge (df_d,df_s, on='Settings Index')\n",
        "    # df_j = AddNumActualStimulations(df_j)\n",
        "    # df_j = AnalyzeWithCustomThresholds (df_j)\n",
        "    # df_j = AnalyzeWithPresetThresholds (df_j)\n",
        "    return df_j, df_d, df_s"
      ],
      "id": "vsIRg70SdobY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Plots"
      ],
      "metadata": {
        "id": "qINEVzl52lDl"
      },
      "id": "qINEVzl52lDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createPlots (df_j):\n",
        "    df_j.dtypes\n",
        "    plotByDay (df_j)\n",
        "    plotByHour (df_j)\n",
        "    PlotApneaEventsGrid (df_j)"
      ],
      "metadata": {
        "id": "AGgoCri491oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3640d0ce-c13a-4521-e694-56fd91c7381c"
      },
      "id": "AGgoCri491oc",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 977 µs (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Summary Tables"
      ],
      "metadata": {
        "id": "N_4X5RS92tGl"
      },
      "id": "N_4X5RS92tGl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createSummaryTables (df,df_s):\n",
        "  \n",
        "  df_s_columns_dropped = df_s.drop(['Settings Date','Settings Time','Alarm intensity'], axis=1)\n",
        "  \n",
        "  reportApneaCountBySetting (df,df_s_columns_dropped)\n",
        "  reportIndividualActualApneas (df)"
      ],
      "metadata": {
        "id": "Ihvpi8G2ze28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee2585c-63d7-4eb1-c6b9-5387fa42b636"
      },
      "id": "Ihvpi8G2ze28",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.48 ms (started: 2023-03-14 08:53:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Summary"
      ],
      "metadata": {
        "id": "c1_bNt0BWjOt"
      },
      "id": "c1_bNt0BWjOt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "spo2_list = [85, 80, 75, 70, 65]\n",
        "hr_list = [110, 100, 90, 80]\n",
        "\n",
        "def createClinicalSummaryTable (df_j, record_name):\n",
        "    num_seconds_per_data_point = 1;\n",
        "    if (AB_Model == \"M1\"):\n",
        "        num_seconds_per_data_point = 2; # Tuhin's model M1 measured every 2 seconds. \n",
        "    # df_j[\"Is_Valid_Data\"] = GetIsValidColumn (df_j)\n",
        "    df_is_valid_data = df_j[df_j[\"Is_Valid_Data\"] == True]\n",
        "    df_clinical_summary = pd.DataFrame ()\n",
        "    df_clinical_summary [\"Name\"] = [record_name]\n",
        "    df_clinical_summary [\"Time ApneBoot System Was On (hrs)\"] = round (len(df_j.index) / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"Time with valid vital and status readings (hrs)\"] = round (df_j[\"Is_Valid_Data\"].sum()/60/60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"SPO2 - Avg\"] = round (df_is_valid_data['SPO2'].mean(),1)\n",
        "    df_clinical_summary [\"SPO2 - Std\"] = round (df_is_valid_data['SPO2'].std(),2)\n",
        "    df_clinical_summary [\"HR - Avg\"] = round (df_is_valid_data['HR'].mean(),1)\n",
        "    df_clinical_summary [\"HR - Std\"] = round (df_is_valid_data['HR'].std(),2)\n",
        "    \n",
        "    for spo2 in spo2_list:\n",
        "        df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\"(hrs)\"] = round(df_is_valid_data.query ('SPO2 < '+str(spo2))['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "    # df_clinical_summary [\"Time SPO2 < 85 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 85')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 80 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 80')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 75 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 75')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 70 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 70')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 65 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 65')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    return df_clinical_summary\n",
        "#   df_s.insert(loc = 3, column=\"Preset mode\", value = 1)"
      ],
      "metadata": {
        "id": "uRiSHGwMw5XT",
        "outputId": "0868015b-4ba9-4844-a681-911723a26dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uRiSHGwMw5XT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.3 ms (started: 2023-03-14 09:11:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R0eILh2iyWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8189841a-219b-4a79-c991-07f18a3c2245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 385 µs (started: 2023-03-14 09:12:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_j stands for df_joined\n",
        "# display (df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"] !=0])\n",
        "#df[\"Time (hours)\"]={len(df)*1/60/60)\n",
        "# df_j.to_csv (folder_name + \" All_Data_Joined_Table.csv\")\n",
        "# df_s.to_csv (folder_name + \" Settings_Index_Table.csv\")"
      ],
      "id": "R0eILh2iyWqc"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# display(df_j[df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]!= df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]])\n",
        "# display(df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"]==0])"
      ],
      "metadata": {
        "id": "k7sHLvRYA10J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51d4cf8-86c2-4ffe-9947-8af9dba49853"
      },
      "id": "k7sHLvRYA10J",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 467 µs (started: 2023-03-14 09:12:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main FOR LOOP Code**\n",
        "\n"
      ],
      "metadata": {
        "id": "Nniyp_1baQUg"
      },
      "id": "Nniyp_1baQUg"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# folder_name = \"Geetha\"\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/\"\n",
        "\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath \"\n",
        "\n",
        "import traceback\n",
        "\n",
        "Data_Cleanup_SP02_LowCutOff = 50  #If the SPO2 value at the time of APnea is below 60, it must be a bad data point. \n",
        "Data_Cleanup_HR_LowCutOff = 50\n",
        "AB_Model = \" \"\n",
        "\n",
        "paths, folder_names = list_folders(startpath)\n",
        "print (paths)\n",
        "print (folder_names)\n",
        "\n",
        "PRINT_TABLES = False\n",
        "os.chdir(startpath)\n",
        "os.makedirs(\"Analysis_Files\", exist_ok=True)\n",
        "analysis_path = startpath + \"/Analysis_Files/\"\n",
        "os.chdir(analysis_path)\n",
        "# errors = pd.DataFrame (columns = ['Folder Name',\"Model\",'Exception', \"filename\", \"lineno\", \"funcname\", \"text\"])\n",
        "errors = pd.DataFrame ()\n",
        "df_overall_clinical_summary = pd.DataFrame ()\n",
        "df_overall_clinical_summary_detailed = pd.DataFrame ()\n",
        "\n",
        "i = 0;\n",
        "for path in paths:\n",
        "    folder_name = folder_names[i]\n",
        "    i += 1\n",
        "    print (\"on file \" + str(i) + ' of ' + str(len(paths)))\n",
        "    try:\n",
        "        print (\"Working on \" + folder_name)\n",
        "        os.chdir(analysis_path)\n",
        "        analysis_folder = \"Analysis - \" + folder_name\n",
        "        os.makedirs(analysis_folder, exist_ok=True)\n",
        "        current_analysis_folder_path = analysis_path+ analysis_folder\n",
        "        os.chdir(current_analysis_folder_path)\n",
        "        \n",
        "        df_j, df_d, df_s = createDataTables (path)\n",
        "        # print (\"df_j - main\")\n",
        "        # display (df_j)\n",
        "        # createPlots (df_j)\n",
        "        # createSummaryTables (df_j,df_s)\n",
        "        #####\n",
        "        df_current_clinical_summary = pd.DataFrame ()\n",
        "        df_current_clinical_summary = createClinicalSummaryTable (df_j, folder_name)\n",
        "        df_current_clinical_summary[\"path\"] = path[-100:]\n",
        "        df_overall_clinical_summary = pd.concat([df_overall_clinical_summary, df_current_clinical_summary])\n",
        "        os.chdir(analysis_path)\n",
        "        df_overall_clinical_summary.to_excel (\"Overall Clinical Summary.xlsx\")\n",
        "        \n",
        "        #####\n",
        "        df_current_clinical_summary_detailed = df_current_clinical_summary\n",
        "        # df_current_clinical_summary_detailed[\"file_list\"] = file_list\n",
        "        df_current_clinical_summary_detailed[\"model\"] = AB_Model;\n",
        "        df_current_clinical_summary_detailed[\"data date-time\"] = df_j[\"Data Date-Time\"].iloc[0];\n",
        "        df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "        df_overall_clinical_summary_detailed.to_excel (\"Overall Clinical Summary - Detailed.xlsx\")\n",
        "        print (folder_name + \" success!\")\n",
        "\n",
        "    except Exception as exc: \n",
        "         print (\"ERROR FOR \" + folder_name + \":\")\n",
        "         filename, lineno, funcname, text = traceback.extract_tb(exc.__traceback__)[-1]\n",
        "         print (exc)\n",
        "         short_path = path[-100:]\n",
        "         current_error = pd.DataFrame (data = {'short_path': [short_path], 'Folder Name':[folder_name], \"Model\": [AB_Model], 'Exception':[exc], \"filename\": [filename], \"lineno\": [lineno], \"funcname\": [funcname], \"text\": [text], 'data header': [header], 'settings header': [settings_header], 'numcommas':[number_of_commas]})\n",
        "         errors = errors.append (current_error,ignore_index = True);\n",
        "         os.chdir(analysis_path)\n",
        "         errors.to_excel (\"Error Summary.xlsx\")\n",
        "\n",
        "\n",
        "print (\"errors table:\")\n",
        "display (errors)\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "RtVUyZ_9ZcLO",
        "outputId": "75ec02c6-c4dc-4ae9-d986-c967a6c62422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "RtVUyZ_9ZcLO",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Parvati_intervention/Parvathi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Johnsi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Surya/surya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Suma/suma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sayeda', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Geetha/Geetha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Shobha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Vaishali', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sudha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Remi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Humera', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Aruna', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Anusha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 1/BO Tadamarri twin 1 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Shwetha 2', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Ayesha Banu', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Manjula', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Prema/BO Prema Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /stj70221oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701/stj703_21oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702/stj70121oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Stj03_01-sep', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ702_Intervention_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ701_Placebo_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 2/BO Tadamari twin 2 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Chandrakala Twin 1/BO Chandrakala Twin 1 Raw Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Noor Fathima/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath /Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sravanthi/AB Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/VaraLaxmi/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sunitha/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai/Raw data of AB device', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Tehseen', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Vani/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ramanamma/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Saraswati/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Hafsa/AB Device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Mounika/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Bhavani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Heena/ApneBoot Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ahmedi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Jyothi/Apneboot data']\n",
            "['Parvathi', 'Johnsi', 'surya', 'suma', 'Sayeda', 'Sneha', 'Geetha', 'Bhagya New', 'Soniya Mary', 'Shobha', 'Vaishali', 'Sujatha', 'Sudha', 'Remi', 'Sushma', 'Anitha', 'Baby of  Sujatha', 'Baby of Pavithra_placebo', 'Humera', 'Bhagya', 'Sushma', 'Aruna', 'Anitha', 'Anusha', 'Baby of Pavithra_placebo', 'Intervention_Unclear data', 'BO Hemabindu 2 data', 'BO Tadamarri twin 1 Raw data', 'BO Shwetha 2', 'BO Anitha', 'BO Ayesha Banu', 'BO Manjula', 'BO Prema Raw data', 'stj70221oct', 'stj703_21oct', 'st701', 'stj70121oct', 'st702', 'Stj03_01-sep', 'STJ702_Intervention_Clinical data_24_July-2020_4PM', 'STJ701_Placebo_Clinical data_24_July-2020_4PM', 'Baby 1', 'BO Tadamari twin 2 Raw data', 'BO Chandrakala Twin 1 Raw Data', 'Apneboot device data', 'Apneboot data', 'AB Data', 'AB device data', 'Apneboot device data', 'Raw data of AB device', 'Tehseen', 'AB device data', 'Apneboot data', 'AB device data', 'AB Device data', 'Apneboot data', 'Bhavani', 'ApneBoot Data', 'Ahmedi', 'Apneboot data']\n",
            "on file 1 of 60\n",
            "Working on Parvathi\n",
            "['27log29.csv']\n",
            "ERROR FOR Parvathi:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 2 of 60\n",
            "Working on Johnsi\n",
            "['LOG00186.TXT']\n",
            "ERROR FOR Johnsi:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 3 of 60\n",
            "Working on surya\n",
            "['10log22.csv', '12log5.csv']\n",
            "ERROR FOR surya:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 4 of 60\n",
            "Working on suma\n",
            "['10log7.csv', '12log2.csv', '7log11.csv', '8log1.csv']\n",
            "ERROR FOR suma:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 5 of 60\n",
            "Working on Sayeda\n",
            "['14log1.csv', '16log1.csv']\n",
            "ERROR FOR Sayeda:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 6 of 60\n",
            "Working on Sneha\n",
            "['12log5 - made from mona xls file.csv']\n",
            "ERROR FOR Sneha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-9b5a1147e6dc>:71: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  errors = errors.append (current_error,ignore_index = True);\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on file 7 of 60\n",
            "Working on Geetha\n",
            "['LOG00184 (1).TXT', 'LOG00185 (1).TXT', 'LOG00187 (1).TXT']\n",
            "ERROR FOR Geetha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 8 of 60\n",
            "Working on Bhagya New\n",
            "['LOG00061.TXT', 'LOG00062 (1).TXT', 'LOG00063.TXT']\n",
            "ERROR FOR Bhagya New:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 9 of 60\n",
            "Working on Soniya Mary\n",
            "['24log15.csv', '24log29.csv', '24log35.csv', '24log42.csv', '24log6.csv', '4log10.csv', '4log14.csv', '4log7.csv', '6log13.csv', '6log6.csv', '7log6.csv']\n",
            "ERROR FOR Soniya Mary:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 10 of 60\n",
            "Working on Shobha\n",
            "['LOG00035.TXT', 'LOG00036.TXT', 'LOG00038.TXT', 'LOG00039.TXT']\n",
            "ERROR FOR Shobha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 11 of 60\n",
            "Working on Vaishali\n",
            "['14log18.csv']\n",
            "ERROR FOR Vaishali:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 12 of 60\n",
            "Working on Sujatha\n",
            "['LOG00089 (2).TXT', 'LOG00090 (1).TXT', 'LOG00184.TXT', 'LOG00185.TXT']\n",
            "ERROR FOR Sujatha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 13 of 60\n",
            "Working on Sudha\n",
            "['1log7.csv']\n",
            "ERROR FOR Sudha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 14 of 60\n",
            "Working on Remi\n",
            "['LOG00097.TXT', 'LOG00098.TXT', 'LOG00099.TXT', 'LOG00100.TXT']\n",
            "ERROR FOR Remi:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 15 of 60\n",
            "Working on Sushma\n",
            "['12log23.csv', '14log18.csv']\n",
            "ERROR FOR Sushma:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 16 of 60\n",
            "Working on Anitha\n",
            "['28log.csv', '29log8.csv']\n",
            "ERROR FOR Anitha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 17 of 60\n",
            "Working on Baby of  Sujatha\n",
            "['LOG00089 (2).TXT', 'LOG00090 (1).TXT']\n",
            "ERROR FOR Baby of  Sujatha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 18 of 60\n",
            "Working on Baby of Pavithra_placebo\n",
            "['2log7.csv', '30log2.csv']\n",
            "ERROR FOR Baby of Pavithra_placebo:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 19 of 60\n",
            "Working on Humera\n",
            "['LOG00101.TXT', 'LOG00102.TXT', 'LOG00103.TXT', 'LOG00104.TXT', 'LOG00105.TXT', 'LOG00106.TXT']\n",
            "ERROR FOR Humera:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 20 of 60\n",
            "Working on Bhagya\n",
            "['LOG00041.TXT', 'LOG00050.TXT', 'LOG00051.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00056.TXT', 'LOG00057.TXT', 'LOG00058.TXT', 'LOG00059.TXT']\n",
            "ERROR FOR Bhagya:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 21 of 60\n",
            "Working on Sushma\n",
            "['12log23.csv']\n",
            "ERROR FOR Sushma:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 22 of 60\n",
            "Working on Aruna\n",
            "['30log2.csv']\n",
            "ERROR FOR Aruna:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 23 of 60\n",
            "Working on Anitha\n",
            "['28log.csv', '29log8.csv']\n",
            "ERROR FOR Anitha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 24 of 60\n",
            "Working on Anusha\n",
            "['29log8.csv']\n",
            "ERROR FOR Anusha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 25 of 60\n",
            "Working on Baby of Pavithra_placebo\n",
            "['2log7.csv']\n",
            "ERROR FOR Baby of Pavithra_placebo:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 26 of 60\n",
            "Working on Intervention_Unclear data\n",
            "['LOG00105.TXT', 'LOG00106.TXT', 'LOG00107.TXT', 'LOG00108.TXT', 'LOG00109.TXT', 'LOG00110.TXT', 'LOG00111.TXT', 'LOG00112.TXT']\n",
            "ERROR FOR Intervention_Unclear data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 27 of 60\n",
            "Working on BO Hemabindu 2 data\n",
            "['LOG00105.TXT', 'LOG00109.TXT', 'LOG00110.TXT', 'LOG00111.TXT']\n",
            "ERROR FOR BO Hemabindu 2 data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 28 of 60\n",
            "Working on BO Tadamarri twin 1 Raw data\n",
            "['LOG00052.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00055.TXT', 'LOG00056.TXT', 'LOG00090.TXT']\n",
            "ERROR FOR BO Tadamarri twin 1 Raw data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 29 of 60\n",
            "Working on BO Shwetha 2\n",
            "['LOG00117.TXT', 'LOG00118.TXT', 'LOG00119.TXT', 'LOG00120.TXT', 'LOG00479.TXT', 'LOG00480.TXT', 'LOG00481.TXT', 'LOG00482.TXT', 'LOG00483.TXT']\n",
            "ERROR FOR BO Shwetha 2:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 30 of 60\n",
            "Working on BO Anitha\n",
            "['LOG00045.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT']\n",
            "ERROR FOR BO Anitha:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 31 of 60\n",
            "Working on BO Ayesha Banu\n",
            "['LOG00121.TXT', 'LOG00122.TXT']\n",
            "ERROR FOR BO Ayesha Banu:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 32 of 60\n",
            "Working on BO Manjula\n",
            "['LOG00114.TXT', 'LOG00115.TXT', 'LOG00116.TXT', 'LOG00478.TXT', 'LOG00484.TXT', 'LOG00485.TXT', 'LOG00486.TXT', 'LOG00487.TXT']\n",
            "ERROR FOR BO Manjula:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 33 of 60\n",
            "Working on BO Prema Raw data\n",
            "['LOG00474.TXT', 'LOG00475.TXT']\n",
            "ERROR FOR BO Prema Raw data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 34 of 60\n",
            "Working on stj70221oct\n",
            "['LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT', 'LOG00043.TXT', 'LOG00044.TXT', 'LOG00045.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT', 'LOG00049.TXT', 'LOG00050.TXT', 'LOG00051.TXT', 'LOG00052.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00055.TXT', 'LOG00056.TXT', 'LOG00057.TXT', 'LOG00058.TXT', 'LOG00059.TXT', 'LOG00060.TXT', 'LOG00061.TXT', 'LOG00062.TXT', 'LOG00063.TXT', 'LOG00064.TXT', 'LOG00065.TXT', 'LOG00066.TXT', 'LOG00067.TXT', 'LOG00068.TXT', 'LOG00069.TXT', 'LOG00070.TXT', 'LOG00071.TXT', 'LOG00072.TXT', 'LOG00073.TXT', 'LOG00074.TXT', 'LOG00075.TXT', 'LOG00076.TXT', 'LOG00077.TXT', 'LOG00078.TXT', 'LOG00079.TXT', 'LOG00080.TXT', 'LOG00081.TXT', 'LOG00082.TXT', 'LOG00083.TXT', 'LOG00084.TXT', 'LOG00085.TXT', 'LOG00086.TXT', 'LOG00087.TXT', 'LOG00088.TXT', 'LOG00089.TXT', 'LOG00090.TXT', 'LOG00091.TXT', 'LOG00092.TXT', 'LOG00093.TXT', 'LOG00094.TXT', 'LOG00095.TXT', 'LOG00096.TXT', 'LOG00097.TXT', 'LOG00098.TXT', 'LOG00099.TXT', 'LOG00100.TXT', 'LOG00101.TXT', 'LOG00102.TXT', 'LOG00103.TXT', 'LOG00104.TXT', 'LOG00105.TXT', 'LOG00106.TXT', 'LOG00107.TXT', 'LOG00108.TXT', 'LOG00109.TXT', 'LOG00110.TXT', 'LOG00111.TXT', 'LOG00112.TXT', 'LOG00113.TXT', 'LOG00114.TXT', 'LOG00115.TXT', 'LOG00116.TXT', 'LOG00117.TXT', 'LOG00118.TXT', 'LOG00119.TXT', 'LOG00120.TXT', 'LOG00121.TXT', 'LOG00122.TXT', 'LOG01291.TXT']\n",
            "ERROR FOR stj70221oct:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 35 of 60\n",
            "Working on stj703_21oct\n",
            "['LOG00000.TXT', 'LOG00001.TXT', 'LOG00002.TXT', 'LOG00003.TXT', 'LOG00004.TXT', 'LOG00005.TXT', 'LOG00006.TXT', 'LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT', 'LOG00043.TXT', 'LOG00044.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT', 'LOG00049.TXT']\n",
            "ERROR FOR stj703_21oct:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 36 of 60\n",
            "Working on st701\n",
            "['LOG00394.TXT', 'LOG00395.TXT', 'LOG00396.TXT', 'LOG00397.TXT', 'LOG00398.TXT', 'LOG00399.TXT', 'LOG00400.TXT', 'LOG00401.TXT', 'LOG00402.TXT', 'LOG00403.TXT', 'LOG00404.TXT', 'LOG00405.TXT', 'LOG00406.TXT', 'LOG00407.TXT', 'LOG00408.TXT', 'LOG00409.TXT', 'LOG00410.TXT', 'LOG00411.TXT', 'LOG00412.TXT', 'LOG00413.TXT', 'LOG00414.TXT', 'LOG00415.TXT', 'LOG00416.TXT', 'LOG00417.TXT', 'LOG00418.TXT', 'LOG00419.TXT', 'LOG00420.TXT', 'LOG00421.TXT', 'LOG00422.TXT', 'LOG00423.TXT', 'LOG00424.TXT', 'LOG00425.TXT', 'LOG00426.TXT', 'LOG00427.TXT', 'LOG00428.TXT', 'LOG00429.TXT', 'LOG00430.TXT', 'LOG00431.TXT', 'LOG00432.TXT', 'LOG00433.TXT', 'LOG00434.TXT', 'LOG00435.TXT', 'LOG00436.TXT', 'LOG00437.TXT', 'LOG00438.TXT', 'LOG00439.TXT', 'LOG00440.TXT', 'LOG00441.TXT', 'LOG00442.TXT', 'LOG00443.TXT', 'LOG00444.TXT', 'LOG00445.TXT', 'LOG00446.TXT', 'LOG00447.TXT', 'LOG00448.TXT', 'LOG00449.TXT', 'LOG00450.TXT', 'LOG00451.TXT', 'LOG00452.TXT', 'LOG00453.TXT', 'LOG00454.TXT', 'LOG00455.TXT', 'LOG00456.TXT', 'LOG00457.TXT', 'LOG00458.TXT', 'LOG00459.TXT', 'LOG00460.TXT', 'LOG00461.TXT', 'LOG00462.TXT', 'LOG00463.TXT', 'LOG00464.TXT', 'LOG00465.TXT', 'LOG00466.TXT', 'LOG00467.TXT', 'LOG00468.TXT', 'LOG00469.TXT', 'LOG00470.TXT', 'LOG00471.TXT', 'LOG00472.TXT', 'LOG00473.TXT', 'LOG00474.TXT', 'LOG00475.TXT']\n",
            "ERROR FOR st701:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 37 of 60\n",
            "Working on stj70121oct\n",
            "['LOG00394.TXT', 'LOG00395.TXT', 'LOG00396.TXT', 'LOG00397.TXT', 'LOG00398.TXT', 'LOG00399.TXT', 'LOG00400.TXT', 'LOG00401.TXT', 'LOG00402.TXT', 'LOG00403.TXT', 'LOG00404.TXT', 'LOG00405.TXT', 'LOG00406.TXT', 'LOG00407.TXT', 'LOG00408.TXT', 'LOG00409.TXT', 'LOG00410.TXT', 'LOG00411.TXT', 'LOG00412.TXT', 'LOG00413.TXT', 'LOG00414.TXT', 'LOG00415.TXT', 'LOG00416.TXT', 'LOG00417.TXT', 'LOG00418.TXT', 'LOG00419.TXT', 'LOG00420.TXT', 'LOG00421.TXT', 'LOG00422.TXT', 'LOG00423.TXT', 'LOG00424.TXT', 'LOG00425.TXT', 'LOG00426.TXT', 'LOG00427.TXT', 'LOG00428.TXT', 'LOG00429.TXT', 'LOG00430.TXT', 'LOG00431.TXT', 'LOG00432.TXT', 'LOG00433.TXT', 'LOG00434.TXT', 'LOG00435.TXT', 'LOG00436.TXT', 'LOG00437.TXT', 'LOG00438.TXT', 'LOG00439.TXT', 'LOG00440.TXT', 'LOG00441.TXT', 'LOG00442.TXT', 'LOG00443.TXT', 'LOG00444.TXT', 'LOG00445.TXT', 'LOG00446.TXT', 'LOG00447.TXT', 'LOG00448.TXT', 'LOG00449.TXT', 'LOG00450.TXT', 'LOG00451.TXT', 'LOG00452.TXT', 'LOG00453.TXT', 'LOG00454.TXT', 'LOG00455.TXT', 'LOG00456.TXT', 'LOG00457.TXT', 'LOG00458.TXT', 'LOG00459.TXT', 'LOG00460.TXT', 'LOG00461.TXT', 'LOG00462.TXT', 'LOG00463.TXT', 'LOG00464.TXT', 'LOG00465.TXT', 'LOG00466.TXT', 'LOG00467.TXT', 'LOG00468.TXT', 'LOG00469.TXT', 'LOG00470.TXT', 'LOG00471.TXT', 'LOG00472.TXT', 'LOG00473.TXT', 'LOG00474.TXT', 'LOG00475.TXT', 'LOG00476.TXT', 'LOG00477.TXT', 'LOG00478.TXT', 'LOG00479.TXT', 'LOG00480.TXT', 'LOG00481.TXT', 'LOG00482.TXT', 'LOG00483.TXT', 'LOG00484.TXT', 'LOG00485.TXT', 'LOG00486.TXT', 'LOG00487.TXT']\n",
            "ERROR FOR stj70121oct:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 38 of 60\n",
            "Working on st702\n",
            "['LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT', 'LOG00043.TXT', 'LOG00044.TXT', 'LOG00045.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT', 'LOG00049.TXT', 'LOG00050.TXT', 'LOG00051.TXT', 'LOG00052.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00055.TXT', 'LOG00056.TXT', 'LOG00057.TXT', 'LOG00058.TXT', 'LOG00059.TXT', 'LOG00060.TXT', 'LOG00061.TXT', 'LOG00062.TXT', 'LOG00063.TXT', 'LOG00064.TXT', 'LOG00065.TXT', 'LOG00066.TXT', 'LOG00067.TXT', 'LOG00068.TXT', 'LOG00069.TXT', 'LOG00070.TXT', 'LOG00071.TXT', 'LOG00072.TXT', 'LOG00073.TXT', 'LOG00074.TXT', 'LOG00075.TXT', 'LOG00076.TXT', 'LOG00077.TXT', 'LOG00078.TXT', 'LOG00079.TXT', 'LOG00080.TXT', 'LOG00081.TXT', 'LOG00082.TXT', 'LOG00083.TXT', 'LOG00084.TXT', 'LOG00085.TXT', 'LOG00086.TXT', 'LOG00087.TXT', 'LOG00088.TXT', 'LOG00089.TXT', 'LOG00090.TXT', 'LOG00091.TXT', 'LOG00092.TXT', 'LOG00093.TXT', 'LOG00094.TXT', 'LOG00095.TXT', 'LOG00096.TXT', 'LOG00097.TXT', 'LOG00098.TXT', 'LOG00099.TXT', 'LOG00100.TXT', 'LOG00101.TXT', 'LOG00102.TXT', 'LOG00103.TXT', 'LOG00104.TXT', 'LOG00105.TXT', 'LOG01291.TXT']\n",
            "ERROR FOR st702:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 39 of 60\n",
            "Working on Stj03_01-sep\n",
            "['LOG00000.TXT', 'LOG00001.TXT', 'LOG00002.TXT', 'LOG00003.TXT', 'LOG00004.TXT', 'LOG00005.TXT', 'LOG00006.TXT', 'LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT']\n",
            "ERROR FOR Stj03_01-sep:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 40 of 60\n",
            "Working on STJ702_Intervention_Clinical data_24_July-2020_4PM\n",
            "['LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT', 'LOG00043.TXT', 'LOG00044.TXT', 'LOG00045.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT', 'LOG00049.TXT', 'LOG00050.TXT', 'LOG00051.TXT', 'LOG00052.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00055.TXT', 'LOG00056.TXT', 'LOG00057.TXT', 'LOG00058.TXT', 'LOG00059.TXT', 'LOG00060.TXT', 'LOG00061.TXT', 'LOG00062.TXT', 'LOG00063.TXT', 'LOG00064.TXT', 'LOG00065.TXT', 'LOG00066.TXT', 'LOG00067.TXT', 'LOG00068.TXT', 'LOG00069.TXT', 'LOG00070.TXT', 'LOG00071.TXT', 'LOG00072.TXT', 'LOG00073.TXT', 'LOG00074.TXT', 'LOG00075.TXT', 'LOG00076.TXT', 'LOG00077.TXT', 'LOG00078.TXT', 'LOG00079.TXT', 'LOG00080.TXT', 'LOG00081.TXT', 'LOG00082.TXT', 'LOG00083.TXT', 'LOG00084.TXT', 'LOG00085.TXT', 'LOG00086.TXT', 'LOG00087.TXT', 'LOG00088.TXT', 'LOG00089.TXT', 'LOG00090.TXT', 'LOG00091.TXT', 'LOG00092.TXT', 'LOG00093.TXT', 'LOG01291.TXT']\n",
            "ERROR FOR STJ702_Intervention_Clinical data_24_July-2020_4PM:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 41 of 60\n",
            "Working on STJ701_Placebo_Clinical data_24_July-2020_4PM\n",
            "['LOG00007.TXT', 'LOG00008.TXT', 'LOG00009.TXT', 'LOG00010.TXT', 'LOG00011.TXT', 'LOG00012.TXT', 'LOG00013.TXT', 'LOG00014.TXT', 'LOG00015.TXT', 'LOG00016.TXT', 'LOG00017.TXT', 'LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT']\n",
            "ERROR FOR STJ701_Placebo_Clinical data_24_July-2020_4PM:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 42 of 60\n",
            "Working on Baby 1\n",
            "['LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT']\n",
            "ERROR FOR Baby 1:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 43 of 60\n",
            "Working on BO Tadamari twin 2 Raw data\n",
            "['LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT']\n",
            "ERROR FOR BO Tadamari twin 2 Raw data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 44 of 60\n",
            "Working on BO Chandrakala Twin 1 Raw Data\n",
            "['LOG00018.TXT', 'LOG00019.TXT', 'LOG00020.TXT', 'LOG00021.TXT', 'LOG00022.TXT', 'LOG00023.TXT', 'LOG00024.TXT', 'LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT', 'LOG00028.TXT', 'LOG00029.TXT', 'LOG00030.TXT', 'LOG00031.TXT', 'LOG00032.TXT', 'LOG00033.TXT', 'LOG00034.TXT', 'LOG00035.TXT', 'LOG00036.TXT', 'LOG00037.TXT', 'LOG00038.TXT', 'LOG00039.TXT', 'LOG00040.TXT', 'LOG00041.TXT', 'LOG00042.TXT']\n",
            "ERROR FOR BO Chandrakala Twin 1 Raw Data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 45 of 60\n",
            "Working on Apneboot device data\n",
            "['LOG00004.TXT']\n",
            "ERROR FOR Apneboot device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 46 of 60\n",
            "Working on Apneboot data\n",
            "['LOG00000.TXT', 'LOG00001.TXT', 'LOG00002.TXT', 'LOG00003.TXT', 'LOG00004.TXT', 'LOG65284.TXT', 'LOG65285.TXT', 'LOG65286.TXT', 'LOG65287.TXT', 'LOG65288.TXT', 'LOG65289.TXT', 'LOG65290.TXT', 'LOG65291.TXT', 'LOG65292.TXT', 'LOG65293.TXT', 'LOG65294.TXT', 'LOG65295.TXT', 'LOG65296.TXT', 'LOG65297.TXT', 'LOG65298.TXT', 'LOG65299.TXT', 'LOG65300.TXT', 'LOG65301.TXT']\n",
            "ERROR FOR Apneboot data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 47 of 60\n",
            "Working on AB Data\n",
            "['LOG00012.TXT']\n",
            "ERROR FOR AB Data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 48 of 60\n",
            "Working on AB device data\n",
            "['LOG01296.TXT']\n",
            "ERROR FOR AB device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 49 of 60\n",
            "Working on Apneboot device data\n",
            "['LOG00027.TXT', 'LOG00028.TXT']\n",
            "ERROR FOR Apneboot device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 50 of 60\n",
            "Working on Raw data of AB device\n",
            "['LOG00014.TXT', 'LOG00015.TXT', 'LOG00017.TXT', 'LOG00021.TXT']\n",
            "ERROR FOR Raw data of AB device:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 51 of 60\n",
            "Working on Tehseen\n",
            "['LOG01299.TXT', 'LOG01300.TXT']\n",
            "ERROR FOR Tehseen:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 52 of 60\n",
            "Working on AB device data\n",
            "['LOG01298.TXT']\n",
            "ERROR FOR AB device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 53 of 60\n",
            "Working on Apneboot data\n",
            "['LOG00037.TXT']\n",
            "ERROR FOR Apneboot data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 54 of 60\n",
            "Working on AB device data\n",
            "['LOG65294.TXT']\n",
            "ERROR FOR AB device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 55 of 60\n",
            "Working on AB Device data\n",
            "['LOG00009.TXT', 'LOG01295.TXT']\n",
            "ERROR FOR AB Device data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 56 of 60\n",
            "Working on Apneboot data\n",
            "['LOG00025.TXT', 'LOG00026.TXT', 'LOG00027.TXT']\n",
            "ERROR FOR Apneboot data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 57 of 60\n",
            "Working on Bhavani\n",
            "['LOG00028.TXT']\n",
            "ERROR FOR Bhavani:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 58 of 60\n",
            "Working on ApneBoot Data\n",
            "['LOG00004.TXT', 'LOG00006.TXT']\n",
            "ERROR FOR ApneBoot Data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 59 of 60\n",
            "Working on Ahmedi\n",
            "['LOG00014.TXT']\n",
            "ERROR FOR Ahmedi:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "on file 60 of 60\n",
            "Working on Apneboot data\n",
            "['LOG01306.TXT']\n",
            "ERROR FOR Apneboot data:\n",
            "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.\n",
            "errors table:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           short_path  \\\n",
              "0   al Validation/RCT ApneBoot/St. Johns Phase 1 D...   \n",
              "1   eport/Product Validation/Clinical Validation/R...   \n",
              "2   /Product Validation/Clinical Validation/RCT Ap...   \n",
              "3   rt/Product Validation/Clinical Validation/RCT ...   \n",
              "4   eport/Product Validation/Clinical Validation/R...   \n",
              "5   Report/Product Validation/Clinical Validation/...   \n",
              "6   alidation/Clinical Validation/RCT ApneBoot/St....   \n",
              "7   Report/Product Validation/Clinical Validation/...   \n",
              "8   eport/Product Validation/Clinical Validation/R...   \n",
              "9   ion Report/Product Validation/Clinical Validat...   \n",
              "10  n Report/Product Validation/Clinical Validatio...   \n",
              "11  on Report/Product Validation/Clinical Validati...   \n",
              "12  tion Report/Product Validation/Clinical Valida...   \n",
              "13  ation Report/Product Validation/Clinical Valid...   \n",
              "14  dation/Clinical Validation/RCT ApneBoot/St. Jo...   \n",
              "15  ation/Clinical Validation/RCT ApneBoot/St. Joh...   \n",
              "16   Validation/Clinical Validation/RCT ApneBoot/S...   \n",
              "17  ion/Clinical Validation/RCT ApneBoot/St. Johns...   \n",
              "18  ion Report/Product Validation/Clinical Validat...   \n",
              "19  ion Report/Product Validation/Clinical Validat...   \n",
              "20  uct Validation/Clinical Validation/RCT ApneBoo...   \n",
              "21  tion Report/Product Validation/Clinical Valida...   \n",
              "22  ct Validation/Clinical Validation/RCT ApneBoot...   \n",
              "23  ion Report/Product Validation/Clinical Validat...   \n",
              "24   Validation/Clinical Validation/RCT ApneBoot/S...   \n",
              "25  ion/Clinical Validation/RCT ApneBoot/St.Johns ...   \n",
              "26  cal Validation/RCT ApneBoot/St.Johns Phase 2 D...   \n",
              "27  n/RCT ApneBoot/St.Johns Phase 2 Data( >june 30...   \n",
              "28  oduct Validation/Clinical Validation/RCT ApneB...   \n",
              "29  /Product Validation/Clinical Validation/RCT Ap...   \n",
              "30  uct Validation/Clinical Validation/RCT ApneBoo...   \n",
              "31  Product Validation/Clinical Validation/RCT Apn...   \n",
              "32  on/Clinical Validation/RCT ApneBoot/St.Johns P...   \n",
              "33  n/Clinical Validation/RCT ApneBoot/St.Johns Ph...   \n",
              "34  cal Validation/RCT ApneBoot/St.Johns Phase 2 D...   \n",
              "35  idation/Clinical Validation/RCT ApneBoot/St.Jo...   \n",
              "36  ical Validation/RCT ApneBoot/St.Johns Phase 2 ...   \n",
              "37  idation/Clinical Validation/RCT ApneBoot/St.Jo...   \n",
              "38  /Clinical Validation/RCT ApneBoot/St.Johns Pha...   \n",
              "39  ohns Phase 2 Data( >june 30,2020)/Extracted da...   \n",
              "40  /St.Johns Phase 2 Data( >june 30,2020)/Extract...   \n",
              "41  dation/Clinical Validation/RCT ApneBoot/St.Joh...   \n",
              "42  on/RCT ApneBoot/St.Johns Phase 2 Data( >june 3...   \n",
              "43   ApneBoot/St.Johns Phase 2 Data( >june 30,2020...   \n",
              "44  eport/Product Validation/Clinical Validation/R...   \n",
              "45  Validation Report/Product Validation/Clinical ...   \n",
              "46  ign Validation Report/Product Validation/Clini...   \n",
              "47  idation Report/Product Validation/Clinical Val...   \n",
              "48  ion Report/Product Validation/Clinical Validat...   \n",
              "49  on Report/Product Validation/Clinical Validati...   \n",
              "50  1-28 - Design Validation Report/Product Valida...   \n",
              "51  n Validation Report/Product Validation/Clinica...   \n",
              "52  lidation Report/Product Validation/Clinical Va...   \n",
              "53  idation Report/Product Validation/Clinical Val...   \n",
              "54   Validation Report/Product Validation/Clinical...   \n",
              "55  Validation Report/Product Validation/Clinical ...   \n",
              "56  1-28 - Design Validation Report/Product Valida...   \n",
              "57  n Validation Report/Product Validation/Clinica...   \n",
              "58  01-28 - Design Validation Report/Product Valid...   \n",
              "59   Validation Report/Product Validation/Clinical...   \n",
              "\n",
              "                                          Folder Name Model  \\\n",
              "0                                            Parvathi         \n",
              "1                                              Johnsi         \n",
              "2                                               surya         \n",
              "3                                                suma         \n",
              "4                                              Sayeda         \n",
              "5                                               Sneha         \n",
              "6                                              Geetha         \n",
              "7                                          Bhagya New         \n",
              "8                                         Soniya Mary         \n",
              "9                                              Shobha         \n",
              "10                                           Vaishali         \n",
              "11                                            Sujatha         \n",
              "12                                              Sudha         \n",
              "13                                               Remi         \n",
              "14                                             Sushma         \n",
              "15                                             Anitha         \n",
              "16                                   Baby of  Sujatha         \n",
              "17                           Baby of Pavithra_placebo         \n",
              "18                                             Humera         \n",
              "19                                             Bhagya         \n",
              "20                                             Sushma         \n",
              "21                                              Aruna         \n",
              "22                                             Anitha         \n",
              "23                                             Anusha         \n",
              "24                           Baby of Pavithra_placebo         \n",
              "25                          Intervention_Unclear data         \n",
              "26                                BO Hemabindu 2 data         \n",
              "27                       BO Tadamarri twin 1 Raw data         \n",
              "28                                       BO Shwetha 2         \n",
              "29                                          BO Anitha         \n",
              "30                                     BO Ayesha Banu         \n",
              "31                                         BO Manjula         \n",
              "32                                  BO Prema Raw data         \n",
              "33                                        stj70221oct         \n",
              "34                                       stj703_21oct         \n",
              "35                                              st701         \n",
              "36                                        stj70121oct         \n",
              "37                                              st702         \n",
              "38                                       Stj03_01-sep         \n",
              "39  STJ702_Intervention_Clinical data_24_July-2020...         \n",
              "40      STJ701_Placebo_Clinical data_24_July-2020_4PM         \n",
              "41                                             Baby 1         \n",
              "42                        BO Tadamari twin 2 Raw data         \n",
              "43                     BO Chandrakala Twin 1 Raw Data         \n",
              "44                               Apneboot device data         \n",
              "45                                      Apneboot data         \n",
              "46                                            AB Data         \n",
              "47                                     AB device data         \n",
              "48                               Apneboot device data         \n",
              "49                              Raw data of AB device         \n",
              "50                                            Tehseen         \n",
              "51                                     AB device data         \n",
              "52                                      Apneboot data         \n",
              "53                                     AB device data         \n",
              "54                                     AB Device data         \n",
              "55                                      Apneboot data         \n",
              "56                                            Bhavani         \n",
              "57                                      ApneBoot Data         \n",
              "58                                             Ahmedi         \n",
              "59                                      Apneboot data         \n",
              "\n",
              "                                            Exception  \\\n",
              "0   Specified \\n as separator or delimiter. This f...   \n",
              "1   Specified \\n as separator or delimiter. This f...   \n",
              "2   Specified \\n as separator or delimiter. This f...   \n",
              "3   Specified \\n as separator or delimiter. This f...   \n",
              "4   Specified \\n as separator or delimiter. This f...   \n",
              "5   Specified \\n as separator or delimiter. This f...   \n",
              "6   Specified \\n as separator or delimiter. This f...   \n",
              "7   Specified \\n as separator or delimiter. This f...   \n",
              "8   Specified \\n as separator or delimiter. This f...   \n",
              "9   Specified \\n as separator or delimiter. This f...   \n",
              "10  Specified \\n as separator or delimiter. This f...   \n",
              "11  Specified \\n as separator or delimiter. This f...   \n",
              "12  Specified \\n as separator or delimiter. This f...   \n",
              "13  Specified \\n as separator or delimiter. This f...   \n",
              "14  Specified \\n as separator or delimiter. This f...   \n",
              "15  Specified \\n as separator or delimiter. This f...   \n",
              "16  Specified \\n as separator or delimiter. This f...   \n",
              "17  Specified \\n as separator or delimiter. This f...   \n",
              "18  Specified \\n as separator or delimiter. This f...   \n",
              "19  Specified \\n as separator or delimiter. This f...   \n",
              "20  Specified \\n as separator or delimiter. This f...   \n",
              "21  Specified \\n as separator or delimiter. This f...   \n",
              "22  Specified \\n as separator or delimiter. This f...   \n",
              "23  Specified \\n as separator or delimiter. This f...   \n",
              "24  Specified \\n as separator or delimiter. This f...   \n",
              "25  Specified \\n as separator or delimiter. This f...   \n",
              "26  Specified \\n as separator or delimiter. This f...   \n",
              "27  Specified \\n as separator or delimiter. This f...   \n",
              "28  Specified \\n as separator or delimiter. This f...   \n",
              "29  Specified \\n as separator or delimiter. This f...   \n",
              "30  Specified \\n as separator or delimiter. This f...   \n",
              "31  Specified \\n as separator or delimiter. This f...   \n",
              "32  Specified \\n as separator or delimiter. This f...   \n",
              "33  Specified \\n as separator or delimiter. This f...   \n",
              "34  Specified \\n as separator or delimiter. This f...   \n",
              "35  Specified \\n as separator or delimiter. This f...   \n",
              "36  Specified \\n as separator or delimiter. This f...   \n",
              "37  Specified \\n as separator or delimiter. This f...   \n",
              "38  Specified \\n as separator or delimiter. This f...   \n",
              "39  Specified \\n as separator or delimiter. This f...   \n",
              "40  Specified \\n as separator or delimiter. This f...   \n",
              "41  Specified \\n as separator or delimiter. This f...   \n",
              "42  Specified \\n as separator or delimiter. This f...   \n",
              "43  Specified \\n as separator or delimiter. This f...   \n",
              "44  Specified \\n as separator or delimiter. This f...   \n",
              "45  Specified \\n as separator or delimiter. This f...   \n",
              "46  Specified \\n as separator or delimiter. This f...   \n",
              "47  Specified \\n as separator or delimiter. This f...   \n",
              "48  Specified \\n as separator or delimiter. This f...   \n",
              "49  Specified \\n as separator or delimiter. This f...   \n",
              "50  Specified \\n as separator or delimiter. This f...   \n",
              "51  Specified \\n as separator or delimiter. This f...   \n",
              "52  Specified \\n as separator or delimiter. This f...   \n",
              "53  Specified \\n as separator or delimiter. This f...   \n",
              "54  Specified \\n as separator or delimiter. This f...   \n",
              "55  Specified \\n as separator or delimiter. This f...   \n",
              "56  Specified \\n as separator or delimiter. This f...   \n",
              "57  Specified \\n as separator or delimiter. This f...   \n",
              "58  Specified \\n as separator or delimiter. This f...   \n",
              "59  Specified \\n as separator or delimiter. This f...   \n",
              "\n",
              "                                             filename  lineno  \\\n",
              "0   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "1   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "2   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "3   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "4   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "5   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "6   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "7   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "8   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "9   /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "10  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "11  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "12  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "13  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "14  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "15  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "16  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "17  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "18  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "19  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "20  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "21  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "22  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "23  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "24  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "25  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "26  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "27  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "28  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "29  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "30  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "31  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "32  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "33  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "34  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "35  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "36  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "37  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "38  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "39  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "40  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "41  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "42  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "43  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "44  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "45  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "46  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "47  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "48  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "49  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "50  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "51  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "52  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "53  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "54  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "55  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "56  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "57  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "58  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "59  /usr/local/lib/python3.9/dist-packages/pandas/...    1536   \n",
              "\n",
              "                 funcname               text data header settings header  \\\n",
              "0   _refine_defaults_read  raise ValueError(                               \n",
              "1   _refine_defaults_read  raise ValueError(                               \n",
              "2   _refine_defaults_read  raise ValueError(                               \n",
              "3   _refine_defaults_read  raise ValueError(                               \n",
              "4   _refine_defaults_read  raise ValueError(                               \n",
              "5   _refine_defaults_read  raise ValueError(                               \n",
              "6   _refine_defaults_read  raise ValueError(                               \n",
              "7   _refine_defaults_read  raise ValueError(                               \n",
              "8   _refine_defaults_read  raise ValueError(                               \n",
              "9   _refine_defaults_read  raise ValueError(                               \n",
              "10  _refine_defaults_read  raise ValueError(                               \n",
              "11  _refine_defaults_read  raise ValueError(                               \n",
              "12  _refine_defaults_read  raise ValueError(                               \n",
              "13  _refine_defaults_read  raise ValueError(                               \n",
              "14  _refine_defaults_read  raise ValueError(                               \n",
              "15  _refine_defaults_read  raise ValueError(                               \n",
              "16  _refine_defaults_read  raise ValueError(                               \n",
              "17  _refine_defaults_read  raise ValueError(                               \n",
              "18  _refine_defaults_read  raise ValueError(                               \n",
              "19  _refine_defaults_read  raise ValueError(                               \n",
              "20  _refine_defaults_read  raise ValueError(                               \n",
              "21  _refine_defaults_read  raise ValueError(                               \n",
              "22  _refine_defaults_read  raise ValueError(                               \n",
              "23  _refine_defaults_read  raise ValueError(                               \n",
              "24  _refine_defaults_read  raise ValueError(                               \n",
              "25  _refine_defaults_read  raise ValueError(                               \n",
              "26  _refine_defaults_read  raise ValueError(                               \n",
              "27  _refine_defaults_read  raise ValueError(                               \n",
              "28  _refine_defaults_read  raise ValueError(                               \n",
              "29  _refine_defaults_read  raise ValueError(                               \n",
              "30  _refine_defaults_read  raise ValueError(                               \n",
              "31  _refine_defaults_read  raise ValueError(                               \n",
              "32  _refine_defaults_read  raise ValueError(                               \n",
              "33  _refine_defaults_read  raise ValueError(                               \n",
              "34  _refine_defaults_read  raise ValueError(                               \n",
              "35  _refine_defaults_read  raise ValueError(                               \n",
              "36  _refine_defaults_read  raise ValueError(                               \n",
              "37  _refine_defaults_read  raise ValueError(                               \n",
              "38  _refine_defaults_read  raise ValueError(                               \n",
              "39  _refine_defaults_read  raise ValueError(                               \n",
              "40  _refine_defaults_read  raise ValueError(                               \n",
              "41  _refine_defaults_read  raise ValueError(                               \n",
              "42  _refine_defaults_read  raise ValueError(                               \n",
              "43  _refine_defaults_read  raise ValueError(                               \n",
              "44  _refine_defaults_read  raise ValueError(                               \n",
              "45  _refine_defaults_read  raise ValueError(                               \n",
              "46  _refine_defaults_read  raise ValueError(                               \n",
              "47  _refine_defaults_read  raise ValueError(                               \n",
              "48  _refine_defaults_read  raise ValueError(                               \n",
              "49  _refine_defaults_read  raise ValueError(                               \n",
              "50  _refine_defaults_read  raise ValueError(                               \n",
              "51  _refine_defaults_read  raise ValueError(                               \n",
              "52  _refine_defaults_read  raise ValueError(                               \n",
              "53  _refine_defaults_read  raise ValueError(                               \n",
              "54  _refine_defaults_read  raise ValueError(                               \n",
              "55  _refine_defaults_read  raise ValueError(                               \n",
              "56  _refine_defaults_read  raise ValueError(                               \n",
              "57  _refine_defaults_read  raise ValueError(                               \n",
              "58  _refine_defaults_read  raise ValueError(                               \n",
              "59  _refine_defaults_read  raise ValueError(                               \n",
              "\n",
              "    numcommas  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "5           0  \n",
              "6           0  \n",
              "7           0  \n",
              "8           0  \n",
              "9           0  \n",
              "10          0  \n",
              "11          0  \n",
              "12          0  \n",
              "13          0  \n",
              "14          0  \n",
              "15          0  \n",
              "16          0  \n",
              "17          0  \n",
              "18          0  \n",
              "19          0  \n",
              "20          0  \n",
              "21          0  \n",
              "22          0  \n",
              "23          0  \n",
              "24          0  \n",
              "25          0  \n",
              "26          0  \n",
              "27          0  \n",
              "28          0  \n",
              "29          0  \n",
              "30          0  \n",
              "31          0  \n",
              "32          0  \n",
              "33          0  \n",
              "34          0  \n",
              "35          0  \n",
              "36          0  \n",
              "37          0  \n",
              "38          0  \n",
              "39          0  \n",
              "40          0  \n",
              "41          0  \n",
              "42          0  \n",
              "43          0  \n",
              "44          0  \n",
              "45          0  \n",
              "46          0  \n",
              "47          0  \n",
              "48          0  \n",
              "49          0  \n",
              "50          0  \n",
              "51          0  \n",
              "52          0  \n",
              "53          0  \n",
              "54          0  \n",
              "55          0  \n",
              "56          0  \n",
              "57          0  \n",
              "58          0  \n",
              "59          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cc33455-bf59-491e-85b7-59b8d51057c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>short_path</th>\n",
              "      <th>Folder Name</th>\n",
              "      <th>Model</th>\n",
              "      <th>Exception</th>\n",
              "      <th>filename</th>\n",
              "      <th>lineno</th>\n",
              "      <th>funcname</th>\n",
              "      <th>text</th>\n",
              "      <th>data header</th>\n",
              "      <th>settings header</th>\n",
              "      <th>numcommas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>al Validation/RCT ApneBoot/St. Johns Phase 1 D...</td>\n",
              "      <td>Parvathi</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eport/Product Validation/Clinical Validation/R...</td>\n",
              "      <td>Johnsi</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/Product Validation/Clinical Validation/RCT Ap...</td>\n",
              "      <td>surya</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt/Product Validation/Clinical Validation/RCT ...</td>\n",
              "      <td>suma</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eport/Product Validation/Clinical Validation/R...</td>\n",
              "      <td>Sayeda</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Report/Product Validation/Clinical Validation/...</td>\n",
              "      <td>Sneha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>alidation/Clinical Validation/RCT ApneBoot/St....</td>\n",
              "      <td>Geetha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Report/Product Validation/Clinical Validation/...</td>\n",
              "      <td>Bhagya New</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>eport/Product Validation/Clinical Validation/R...</td>\n",
              "      <td>Soniya Mary</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ion Report/Product Validation/Clinical Validat...</td>\n",
              "      <td>Shobha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>n Report/Product Validation/Clinical Validatio...</td>\n",
              "      <td>Vaishali</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>on Report/Product Validation/Clinical Validati...</td>\n",
              "      <td>Sujatha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tion Report/Product Validation/Clinical Valida...</td>\n",
              "      <td>Sudha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ation Report/Product Validation/Clinical Valid...</td>\n",
              "      <td>Remi</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>dation/Clinical Validation/RCT ApneBoot/St. Jo...</td>\n",
              "      <td>Sushma</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ation/Clinical Validation/RCT ApneBoot/St. Joh...</td>\n",
              "      <td>Anitha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Validation/Clinical Validation/RCT ApneBoot/S...</td>\n",
              "      <td>Baby of  Sujatha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ion/Clinical Validation/RCT ApneBoot/St. Johns...</td>\n",
              "      <td>Baby of Pavithra_placebo</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ion Report/Product Validation/Clinical Validat...</td>\n",
              "      <td>Humera</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ion Report/Product Validation/Clinical Validat...</td>\n",
              "      <td>Bhagya</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>uct Validation/Clinical Validation/RCT ApneBoo...</td>\n",
              "      <td>Sushma</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>tion Report/Product Validation/Clinical Valida...</td>\n",
              "      <td>Aruna</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ct Validation/Clinical Validation/RCT ApneBoot...</td>\n",
              "      <td>Anitha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ion Report/Product Validation/Clinical Validat...</td>\n",
              "      <td>Anusha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Validation/Clinical Validation/RCT ApneBoot/S...</td>\n",
              "      <td>Baby of Pavithra_placebo</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ion/Clinical Validation/RCT ApneBoot/St.Johns ...</td>\n",
              "      <td>Intervention_Unclear data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>cal Validation/RCT ApneBoot/St.Johns Phase 2 D...</td>\n",
              "      <td>BO Hemabindu 2 data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>n/RCT ApneBoot/St.Johns Phase 2 Data( &gt;june 30...</td>\n",
              "      <td>BO Tadamarri twin 1 Raw data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>oduct Validation/Clinical Validation/RCT ApneB...</td>\n",
              "      <td>BO Shwetha 2</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/Product Validation/Clinical Validation/RCT Ap...</td>\n",
              "      <td>BO Anitha</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>uct Validation/Clinical Validation/RCT ApneBoo...</td>\n",
              "      <td>BO Ayesha Banu</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Product Validation/Clinical Validation/RCT Apn...</td>\n",
              "      <td>BO Manjula</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>on/Clinical Validation/RCT ApneBoot/St.Johns P...</td>\n",
              "      <td>BO Prema Raw data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>n/Clinical Validation/RCT ApneBoot/St.Johns Ph...</td>\n",
              "      <td>stj70221oct</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>cal Validation/RCT ApneBoot/St.Johns Phase 2 D...</td>\n",
              "      <td>stj703_21oct</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>idation/Clinical Validation/RCT ApneBoot/St.Jo...</td>\n",
              "      <td>st701</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>ical Validation/RCT ApneBoot/St.Johns Phase 2 ...</td>\n",
              "      <td>stj70121oct</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>idation/Clinical Validation/RCT ApneBoot/St.Jo...</td>\n",
              "      <td>st702</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>/Clinical Validation/RCT ApneBoot/St.Johns Pha...</td>\n",
              "      <td>Stj03_01-sep</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ohns Phase 2 Data( &gt;june 30,2020)/Extracted da...</td>\n",
              "      <td>STJ702_Intervention_Clinical data_24_July-2020...</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>/St.Johns Phase 2 Data( &gt;june 30,2020)/Extract...</td>\n",
              "      <td>STJ701_Placebo_Clinical data_24_July-2020_4PM</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>dation/Clinical Validation/RCT ApneBoot/St.Joh...</td>\n",
              "      <td>Baby 1</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>on/RCT ApneBoot/St.Johns Phase 2 Data( &gt;june 3...</td>\n",
              "      <td>BO Tadamari twin 2 Raw data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>ApneBoot/St.Johns Phase 2 Data( &gt;june 30,2020...</td>\n",
              "      <td>BO Chandrakala Twin 1 Raw Data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>eport/Product Validation/Clinical Validation/R...</td>\n",
              "      <td>Apneboot device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Validation Report/Product Validation/Clinical ...</td>\n",
              "      <td>Apneboot data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>ign Validation Report/Product Validation/Clini...</td>\n",
              "      <td>AB Data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>idation Report/Product Validation/Clinical Val...</td>\n",
              "      <td>AB device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ion Report/Product Validation/Clinical Validat...</td>\n",
              "      <td>Apneboot device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>on Report/Product Validation/Clinical Validati...</td>\n",
              "      <td>Raw data of AB device</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1-28 - Design Validation Report/Product Valida...</td>\n",
              "      <td>Tehseen</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>n Validation Report/Product Validation/Clinica...</td>\n",
              "      <td>AB device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>lidation Report/Product Validation/Clinical Va...</td>\n",
              "      <td>Apneboot data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>idation Report/Product Validation/Clinical Val...</td>\n",
              "      <td>AB device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Validation Report/Product Validation/Clinical...</td>\n",
              "      <td>AB Device data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Validation Report/Product Validation/Clinical ...</td>\n",
              "      <td>Apneboot data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1-28 - Design Validation Report/Product Valida...</td>\n",
              "      <td>Bhavani</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>n Validation Report/Product Validation/Clinica...</td>\n",
              "      <td>ApneBoot Data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>01-28 - Design Validation Report/Product Valid...</td>\n",
              "      <td>Ahmedi</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Validation Report/Product Validation/Clinical...</td>\n",
              "      <td>Apneboot data</td>\n",
              "      <td></td>\n",
              "      <td>Specified \\n as separator or delimiter. This f...</td>\n",
              "      <td>/usr/local/lib/python3.9/dist-packages/pandas/...</td>\n",
              "      <td>1536</td>\n",
              "      <td>_refine_defaults_read</td>\n",
              "      <td>raise ValueError(</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cc33455-bf59-491e-85b7-59b8d51057c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cc33455-bf59-491e-85b7-59b8d51057c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cc33455-bf59-491e-85b7-59b8d51057c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.31 s (started: 2023-03-14 09:23:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Match Table\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "clinical_fn = \"Overall Clinical Summary - Detailed.xlsx\"\n",
        "\n",
        "os.chdir(startpath)\n",
        "df_lookup = pd.read_csv(lookup_fn)\n",
        "os.chdir(analysis_path)\n",
        "df_clinical = pd.read_excel(clinical_fn)\n",
        "\n",
        "df_match = df_lookup.set_index('shortpath').join(df_clinical.set_index('path'))\n",
        "columns_to_keep = [\n",
        "# \"Order\",\n",
        "\"Unnamed: 1\",\n",
        "\"Baby of\",\n",
        "\"Start date of enrollment\",\n",
        "\"End date of enrollment\",\n",
        "\"Device_type\",\n",
        "\"Number of days of enrollment\",\n",
        "\"Birth weight (grams)\",\n",
        "\"GA\",\n",
        "\"Sub-Group\",\n",
        "# \"Total hypoxia duration (in secs)\",\n",
        "# \"Total hypoxia duration (in hh:mm:ss)\",\n",
        "\"Ventilation\",\n",
        "# \"86,400\",\n",
        "# \"Time Enrolled (S)\",\n",
        "# \"#Seconds in a day\",\n",
        "# \"% seconds in Hypoxia\",\n",
        "# \"Notes\",\n",
        "# \"Notes 2\",\n",
        "# \"Unnamed: 0\",\n",
        "# \"Name\",\n",
        "\"Time ApneBoot System Was On (hrs)\",\n",
        "\"Time with valid vital and status readings (hrs)\",\n",
        "\"SPO2 - Avg\",\n",
        "\"SPO2 - Std\",\n",
        "\"HR - Avg\",\n",
        "\"HR - Std\",\n",
        "\"Time SPO2 < 85 (hrs)\",\n",
        "\"Time SPO2 < 80 (hrs)\",\n",
        "\"Time SPO2 < 75 (hrs)\",\n",
        "\"Time SPO2 < 70 (hrs)\",\n",
        "\"Time SPO2 < 65 (hrs)\",\n",
        "\"model\",\n",
        "# \"data date-time\",\n",
        "]\n",
        "\n",
        "df_match = df_match [columns_to_keep]\n",
        "display (df_match)\n",
        "df_match.to_excel (\"4 - Matched Table Summary.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7SYrEoQoApav",
        "outputId": "b97e5ad9-1c46-424b-f76a-48818d3a363a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "id": "7SYrEoQoApav",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-27c28dd16430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_clinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclinical_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shortpath'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clinical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stream is empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.52 s (started: 2023-03-14 09:12:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4fmuhFuf5k"
      },
      "source": [
        "# DRAFT - New Section"
      ],
      "id": "5E4fmuhFuf5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdo3Bol12w2"
      },
      "source": [
        "## ** Not Used Code**"
      ],
      "id": "Ntdo3Bol12w2"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #fname = \"Report.pdf\"\n",
        "# with PdfPages(fname) as pdf:\n",
        "#   print(\"This is a test of the print function\")\n",
        "#   pdf.savefig()"
      ],
      "metadata": {
        "id": "0EU2cARS1Lsy"
      },
      "id": "0EU2cARS1Lsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# usage_pv_data_table = pd.pivot_table(data_table, index =['Data Date',\"Settings Index\"],\n",
        "#                          aggfunc = 'count')\n",
        "\n",
        "# print(usage_pv_data_table)\n",
        "# usage_pv_data_table.to_csv('Usage_pv_data_table.csv',index=True)\n",
        "# usage_pv_data_table.to_excel(\"Usage_pv_data_table.xlsx\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJ1x3Bq8bbc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pd.reset_option(\"all\")\n",
        "#df = stimulation_results_table_with_all_thresholds\n",
        "#print(df)\n",
        "#pivot = pd.pivot_table(stimulation_results_table_with_all_thresholds,\n",
        "                       #values=[\"Status\"], \n",
        "#                       index=['Status'])\n",
        "                       #aggfunc={'Status': np.count,\n",
        "                       # 'HR': [min, max, np.mean]})\n",
        "\n",
        "#df = df.Status.value_counts()\n",
        "#print(pivot)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "# pd.set_option(\"precision\", 4)\n",
        "\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#print(len (stimulation_results_table_with_all_thresholds))\n",
        "#filtered_results_table_all = df[(df[\"Status\"]==129) | (df[\"Status\"]==131)]\n",
        "#print(len (filtered_results_table_all))\n",
        "\n",
        "#data_table = filtered_results_table_all\n",
        "\n",
        "# pivot = pd.pivot_table(data_table,\n",
        "#                        values=['SPO2','HR'], \n",
        "#                        index=['Data Date'],\n",
        "#                        aggfunc={'SPO2': np.mean,\n",
        "#                         'HR': [min, max, np.mean]})\n",
        "\n",
        "#print(pivot)\n",
        "#filtered_results_table_all.to_csv(\"Filtered_Results_Table_All.csv\")\n",
        "\n",
        "# 129    91112\n",
        "# 153    49477\n",
        "# 131    32220\n"
      ],
      "id": "WYJ1x3Bq8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBwS6cI9JH6"
      },
      "source": [
        "\n",
        "Want \n",
        "- Date\n",
        "- Setting Index\n",
        "- \n",
        "\n"
      ],
      "id": "qlBwS6cI9JH6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # !sudo apt-get install wkhtmltopdf\n",
        "# # !yum install wkhtmltopdf\n",
        "# !apt-get install wkhtmltopdf\n",
        "# import pandas as pd \n",
        "# df_apnea_summary_table.to_html('HTMLTest.html')  \n",
        "\n",
        "# import pdfkit \n",
        "\n",
        "# pdfkit.from_url('HTMLTest.html', 'HTMLTest.pdf')"
      ],
      "metadata": {
        "id": "k08O7_OMVpRX"
      },
      "id": "k08O7_OMVpRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df = pd.DataFrame({'Col': [1,4,5,6,7],\n",
        "                   'Col2': [1,4,5,6,7],\n",
        "                   })\n",
        "display (df)\n",
        "New_Col = \"Col3\"\n",
        "df [New_Col] = df[\"Col\"] +1\n",
        "\n",
        "display (df)\n",
        "display (df[New_Col])"
      ],
      "metadata": {
        "id": "1gwuIXkd74XG"
      },
      "id": "1gwuIXkd74XG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Create a pandas dataframe with demo data:\n",
        "#!pip install -e git+https://github.com/mindee/doctr.git#egg=python-doctr[torch]\n",
        "#!pip install weasyprint\n",
        "!pip install django-weasyprint\n",
        "import pandas as pd\n",
        "demodata_csv = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
        "df = pd.read_csv(demodata_csv)\n",
        "\n",
        "def dfToPDF (df):\n",
        "  # Pretty print the dataframe as an html table to a file\n",
        "  intermediate_html = '/tmp/intermediate.html'\n",
        "  to_html_pretty(df,intermediate_html,'Iris Data')\n",
        "  # if you do not want pretty printing, just use pandas:\n",
        "  # df.to_html(intermediate_html)\n",
        "\n",
        "  # Convert the html file to a pdf file using weasyprint\n",
        "  import weasyprint\n",
        "  out_pdf= '/tmp/demo.pdf'\n",
        "  weasyprint.HTML(intermediate_html).write_pdf(out_pdf)\n",
        "\n",
        "  # This is the table pretty printer used above:\n",
        "\n",
        "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
        "    '''\n",
        "    Write an entire dataframe to an HTML file\n",
        "    with nice formatting.\n",
        "    Thanks to @stackoverflowuser2010 for the\n",
        "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
        "    '''\n",
        "    ht = ''\n",
        "    if title != '':\n",
        "        ht += '<h2> %s </h2>\\n' % title\n",
        "    ht += df.to_html(classes='wide', escape=False)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)\n",
        "\n",
        "HTML_TEMPLATE1 = '''\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "  h2 {\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "  }\n",
        "  table { \n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "  }\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "    font-size: 90%;\n",
        "  }\n",
        "  table tbody tr:hover {\n",
        "    background-color: #dddddd;\n",
        "  }\n",
        "  .wide {\n",
        "    width: 90%; \n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "'''\n",
        "\n",
        "HTML_TEMPLATE2 = '''\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "_4nxBzcnuBex"
      },
      "id": "_4nxBzcnuBex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # PRINT TABLES & DATA\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# #https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
        "# #df_apnea_summary_table.plot()\n",
        "# #dfToPDF (df)\n",
        "# # fig = convertDataframeToFigure (apnea_summary_table)\n",
        "# # pdf = PdfPages(\"foo.pdf\")\n",
        "# # pdf.savefig(fig, bbox_inches='tight')\n",
        "# # pdf.close()\n",
        "# # !pip install -c conda-forge python-pdfkit\n",
        "# !pip3 install wkhtmltopdf\n",
        "# !pip3 install pdfkit\n",
        "\n",
        "# import pandas as pd\n",
        "# import pdfkit as pdf\n",
        "# import sqlite3\n",
        "\n",
        "# # con=sqlite3.connect(\"baza.db\")\n",
        "\n",
        "# # df=pd.read_sql_query(\"select * from dobit\", con)\n",
        "# #df_apnea_summary_table.datetime = pd.to_datetime(apnea_summary_table.datetime)\n",
        "# display(df_apnea_summary_table)\n",
        "\n",
        "# df_apnea_summary_table.to_html('apnea_summary_table.html')\n",
        "# nazivFajla='test.pdf'\n",
        "# config = pdf.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "# pdf.from_url('apnea_summary_table.html', nazivFajla, configuration=config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kb94aQAehXxh"
      },
      "id": "Kb94aQAehXxh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTpOGQud6Max",
        "7VpeZHhf7O2V",
        "T3dPG9_2xoX3",
        "c9pqOw4FnVYA",
        "Ff704C-MwEsw",
        "4C39qoDxEcnt",
        "vFvsiREGpJ-8",
        "1uadoNfrjZUt",
        "bHJA2jljjdc-",
        "eoiLSOJ3jfmj",
        "kPbeaF7WOonR",
        "Y7x2w8JT2a_D",
        "qINEVzl52lDl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}