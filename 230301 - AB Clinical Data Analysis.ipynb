{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulbempu/ApneBoot-Clinical-Data-Analysis/blob/main/230301%20-%20AB%20Clinical%20Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-07-23 - I updated it so it loads logs and creates df_s and df_d faster. Also includes Log Source File. Works for Zug, need to check for nonin.\n",
        "Actual and Preset are slightly different because:\n",
        "- Preset mode number shows up at the start of the apnea, Stim shows at start of stim +1 (instead of 5s it looks like 6 sec+1. This may be a rounding issue. Would be nice if they were on the same line but ok.\n",
        "- This rounding issue may also cause different apnea stimulation lengths by a second or two.\n",
        "\n",
        "\n",
        "22-09-03 -\n",
        "- Added code to convert table to pdf\n",
        "\n",
        "22-09-10 -\n",
        "- Fix Smoothing Issue\n",
        "- Add Thresholds\n",
        "\n",
        "22-19-18\n",
        "Todo:\n",
        "- X make individual plots ouput to pdf\n",
        "- X - Good Enough - make summary table cleaner\n",
        "  - reduce number of columns\n",
        "  - increase overall font size\n",
        "- X test with custom thresholds\n",
        "- test and fix for nonin\n",
        "- combine relevent pdfs into a report.\n",
        "- test with Clinical Data\n",
        "\n",
        "23-03-01\n",
        "- want table with name, total time monitored, total time below X condition calculated), total stimulations, total stimulation time, total time under Y condition, total errorenous data.\n",
        "\n",
        "23-03-15\n",
        "- check against Mona's numbers\n",
        "-\n",
        "\n"
      ],
      "metadata": {
        "id": "COmxc45t43_s"
      },
      "id": "COmxc45t43_s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2P7Ld8v0Zf"
      },
      "source": [
        "## **Initialize**"
      ],
      "id": "VY2P7Ld8v0Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Folder Name"
      ],
      "metadata": {
        "id": "s14DGNWX59Me"
      },
      "id": "s14DGNWX59Me"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Find Folders"
      ],
      "metadata": {
        "id": "KR-D_OFUQ4mK"
      },
      "id": "KR-D_OFUQ4mK"
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "outputId": "bc1425d8-2ff9-4321-882c-085aee22e28b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n432-4cQ4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.9)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "Imports done\n",
            "time: 6.56 s (started: 2023-11-15 09:07:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import fileinput\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "import linecache\n",
        "from pathlib import Path\n",
        "# Garbage Collector - use it like gc.collect()\n",
        "import gc\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "print (\"Imports done\")"
      ],
      "id": "6n432-4cQ4mR"
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "outputId": "8ab58759-ffb0-468e-e159-34819b4fec62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-ikFo4Q4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 2.79 s (started: 2023-11-15 09:07:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "aF-ikFo4Q4mR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Folders List"
      ],
      "metadata": {
        "id": "wu1Ny53mRFbR"
      },
      "id": "wu1Ny53mRFbR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "def list_folders(startpath):\n",
        "    list_path = []\n",
        "    list_folder = []\n",
        "    log = \"log\"\n",
        "    LOG = \"LOG\"\n",
        "    is_data_dir = 0;\n",
        "    previous_name_path = \"\"\n",
        "    for root, subdirs, files in os.walk(startpath):\n",
        "        is_data_dir = 0\n",
        "        for filename in files:\n",
        "            current_name_path = os.path.join(root)\n",
        "            if ((log in filename) | (LOG in filename)) & (previous_name_path != current_name_path):\n",
        "                full_path = os.path.join(root,filename)\n",
        "                list_folder.insert (0, os.path.basename (current_name_path))\n",
        "                list_path.insert(0, root)\n",
        "                previous_name_path = current_name_path\n",
        "\n",
        "    return list_path, list_folder\n"
      ],
      "metadata": {
        "id": "z6m2mfEt8Smu",
        "outputId": "5165db89-2678-4af1-a821-a32af9e469c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z6m2mfEt8Smu",
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.49 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Initialize Folders"
      ],
      "metadata": {
        "id": "PTpOGQud6Max"
      },
      "id": "PTpOGQud6Max"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQuN0Iql7AUK"
      },
      "source": [
        "## **Convert Files to Data Frames**"
      ],
      "id": "LQuN0Iql7AUK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers for Different Logger Versions"
      ],
      "metadata": {
        "id": "7VpeZHhf7O2V"
      },
      "id": "7VpeZHhf7O2V"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "header = \"\"\n",
        "settings_header = \"\"\n",
        "AB_Model = \"default_string\"\n",
        "number_of_commas = 0\n",
        "\n",
        "\n",
        "def decideDataLoggerVersion (df):\n",
        "  # Read the third line's header and decide which data logger version is used\n",
        "  # Assumes that the third line is unique for each data logger version\n",
        "  # I need to check with Sourabh if the third line correlates with versions for the St. John's studies.\n",
        "  global header\n",
        "  global settings_header\n",
        "  global AB_Model\n",
        "  global number_of_commas\n",
        "\n",
        "  raw_logfile_data_table_headers = [\"default\"]\n",
        "  settings_table_headers = [\"\"]\n",
        "  data_table_headers = [\"\"]\n",
        "  settings_columns_rename_dict = [\"\"]\n",
        "  settings_columns_to_drop = [\"\"]\n",
        "  version = \"unknown data code version\"\n",
        "\n",
        "  ZUG_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,PI,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Battery voltage;\"\n",
        "  NONIN_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\"\n",
        "  CLINICAL_SETTINGS_HEADER_INTERVENTION = \"dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\"\n",
        "  CLINICAL_SETTINGS_HEADER_PLACEBO = \"dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\"\n",
        "\n",
        "  settings_header = df.iat[0,0]\n",
        "  header = df.iat[2,0]\n",
        "  number_of_commas = header.count (',')\n",
        "  print (settings_header)\n",
        "  print (header)\n",
        "\n",
        "  if header == ZUG_DATA_HEADER:\n",
        "    version = \"ZUG Circa April 2022\"\n",
        "    # print (\"Detected Zug\")\n",
        "  elif (header == NONIN_DATA_HEADER):\n",
        "      if (settings_header == CLINICAL_SETTINGS_HEADER_INTERVENTION):\n",
        "          version = \"Clinical M3-Intervention (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Intervention\"\n",
        "      elif (settings_header == CLINICAL_SETTINGS_HEADER_PLACEBO):\n",
        "          version = \"Clinical M3-Placebo (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Placebo\"\n",
        "      else:\n",
        "          version = \"NONIN Circa April 2022\"\n",
        "    # print (\"Detected Nonin\")\n",
        "  elif number_of_commas == 5:\n",
        "      version = \"Clinical M1 (Nonin, Tuhin) 2019\"\n",
        "      AB_Model = \"M1\"\n",
        "  elif number_of_commas == 9:\n",
        "      version = \"Clinical M2 (Nonin, Satish) 2019\"\n",
        "      AB_Model = \"M2\"\n",
        "  else:\n",
        "    print (\"Not able to Detect Nonin Nor Zug\")\n",
        "    AB_Model = \"Unable to detect AB Model\"\n",
        "\n",
        "  print (version)\n",
        "\n",
        "  if version == \"ZUG Circa April 2022\":\n",
        "    AB_Model = \"ZUG Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "            \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "                \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Data Date-Time\": 'datetime64[ns]',\n",
        "                \"Data Date\": 'datetime64[ns]',\n",
        "                \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "                \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float\n",
        "                #,\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Settings Date-Time\": str,\n",
        "                \"Settings Date\": str,\n",
        "                'Settings Time':str,\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str}\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"PI\":\"HR Threshold\",\n",
        "            \"Status\":\"AND/OR\",\n",
        "            \"Pulse-ox mode\":\"Duration\",\n",
        "            \"Threshold Met\":\"Stimulator Intensity\",\n",
        "            \"Stimulator Error\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "\n",
        "    settings_columns_to_drop = [\"Stimulator ON/OFF\",\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\"]\n",
        "\n",
        "  if version == \"NONIN Circa April 2022\":\n",
        "    AB_Model = \"NONIN Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"Status\":\"HR Threshold\",\n",
        "            \"Pulse-ox mode\":\"AND/OR\",\n",
        "            \"Threshold Met\":\"Duration\",\n",
        "            \"Stimulator Error\":\"Stimulator Intensity\",\n",
        "            \"Stimulator ON/OFF\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "  if version == \"Clinical M1 (Nonin, Tuhin) 2019\":\n",
        "\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"Status\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "                    \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "  if version == \"Clinical M2 (Nonin, Satish) 2019\":\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Status\",\n",
        "            \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Unused Column 4\",\n",
        "             # <-- need to double check which column is stim off/on\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "        \"HR\",\t\"SPO2\",\t\"Status\",\"Stimulator ON/OFF\",\n",
        "        \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Unused Column 4\",\n",
        "            ]\n",
        "\n",
        "################ M3 ###########\n",
        "  if ((version == \"Clinical M3-Intervention (Nonin) 2019\") | (version == \"Clinical M3-Placebo (Nonin) 2019\")):\n",
        "\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    ## Settings rename dictionary is different\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Intervention or Placebo\",\n",
        "            \"HR\" : \"Stimulator Intensity\",\n",
        "            \"Status\":\"Alarm intensity\",\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "\n",
        "  return raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict"
      ],
      "metadata": {
        "id": "-OMUDW4FZpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65978531-fa09-4a19-8578-b657f1a48916"
      },
      "id": "-OMUDW4FZpEd",
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.03 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile & Split Log Files to df_d and df_s"
      ],
      "metadata": {
        "id": "kns3IrBcDkdb"
      },
      "id": "kns3IrBcDkdb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Reference here: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
        "file_list = []\n",
        "\n",
        "def compileLogFiles (path):\n",
        "  global file_list\n",
        "#   print (path)\n",
        "  os.chdir(path)\n",
        "  file_list = sorted(glob.glob(\"*LOG*.csv\")) + sorted(glob.glob(\"*log*.csv\")) + sorted(glob.glob(\"*Log*.csv\")) + sorted(glob.glob(\"*LOG*.txt\")) + sorted(glob.glob(\"*log*.txt\")) + sorted(glob.glob(\"*Log*.txt\")) + sorted(glob.glob(\"*LOG*.TXT\")) + sorted(glob.glob(\"*log*.TXT\")) + sorted(glob.glob(\"*Log*.TXT\"))\n",
        "              # in 2019 clinical, some files are log and some are LOG\n",
        "#   file_list = sorted(glob.glob(\"*\"))\n",
        "  number_of_files = len(file_list)\n",
        "#   print(\"Number of Files:\" , len(file_list))\n",
        "  print (file_list)\n",
        "  li = []\n",
        "\n",
        "  for file_name in file_list:\n",
        "    # This could work faster potentially, but then the data logger identifier code for finding the zug/nonin code string has to be changed\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n', names=list(range(12)))\n",
        "\n",
        "    # df = pd.read_csv(file_name, header=None)\n",
        "    df = pd.read_csv(file_name, header=None, sep='\\0')\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n')\n",
        "    # df = pd.read_csv(file_name, header=None, sep=',')\n",
        "    df['Source File'] = file_name\n",
        "    li.append (df)\n",
        "\n",
        "  frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "_MMQAV31zaJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353ee350-f222-41c2-d5e0-7b30f54979fd"
      },
      "id": "_MMQAV31zaJk",
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.32 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def splitToDataAndSettingsDF (df_LOGs):\n",
        "\n",
        "  raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict = decideDataLoggerVersion (df_LOGs)\n",
        "\n",
        "  df_raw = df_LOGs[0].str.split(',', expand=True)\n",
        "  #display (df_raw)\n",
        "\n",
        "  df_raw.columns = raw_logfile_data_table_headers\n",
        "  df_raw[\"Source File\"] = df_LOGs [\"Source File\"]\n",
        "\n",
        "  # Extract Settings\n",
        "  df_raw_shift = df_raw.shift(periods=-1)\n",
        "  df_s = df_raw_shift[(df_raw.iloc[:,2]==\"Preset mode\") | (df_raw.iloc[:,2]==\"Intervention\") | (df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  # For the clinical data - just use the rows with a new source file to keep the time/date and file.\n",
        "  if ((AB_Model == \"M1\") | (AB_Model == 'M2')):\n",
        "    df_s = df_raw.drop_duplicates(subset=[\"Source File\"], keep='first')\n",
        "\n",
        "\n",
        "  # Delete settings and settings headers\n",
        "  df_raw_shift = df_raw.shift(periods=1)                                        #shift down one row as a way to find one line below the settings header\n",
        "  rows_below_header = df_raw[(df_raw_shift.iloc[:,2]==\"Preset mode\") |(df_raw_shift.iloc[:,2]==\"Intervention\")|(df_raw_shift.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop(rows_below_header.index)                                 #Drop all the setttings data lines\n",
        "  rows_with_header = df_raw[(df_raw.iloc[:,2]==\"Preset mode\") |(df_raw.iloc[:,2]==\"Intervention\")|(df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the settings headers\n",
        "  rows_with_header = df_raw[df_raw.iloc[:,2]==\"SPO2\"]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the DATA headers\n",
        "\n",
        "  # Format Settings Files\n",
        "  df_s.drop(settings_columns_to_drop, axis=1, inplace=True)                     # Drop extra columns\n",
        "  df_s.rename(columns=settings_columns_rename_dict, inplace=True)\n",
        "  if 'Alarm Intensity' in df_s.columns:\n",
        "    df_s['Alarm intensity'].apply(lambda v: v.rstrip(';'))\n",
        "\n",
        "  #What's left of df_raw is now df_d for data\n",
        "  df_d = df_raw\n",
        "  if (AB_Model == \"NONIN Circa April 2022\"):\n",
        "    df_d.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "    #df_s.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "\n",
        "  # In the clinical, Tuhin put P for the devices that were placebo and would have stimulated but actually didn't.\n",
        "  # Replace those with the number 1\n",
        "  df_d[\"Stimulator ON/OFF\"].mask(df_d[\"Stimulator ON/OFF\"] == \" P\", 1, inplace= True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  if (AB_Model == \"M1\"):\n",
        "    format_day = '%d-%MM-%yyyy'\n",
        "    format_time = '%H:%m:%s'\n",
        "  else:\n",
        "    format_day = '%d/%m/%y'\n",
        "    format_time = '%H:%M:%S'\n",
        "\n",
        "\n",
        "#   if (AB_Model == \"M1\"):\n",
        "#       try:\n",
        "#         display (df_s)\n",
        "#         display (df_d)\n",
        "#         # df_s.head()\n",
        "#         # df_d.head()\n",
        "\n",
        "#         # print (df_d.columns)\n",
        "#         # print (\"df_s1 \" + df_s[\"Settings Date\"][3] + df_s[\"Settings Time\"][3])\n",
        "#         df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"df_d1 \" + df_d[\"Data Date\"][3] + df_d[\"Data Time\"][3])\n",
        "#         df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"matched 1!\")\n",
        "#       except Exception as e:\n",
        "#           print (e)\n",
        "#           print (\"try alternate date format:\")\n",
        "#           display (df_s)\n",
        "#         #   print (df_d.columns)\n",
        "#           try:\n",
        "#             # df_s.drop (\"Settings Date-Time\")\n",
        "#             # df_d.drop (\"Data Date-Time\")\n",
        "#             # df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             # df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             print (\"matched 2!\")\n",
        "#           except Exception as e2:\n",
        "#             print (e2)\n",
        "#             print (\"no more date formats to try!\")\n",
        "\n",
        "\n",
        "#   else:\n",
        "#     df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#     df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#   print (\"inserting with \"+format_day + \" \" + format_time)\n",
        "#   display (df_s)\n",
        "\n",
        "#   print (\"df_s insert done, here's what it looks like\")\n",
        "#   display (df_s)\n",
        "#   display (df_d)\n",
        "\n",
        "#   print (\"df_d coerce done and now df_d looks like:\")\n",
        "#   display (df_d)\n",
        "#   print (\"inserts done\")\n",
        "\n",
        "# MARCH 9, 2023 - These two lines below work (infer_datetime_format=True needs to be checked bc some columns may have multiple date Time formats?)\n",
        "# but it's still slow so I'm commenting them out for now and replacing them with the two below\n",
        "\n",
        "#   df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "#   df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "\n",
        "  df_s.insert(loc=0, column=\"Settings Date-Time\", value=df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"])\n",
        "  df_d.insert(loc=0, column=\"Data Date-Time\", value=df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"])\n",
        "\n",
        "  df_s['Settings Date-Time'] = getDateTimeColumn (df_s[[\"Settings Date-Time\"]])\n",
        "  df_d['Data Date-Time'] = getDateTimeColumn (df_d[[\"Data Date-Time\"]])\n",
        "\n",
        "\n",
        "  if ((AB_Model == \"M1\") | (AB_Model == \"M2\") | (AB_Model == \"M3-Placebo\") | (AB_Model == \"M3-Intervention\")):\n",
        "      df_s.insert(loc = 3, column=\"Preset mode\", value = 1)\n",
        "      df_s.insert(loc = 4, column=\"SPO2 Threshold\", value = 0)\n",
        "      df_s.insert(loc = 5, column=\"HR Threshold\", value = 0)\n",
        "      df_s.insert(loc = 6, column=\"AND/OR\", value = 0)\n",
        "      df_s.insert(loc = 7, column=\"Duration\", value = 0)\n",
        "      if ((AB_Model == \"M1\") | (AB_Model == \"M2\")):\n",
        "        df_s.insert(loc = 8, column=\"Stimulator Intensity\", value = 0)\n",
        "        df_s.insert(loc = 9, column=\"Alarm intensity\", value = 0)\n",
        "\n",
        "  #Cleanup NaNs\n",
        "  df_d = df_d.fillna(0)\n",
        "  df_s = df_s.fillna(0)\n",
        "\n",
        "  #Convert to best datatypes\n",
        "\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format='%d/%m/%y')\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format='%H:%M:%S')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format='%d/%m/%y')\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format='%H:%M:%S')#.dt.time\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format=format_day)\n",
        "#   print (\"Settings Date Updated done\")\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Settings Time Updated done\")\n",
        "\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format=format_day)\n",
        "#   print (\"Data Date Updated done\")\n",
        "\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Data Time Updated done\")\n",
        "\n",
        "## For Clinical Analysis I am not going to do these, since they are already done above when combined.\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"])\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"], errors = 'coerce')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"])\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"], errors = 'coerce')#.dt.time\n",
        "  df_s.drop(columns = \"Settings Date\", axis = 1, inplace=True)\n",
        "  df_s.drop(columns = \"Settings Time\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Date\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Time\", axis = 1, inplace=True)\n",
        "  df_s=df_s.astype(settings_convert_dict, errors='raise')\n",
        "  df_d=df_d.astype(data_convert_dict, errors='raise')\n",
        "\n",
        "  #df_d = ResolveMidnightDateIssue (df_d)\n",
        "\n",
        "#  df_d[\"Data Date-Time\"]=pd.to_datetime(df_d[\"Data Date-Time\"],format='%d/%m/%y %H:%M:%S')\n",
        "\n",
        "  # For Settings Table delete the confusing default numbers left in place when \"preset\" condition is on.\n",
        "#\n",
        "  df_s = DeleteThresholdsForRowsUsingPresetConditions(df_s)\n",
        "  df_s, df_d = addSettingsIndex (df_s,df_d)\n",
        "\n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "_jiazNDlz1Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35afa981-5a57-418a-d8f5-1a83d2e5f620"
      },
      "id": "_jiazNDlz1Dp",
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.41 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XH-EgNxkPi",
        "outputId": "0d6b13dc-d9b8-4a60-84d1-1f8564957de4"
      },
      "id": "T9XH-EgNxkPi",
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.9 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It was observed with Zug that for the first ~30 seconds after midnight, the date does not change. This needs to be fixed or \"smoothed\" with the code below.\n",
        "#import calendar\n",
        "\n",
        "#### This function is not finished.\n",
        "def ResolveMidnightDateIssue (df_above):\n",
        "  print (\"in the smooth\")\n",
        "  df_diff = pd.DataFrame ()\n",
        "  df_below = pd.DataFrame ()\n",
        "\n",
        "  df_below[\"Data Date-Time\"] = df_above[\"Data Date-Time\"].shift (periods=1, fill_value=0)\n",
        "  #df_below[\"Data Date\"] = df_above[\"Data Date\"].shift (periods=1, fill_value=0)\n",
        "  df_below [\"Date Diff\"] = df_above[\"Data Date-Time\"] < df_below[\"Data Date-Time\"]\n",
        "  df_below [\"Date Diff Num\"] = (df_above[\"Data Date-Time\"] - df_below[\"Data Date-Time\"]).dt.total_seconds()\n",
        "  print (df_below [\"Date Diff Num\"].dtype)\n",
        "\n",
        "\n",
        "  # display(df_above)\n",
        "  # display(df_below)\n",
        "  # display (df_below[df_below[\"Date Diff\"]==1])\n",
        "  df_midnight_bounds = df_below[df_below[\"Date Diff Num\"].abs()>1000]\n",
        "  #display (df_midnight_bounds)\n",
        "  # for i in df_midnight_bounds.index:\n",
        "  #   print (i)\n",
        "\n",
        "\n",
        "\n",
        "  #display (df_below[df_below[\"Date Diff Num\"]!=1])\n",
        "\n",
        "  print (\"Sum is: \" + df_below[\"Date Diff\"].astype(int).sum().astype(str))\n",
        "\n",
        "  return df_above\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2noyZAXZNuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4412eb89-2f6e-4c2e-a031-e12d55e54418"
      },
      "id": "J2noyZAXZNuk",
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.28 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def addSettingsIndex (df_s,df_d):\n",
        "  #df_s[\"Settings Index\"] = np.arange(len(df_s))\n",
        "  df_s.insert(loc=0, column=\"Settings Index\", value=np.arange(len(df_s))+1)\n",
        "  df_d = pd.merge_asof (df_d,df_s[\"Settings Index\"],left_index=True, right_index=True)\n",
        "  SettingsIndexCol = df_d.pop('Settings Index')\n",
        "  df_d.insert(0, 'Settings Index', SettingsIndexCol)\n",
        "\n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "SeN4pRpcmoTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9264cbb-250e-42df-e25e-ff85c51c4d7f"
      },
      "id": "SeN4pRpcmoTt",
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.06 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971bb313-c358-4546-c7d8-0320f959e3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 819 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def DeleteThresholdsForRowsUsingPresetConditions (settings_table):\n",
        "    # display(settings_table)\n",
        "    for ind in settings_table.index:\n",
        "        if settings_table[\"Preset mode\"][ind] == 1:\n",
        "            settings_table[\"SPO2 Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"HR Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"AND/OR\"][ind] = np.NaN\n",
        "            settings_table[\"Duration\"][ind] = np.NaN\n",
        "                       #Preset mode\tSPO2 Threshold\tHR Threshold\tAND/OR\tDuration\n",
        "    return settings_table\n"
      ],
      "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba"
    },
    {
      "cell_type": "code",
      "source": [
        "# Send an unformatted clinical data column and returns a date-time column\n",
        "def getDateTimeColumn (df):\n",
        "    df2 = pd.DataFrame ()\n",
        "    df[df. columns[0]] = df[df. columns[0]].str.replace('/',' ').str.replace('-',' ').str.replace(':',' ')\n",
        "\n",
        "    df[['Day','Month','Year','Hour','Minute','Second']] = df[df. columns[0]].str.split(expand = True)\n",
        "    df = df.drop([df. columns[0]], axis=1)\n",
        "    df=df.astype(int)\n",
        "\n",
        "    df['Year'].where(df[\"Year\"] > 2000, other = df[\"Year\"] + 2000, inplace = True)\n",
        "    df['Second'].where(df['Second'] != 60, other = 0, inplace = True)\n",
        "\n",
        "    df2['Datetime'] = pd.to_datetime(df[['Day','Month','Year','Hour','Minute','Second']])\n",
        "    return df2\n",
        "\n",
        "# dftest = pd.DataFrame ()\n",
        "# getDateTimeColumn (dftest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPPshOYtN8Aq",
        "outputId": "6bbeba1f-3ca9-498d-8ac5-94a08066f760"
      },
      "id": "zPPshOYtN8Aq",
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.32 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dPG9_2xoX3"
      },
      "source": [
        "## **Analyze Thresholds**"
      ],
      "id": "T3dPG9_2xoX3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Only Valid Data\n",
        "This filters data based on device status."
      ],
      "metadata": {
        "id": "YxecqEFREEhV"
      },
      "id": "YxecqEFREEhV"
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e513cba7-22fc-4c94-99ff-b26296828754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.16 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def GetIsValidColumn (df):\n",
        "    is_valid = pd.DataFrame ()\n",
        "    is_valid [\"valid_vitals\"] = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff) & (df[\"HR\"] !=255) & (df[\"SPO2\"] !=127))\n",
        "    # print (\"Num IsValid Vitals True:\")\n",
        "    # print (is_valid[\"valid_vitals\"].sum())\n",
        "    # print (is_valid [\"valid_vitals\"])\n",
        "    # is_valid['valid_vitals'].value_counts()\n",
        "    # print (\"num valid vitals: \" + is_valid [is_valid[\"valid_vitals\"]==True].count)\n",
        "\n",
        "    # Determine if status scale is 0-6 or 0-255...\n",
        "    max_status = df[\"Status\"].max()\n",
        "    # print (\"about to check valid_status\")\n",
        "    # display (df)\n",
        "    # if (AB_Model == \"M1\"):\n",
        "    if (max_status < 7):\n",
        "        # print (\"eval status for 0-6 status\")\n",
        "        is_valid [\"valid_status\"] = (df['Status'] == 0);\n",
        "    elif (max_status >= 7):\n",
        "        # print (\"eval status for 0-255 status\")\n",
        "        is_valid [\"valid_status\"] = ((df['Status'] == 129) | (df['Status'] == 131));\n",
        "\n",
        "    # print (\"Num IsValid Status True:\")\n",
        "    # print (is_valid[\"valid_status\"].sum())\n",
        "\n",
        "    is_valid['Is_Valid_Data'] = np.where((is_valid['valid_status'] == True) & (is_valid[\"valid_vitals\"] == True), True, False)\n",
        "    # is_valid [\"Is_Valid_Data\"] = ((is_valid['valid_vitals'] == True) & (is_valid ['valid_status'] == True))\n",
        "    # is_valid['Is_Valid_Data'].value_counts()\n",
        "    # print (\"Num IsValid True:\")\n",
        "    # print (is_valid[\"Is_Valid_Data\"].sum())\n",
        "    return is_valid [\"Is_Valid_Data\"]\n",
        "\n",
        "\n"
      ],
      "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Against Custom Thresholds\n",
        "This function returns what is expected in the custom mode the user selected. It should match with actual stimulations in custom mode."
      ],
      "metadata": {
        "id": "dm2RieFwTAjS"
      },
      "id": "dm2RieFwTAjS"
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12a5dc5-a7db-4de1-d263-c6662f3ca428",
        "id": "pndZJ_WATAja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.01 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def AnalyzeWithCustomThresholds (df):\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) & (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) | (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_result = (df[\"AND/OR\"]==0)*is_below_threshold_OR + (df[\"AND/OR\"]==1)*is_below_threshold_AND\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= df[\"Duration\"],0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "\n",
        "  df[Duration_Custom] = df_unmasked.mask(df_unmasked <= df[\"Duration\"],0)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "id": "pndZJ_WATAja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze With Preset Thresholds\n",
        "This function is useful to see how the system would have performed if it were operating in preset mode."
      ],
      "metadata": {
        "id": "c9pqOw4FnVYA"
      },
      "id": "c9pqOw4FnVYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "SPO2_threshold_AND_condition = 85\n",
        "HR_threshold_AND_condition = 100\n",
        "SP02_threshold_OR_condition = 75\n",
        "HR_threshold_OR_condition  = 90\n",
        "Preset_Mode_Duration = 5\n",
        "\n",
        "def AnalyzeWithPresetThresholds (df):\n",
        "\n",
        "#   orubt (\"started\")\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "#   is_valid[\"\"] = df['Is_Valid_Data']\n",
        "#   print (\"in Analyze with Preset Thresholds\")\n",
        "#   is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "#   is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "\n",
        "  is_below_threshold_AND = df['Is_Valid_Data'] & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  is_below_threshold_OR = df['Is_Valid_Data']& ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "  # is_below_threshold_result = ((df[\"AND/OR\"]==0))&(is_below_threshold_OR) | ((df[\"AND/OR\"]==1) &is_below_threshold_AND)\n",
        "  is_below_threshold_result = is_below_threshold_OR | is_below_threshold_AND\n",
        "  #print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "#   display (is_below_threshold_result)\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= Preset_Mode_Duration,0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  # print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "\n",
        "  # print (\"Total preset results are: \" + str(is_below_threshold_result.sum()))\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "  df[Duration_Preset] = df_unmasked.mask(df_unmasked <= Preset_Mode_Duration,0)\n",
        "#   print (\"finished Analyze with Preset Thresholds\")\n",
        "  #print (\"Sum is:\" + str(sum(df[Duration_Preset])))\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "NFGvMndV_NLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee39b1f6-1ccb-4c8e-ffa5-dc7b79e52385"
      },
      "id": "NFGvMndV_NLH",
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.27 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Actual Stimulations\n",
        "This function looks at Stim Off/On field and counts the apnea durations (assuming SPO2 & HR are not 0). It does not consider the Preset/Custom settings at all."
      ],
      "metadata": {
        "id": "Ff704C-MwEsw"
      },
      "id": "Ff704C-MwEsw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Assumes it is being passed df_j\n",
        "def AddNumActualStimulations (df):\n",
        "\n",
        "#   Valid_Stimulations = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff)*(df[\"HR\"]>Data_Cleanup_HR_LowCutOff)\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  Valid_Stimulations = df[\"Stimulator ON/OFF\"]*is_valid\n",
        "  df[Duration_Actual] = calcDurationsCrossedThreshold(pd.DataFrame(Valid_Stimulations))\n",
        "\n",
        "  ## New code (22-07-23) - I later realized that with the new apnea duration counter, we don't need to \"Stimulation started column\" as it easily puts the apnea duration time where the stimulation started.\n",
        "  # df[\"Stimulator ON/OFF with Valid SPO2/HR\"] = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]!=0)*(df[\"HR\"]!=0)\n",
        "\n",
        "  # df_previousrow = df.shift(periods=1)\n",
        "  # isStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF with Valid SPO2/HR\"]==1) &\n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF with Valid SPO2/HR\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) &\n",
        "  #                         (df[\"HR\"]!=0)\n",
        "  #                         )  # This condition was added because there are some odd cases where the stimulator turns when HR/SPO2 are 0...\n",
        "\n",
        "  #This gives 408 rows, but the one above gives 411 rows. There are likely some times then the O2 or HR jumps to zero mid apnea but jumps back up and the stimulator is on the whole time?\n",
        "  # OldisStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF\"]==1) &\n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) &\n",
        "  #                         (df[\"HR\"]!=0))\n",
        "\n",
        "  #Should be 408 Rows\n",
        "\n",
        "  # df[\"Stimulation Triggered (Actual Stimulator ON Triggered)\"] = isStimulationStarted\n",
        "  # df[\"Actual - Stimulation Durations (s)\"] = calcDurationsCrossedThreshold(pd.DataFrame(df[\"Stimulator ON/OFF with Valid SPO2/HR\"]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "CI2GKzN15PZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8bfcdf-78ad-46af-a410-c5e3b6ef89b4"
      },
      "id": "CI2GKzN15PZJ",
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 730 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Cross Duration\n",
        "This takes an array of \"threshold crossed\" or \"stimulation on\" (0,0,0,1,1,1,1,0..etc) and returns an array with the time in the first place the threshold is cross i.e. (0,0,0,4,0,0,0,0...)"
      ],
      "metadata": {
        "id": "4C39qoDxEcnt"
      },
      "id": "4C39qoDxEcnt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Input: A df with 0s and 1s representing cross thresholds\n",
        "# see this -  https://stackoverflow.com/questions/62615666/how-to-sum-variable-ranges-in-a-pandas-column-to-another-column\n",
        "def calcDurationsCrossedThreshold (df):\n",
        "\n",
        "  df = df.iloc[::-1]\n",
        "  a = df.iloc[:,0]==0\n",
        "  blocks = a.cumsum()\n",
        "\n",
        "  m = blocks.duplicated(keep='last')\n",
        "\n",
        "  df['Sum'] = df.iloc[:,0].groupby(blocks).cumsum().mask(m)\n",
        "  df = df.iloc[::-1]\n",
        "  df_return = df ['Sum'].fillna(0)\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "HIOGli41rAgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a95cf7-f079-4266-82cc-a39c88af58ab"
      },
      "id": "HIOGli41rAgo",
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.09 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Summary Tables**"
      ],
      "metadata": {
        "id": "vFvsiREGpJ-8"
      },
      "id": "vFvsiREGpJ-8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportApneaCountBySetting (df,df_s):\n",
        "  table = pd.pivot_table (df, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='sum')\n",
        "#   display (table)\n",
        "  table = table.rename (columns = {Duration_Actual:SumDuration_Actual, Duration_Preset:SumDuration_Preset, Duration_Custom:SumDuration_Preset})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "\n",
        "\n",
        "  #Count function counts zeros too, so need to replace zeros with NAs for this to work.\n",
        "  df_nan = df.mask(df==0) # This will make all zeros into Nan\n",
        "  table = pd.pivot_table (df_nan, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='count')\n",
        "\n",
        "  table = table.rename (columns = {Duration_Actual:Count_Actual, Duration_Preset:Count_Preset, Duration_Custom:Count_Custom})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "#   display (df_s)\n",
        "\n",
        "  if (PRINT_TABLES == True):\n",
        "    df_s.to_excel (folder_name + \" - Summary of Events.xlsx\")\n",
        "    dataframe_to_pdf(df_s, folder_name + \" - Apnea Count By Setting\")\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McI1Xwv81qIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19fafe9-cf66-4c43-8352-ae9d8797af1b"
      },
      "id": "McI1Xwv81qIh",
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.23 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportIndividualActualApneas (df):\n",
        "  table_A = df[df[Duration_Actual]!=0]\n",
        "  table_P = df[df[Duration_Preset]!=0]\n",
        "  table_C = df[df[Duration_Custom]!=0]\n",
        "  table_A_P = df[ (df[\"Preset mode\"]==1 & (df[Duration_Actual]!=df[Duration_Preset]))]\n",
        "  table_A_C = df[ (df[\"Preset mode\"]==0 & (df[Duration_Actual]!=df[Duration_Custom]))]\n",
        "\n",
        "  if (PRINT_TABLES == True):\n",
        "    with pd.ExcelWriter(folder_name + \" - Individual Events.xlsx\") as writer:\n",
        "        table_A.to_excel (writer, sheet_name=\"Actual\")\n",
        "        table_P.to_excel (writer, sheet_name=\"Preset\")\n",
        "        table_C.to_excel (writer, sheet_name=\"Custom\")\n",
        "        table_A_P.to_excel (writer, sheet_name=\"Actual-Preset Discrepancy\")\n",
        "        table_A_C.to_excel (writer, sheet_name=\"Actual-Custom Discrepancey\")\n",
        "\n",
        "    dataframe_to_pdf(table_A, folder_name + \" - Individual Events (Actual)\")\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "IbdRSJx_MgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d749fd53-b192-4566-ce20-ffec48c8a93d"
      },
      "id": "IbdRSJx_MgxZ",
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.23 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def countApneas (df):\n",
        "   df_nan = df.mask(df==0)\n",
        "   count = np.sum(df_nan.count())\n",
        "#    print (\"Num Apneas is:\" + str(count))\n",
        "   return count\n",
        "\n",
        "def sumApneaTime (df):\n",
        "    # print (\"sumApneaTime-start\")\n",
        "    # sum = df.sum(df[df.columns[0]])\n",
        "    sum = df.sum()\n",
        "    # print (\"Sum Apnea Time is:\" + str (sum))\n",
        "    return sum\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SvGB35kvb-z",
        "outputId": "36a7edd3-faeb-45ca-d737-ef722897adb7"
      },
      "id": "4SvGB35kvb-z",
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 864 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def convertDataframeToFigure (df):\n",
        "#   display (df)\n",
        "  fig, ax =plt.subplots(figsize =(20,20))\n",
        "  #fig, ax =plt.subplots(figsize=(len(df),len(df.columns)))\n",
        "  ax.axis('tight')\n",
        "  ax.axis('off')\n",
        "  the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "  return fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qxv3-8-3lsTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d50b6b9-04bc-4b69-cc67-6c6a4be75653"
      },
      "id": "Qxv3-8-3lsTZ",
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 779 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ## Print Tables to PDF **\n",
        "This code enables printing tables to pdf."
      ],
      "metadata": {
        "id": "Sb6hldAxxaXX"
      },
      "id": "Sb6hldAxxaXX"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import textwrap as twp\n",
        "\n",
        "# #create column headers with long text and apply textwrap with \\n after defined lenght\n",
        "# columns=[twp.fill('this is a long column header text',25), twp.fill('...and this is an even longer column header text',25)]\n",
        "\n",
        "# https://predictivehacks.com/?all-tips=save-a-pandas-dataframe-as-an-image\n",
        "# pip install dataframe-image\n",
        "# import pandas as pd\n",
        "# import dataframe_image as dfi\n",
        "\n",
        "# dfi.export(df, 'dataframe.png')\n",
        "\n",
        "def _draw_as_table(df, pagesize):\n",
        "    alternating_colors = [['white'] * len(df.columns), ['lightgray'] * len(df.columns)] * len(df)\n",
        "    alternating_colors = alternating_colors[:len(df)]\n",
        "    fig, ax = plt.subplots(figsize=pagesize)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    # df=df.to_string(line_width=5)\n",
        "    # .str.wrap(5)\n",
        "    col_headers=list(df.columns.str.wrap(15)) #df.columns#.map(\"str\")\n",
        "    #display (col_headers)\n",
        "    #print (\"Cols is \" + len(df[0]))\n",
        "    #display (df)\n",
        "    the_table = ax.table(cellText=df.values,\n",
        "                        rowLabels=df.index,\n",
        "                        colLabels=col_headers,\n",
        "                        #colLabels=df.columns,\n",
        "                        rowColours=['lightblue']*len(df),\n",
        "                        colColours=['lightblue']*len(df.columns),\n",
        "                        cellColours=alternating_colors,\n",
        "                        loc='center')\n",
        "    the_table.auto_set_column_width(col=list(range(len(df.columns)))) # Provide integer list of columns to adjust\n",
        "\n",
        "    # the_table.auto_set_font_size(False)\n",
        "    # the_table.set_fontsize(12)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def dataframe_to_pdf(df, filename, numpages=(1, 1), pagesize=(11, 8.5)):\n",
        "  with PdfPages(filename) as pdf:\n",
        "    # display (df)\n",
        "    # nh, nv = numpages\n",
        "    # rows_per_page = len(df) // nh\n",
        "    # cols_per_page = len(df.columns) // nv\n",
        "\n",
        "    # nh, nv = numpages\n",
        "    rows_per_page = 30\n",
        "    cols_per_page = len(df.columns)\n",
        "    nv = 1\n",
        "\n",
        "    if len(df) % rows_per_page == 0:\n",
        "      nh = int(len(df) / rows_per_page)\n",
        "    else:\n",
        "      nh = int(len(df) / rows_per_page) +1\n",
        "\n",
        "    # print ('num cols is ' + str(len(df.columns)))\n",
        "    # print ('num rows is ' + str(len(df)) + \"nv is \" + str(nv))\n",
        "\n",
        "    for i in range(0, nh):\n",
        "        for j in range(0, nv):\n",
        "            # print (\"i is \" + str(i) + \"and j is \" + str(j))\n",
        "            page = df.iloc[(i*rows_per_page):min((i+1)*rows_per_page, len(df)),\n",
        "                           (j*cols_per_page):min((j+1)*cols_per_page, len(df.columns))]\n",
        "            # display (page)\n",
        "            fig = _draw_as_table(page, pagesize)\n",
        "            if nh > 1 or nv > 1:\n",
        "                # Add a part/page number at bottom-center of page\n",
        "                fig.text(0.5, 0.5/pagesize[0],\n",
        "                         \"Part-{}x{}: Page-{}\".format(i+1, j+1, i*nv + j + 1),\n",
        "                         ha='center', fontsize=8)\n",
        "\n",
        "            pdf.savefig(fig, bbox_inches='tight')\n",
        "            # plt.show ()\n",
        "            plt.close()\n"
      ],
      "metadata": {
        "id": "BQDht-5kNQpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0516595a-9806-4d6f-ddeb-e5ce748cd0a8"
      },
      "id": "BQDht-5kNQpD",
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.37 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AZp6q5Z8Aq"
      },
      "source": [
        "## **Plots**"
      ],
      "id": "X_AZp6q5Z8Aq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot AB Data"
      ],
      "metadata": {
        "id": "1uadoNfrjZUt"
      },
      "id": "1uadoNfrjZUt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotApneBootData (df,plot_title,x_axis_start,x_axis_end):\n",
        "    #display (df)\n",
        "\n",
        "    f, (ax, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 1]})\n",
        "\n",
        "    ax2 = df.plot(x=\"Data Date-Time\", y=\"Status\", rot=0,ax=ax2)\n",
        "\n",
        "    plotSPO2AndHR(df,plot_title,x_axis_start,x_axis_end,ax)\n",
        "\n",
        "    f.tight_layout()\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xxrNme8yvvkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d8f0c0-03e3-4b3e-a619-2da5e30a8a6f"
      },
      "id": "xxrNme8yvvkW",
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 863 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "#@title\n",
        "def plotSPO2AndHR (df,plot_title,x_axis_start,x_axis_end,ax):\n",
        "  plot_type = 'scatter'\n",
        "\n",
        "#   Setup plots to show which data is valid and invalid.\n",
        "  df_invalid = df [df[\"Is_Valid_Data\"]==0]\n",
        "  df = df [df[\"Is_Valid_Data\"]==1]\n",
        "\n",
        "#   This is y value to show for these.\n",
        "  df_invalid['Is_Valid_Data'] = 43\n",
        "  df[\"Stimulator ON/OFF Plot\"] = df[\"Stimulator ON/OFF\"]*20\n",
        "\n",
        "  ax = df.plot(x=\"Data Date-Time\", y=\"SPO2\",\n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            rot=0,\n",
        "                            color = 'orangered',\n",
        "                            label = \"SPO2 Valid\",\n",
        "                            linewidth=1,\n",
        "                            kind = plot_type,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df.plot(x=\"Data Date-Time\", y=\"HR\",\n",
        "                          color = 'cornflowerblue',\n",
        "                          label = \"HR Valid\",\n",
        "                          linewidth=1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "\n",
        "  df.plot.line(x=\"Data Date-Time\", y=\"Stimulator ON/OFF Plot\",\n",
        "                          linewidth=4,\n",
        "                          alpha=0.2,\n",
        "                          color = 'Orange',\n",
        "                          label = \"Stim ON\",\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax)\n",
        "\n",
        "  df_t = getThresholdTable (df)\n",
        "\n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"SPO2 Threshold\",\n",
        "                          color = 'DarkRed',\n",
        "                          label = \"SPO2 Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dashed',\n",
        "                          alpha=0.2,\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax\n",
        "                          )\n",
        "\n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"HR Threshold\",\n",
        "                          color = 'DarkBlue',\n",
        "                          label = \"HR Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dotted',\n",
        "                          alpha=0.2,\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y=\"SPO2\",\n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            rot=0,\n",
        "                            c = 'maroon',\n",
        "                            s = 1,\n",
        "                            # color = 'black',\n",
        "                            label = \"SPO2 Invalid\",\n",
        "                            linewidth=1,\n",
        "                            kind = plot_type,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y=\"HR\",\n",
        "                        #   color = 'black',\n",
        "                          c = 'midnightblue',\n",
        "                          label = \"HR Invalid\",\n",
        "                          linewidth=1,\n",
        "                           s = 1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y='Is_Valid_Data',\n",
        "                        #   color = 'black',\n",
        "                          c = 'black',\n",
        "                          label = \"Data Invalid\",\n",
        "                          linewidth=1,\n",
        "                           s = 1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "\n",
        "\n",
        "  x_offset = (x_axis_end - x_axis_start)/10\n",
        "  df_a = df[(df[Duration_Preset] > 0)]\n",
        "  df_a=df_a.reset_index(drop=True)\n",
        "  df_a[\"Arrow Offet\"] = df_a[\"Data Date-Time\"] - x_offset\n",
        "\n",
        "  for ind in df_a.index:\n",
        "    if df_a[\"Arrow Offet\"][ind] <= x_axis_start:\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than \" + str(x_axis_start))\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than\" + str(x_axis_start))\n",
        "      df_a[\"Arrow Offet\"][ind] = df_a[\"Arrow Offet\"][ind] + x_offset*2\n",
        "    #   print (\"and the arrow didn't fit in the screen so we replace with: \" + str(df_a[\"Arrow Offet\"][ind]))\n",
        "    #print (ind)\n",
        "    # ax.annotate(\"Event For \" + df_a[Duration_Actual][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "    #         xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]),\n",
        "    #         fontsize = 10,\n",
        "    #         xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20),\n",
        "    #         arrowprops = dict(facecolor = 'yellow'),\n",
        "    #         color = 'black',\n",
        "    #         backgroundcolor='white')\n",
        "\n",
        "    ax.annotate(\"Event For \" + df_a[Duration_Preset][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "            xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]),\n",
        "            fontsize = 10,\n",
        "            xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20),\n",
        "            arrowprops = dict(facecolor = 'yellow'),\n",
        "            color = 'black',\n",
        "            backgroundcolor='white')\n",
        "\n",
        "  del df\n",
        "  del df_invalid\n",
        "  gc.collect()\n",
        "  ax.grid('on', which='major')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "br-rk3f9_P2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af559f9d-9299-4c6b-b1d2-e0df42ea127f"
      },
      "id": "br-rk3f9_P2G",
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.06 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Threshold Table"
      ],
      "metadata": {
        "id": "qYEzi3M-S0K6"
      },
      "id": "qYEzi3M-S0K6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def getThresholdTable (df):\n",
        "  SPO2_threshold_AND_condition = 85\n",
        "  HR_threshold_AND_condition = 100\n",
        "  SP02_threshold_OR_condition = 75\n",
        "  HR_threshold_OR_condition  = 90\n",
        "  Preset_Mode_Duration = 5\n",
        "\n",
        "  df_t = pd.DataFrame()\n",
        "  #df_t = df\n",
        "  # df_t [\"HR Threshold\"] = 60\n",
        "  # df_t [\"SPO2 Threshold\"] = 64\n",
        "  df_t [\"Data Date-Time\"] = df[\"Data Date-Time\"]\n",
        "  df_t [\"HR Threshold\"] = df[\"Preset mode\"]*HR_threshold_OR_condition\n",
        "  df_t [\"SPO2 Threshold\"] = df[\"Preset mode\"]*SP02_threshold_OR_condition\n",
        "  df_t[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]=df[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]\n",
        "  df_t[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]=df[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]\n",
        "\n",
        "  # df_t [\"HR Custom\"] = df[\"HR Threshold\"]\n",
        "  # df[\"SPO2 Threshold\"].notna().astype(int)*df[\"SPO2 Threshold\"]\n",
        "  # display (df_t)\n",
        "\n",
        "  #is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "\n",
        "  #print (\"df_t is: \")\n",
        "  #display (df_t)\n",
        "\n",
        "  return df_t"
      ],
      "metadata": {
        "id": "oDhFqjhBjY20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9058d3-ed90-4794-b44a-55a43ac14521"
      },
      "id": "oDhFqjhBjY20",
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.12 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot by Day"
      ],
      "metadata": {
        "id": "bHJA2jljjdc-"
      },
      "id": "bHJA2jljjdc-"
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "2ea3a1SQZLQB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c4cc28-25c2-4fb5-fe7e-db62a37b2cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.84 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_plot=df_j\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "def plotByDay (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = df[\"Data Date-Time\"].dt.date\n",
        "    # df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    length = len(date_list)\n",
        "    print (\"Number of days is\" + str(length))\n",
        "    print (\"Working on / free mem: \")\n",
        "    fname = folder_name + ' plot_by_day.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "        for i in range(length):\n",
        "          print (str(i), end = ' / ')\n",
        "          !free -h --si | awk  '/Mem:/{print $4} '\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "\n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "\n",
        "          # x axis start and end\n",
        "          x_axis_start = current_date.replace(second = 1)\n",
        "          #print(x_axis_start)\n",
        "          x_axis_end = current_date.replace(hour = 23, minute=59, second = 59)\n",
        "\n",
        "\n",
        "          ##### Sept 7 - Not sure if this below has to be commented or fixed\n",
        "          # df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"].astype(str)).dt.time\n",
        "          # #df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"])\n",
        "        #   df_current_date[\"Data Time\"] = df_current_date[\"Data Time\"].dt.time\n",
        "\n",
        "          df_current_date[\"Data Time\"] = df_current_date[\"Data Date-Time\"].dt.time\n",
        "          df_current_date.set_index('Data Time')\n",
        "          #display(df_current_date.dtypes)\n",
        "          #display (df_current_date)\n",
        "\n",
        "          plotApneBootData (df_current_date,current_date_64,x_axis_start,x_axis_end)\n",
        "          pdf.savefig()\n",
        "          plt.close()\n",
        "          del df_current_date\n",
        "          gc.collect()\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "2ea3a1SQZLQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot By Hour"
      ],
      "metadata": {
        "id": "eoiLSOJ3jfmj"
      },
      "id": "eoiLSOJ3jfmj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotByHour (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    # df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    # df[\"Data Time\"] = pd.to_datetime(df[\"Data Time\"])\n",
        "    # df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "\n",
        "    df[\"Data Date\"] = df[\"Data Date-Time\"].dt.date\n",
        "    df[\"Data Time\"] = df[\"Data Date-Time\"].dt.date\n",
        "    df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "\n",
        "    # display(df)\n",
        "    # return\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    date_length = len(date_list)\n",
        "    fname = folder_name + ' plot_by_hour.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "\n",
        "        firstPage = plt.figure(figsize=(11.69,8.27))\n",
        "        firstPage.clf()\n",
        "        txt = 'This is the title page'\n",
        "        firstPage.text(0.5,0.5,txt, transform=firstPage.transFigure, size=24, ha=\"center\")\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "\n",
        "        for i in range(date_length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "\n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "\n",
        "          hour_list = np.unique(df_current_date[\"Data Time-Hour\"])\n",
        "          hour_length = len(hour_list)\n",
        "          #print (hour_list)\n",
        "\n",
        "          for j in range(hour_length):\n",
        "              current_hour_64 = hour_list[j]\n",
        "              #current_date=pd.to_datetime(current_date_64)\n",
        "              df_current_hour = df_current_date[(df_current_date[\"Data Time-Hour\"]==current_hour_64)]\n",
        "              x_start = current_date + pd.offsets.Hour(current_hour_64)\n",
        "              x_end = current_date + pd.offsets.Hour(current_hour_64+1)\n",
        "              df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "\n",
        "              # x_start = df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              title = str (current_date) + ' ' + str(x_start)\n",
        "              plotApneBootData (df_current_hour,x_start,x_start,x_end)\n",
        "              # plotApneBootData (df_current_hour,current_date,current_hour_64,current_hour_64+1)\n",
        "              pdf.savefig()\n",
        "              plt.close()\n",
        "              del df_current_hour\n",
        "              gc.collect()\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "id": "kNpgyduy7ulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3557959-dfff-483f-b355-97866390d2a6"
      },
      "id": "kNpgyduy7ulE",
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.97 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubPlot Grids of Apnea Events"
      ],
      "metadata": {
        "id": "kPbeaF7WOonR"
      },
      "id": "kPbeaF7WOonR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "### Plot multiple subplots\n",
        "\n",
        "def PlotApneaEventsGrid (df):\n",
        "\n",
        "  start_offset = dt.timedelta (seconds=15)\n",
        "  end_offset = dt.timedelta (seconds=45)\n",
        "  num_rows = 2\n",
        "  num_cols = 2\n",
        "  num_subplots = num_rows * num_cols\n",
        "\n",
        "#   df_list_of_apnea_events = df[(df[Duration_Actual] != 0)]\n",
        "  df_list_of_apnea_events = df[(df[Duration_Preset] != 0)]\n",
        "\n",
        "  num_events = len(df_list_of_apnea_events)\n",
        "  # print (\"div \" + str(num_events/num_subplots))\n",
        "  # print (\"div \" + str(9/4))\n",
        "  # print (\"div \" + str(np.ceil(9/4)))\n",
        "  # #num_pages = int(num_events/num_subplots + 1)\n",
        "  num_pages = int(np.ceil(num_events/num_subplots))\n",
        "  #print (\"number of pages is \" + str (num_pages))\n",
        "  #print (\"number of events is \" + str (num_events))\n",
        "  current_page = 0\n",
        "  current_event = 0\n",
        "\n",
        "  fname = folder_name + ' plot_individual_events.pdf'\n",
        "  with PdfPages(fname) as pdf:\n",
        "    for page in range (num_pages):\n",
        "      fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols)\n",
        "      # print (axes.flat)\n",
        "      for ax in axes.flat:\n",
        "        if (current_event < num_events):\n",
        "          event_time = df_list_of_apnea_events.iloc[current_event].at[\"Data Date-Time\"]\n",
        "          plot_start = event_time - start_offset\n",
        "          plot_end = event_time + end_offset\n",
        "          df_event_data = df[((df[\"Data Date-Time\"] > plot_start) & (df[\"Data Date-Time\"] < plot_end))]\n",
        "          #print (\"Current Event Index is \" + str(current_event))\n",
        "          current_event = current_event + 1\n",
        "          plot_title = folder_name + \" Event \" + str(current_event) + \":  \" + str(event_time)\n",
        "          plotSPO2AndHR (df_event_data,plot_title,plot_start,plot_end,ax)\n",
        "    #   print (\"tight layout\")\n",
        "      fig.tight_layout()\n",
        "      pdf.savefig()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "C5DBtqMI2WTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb282020-06d0-49cc-ce43-ea7cd75d037a"
      },
      "id": "C5DBtqMI2WTB",
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.58 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4vbvlm-hsj"
      },
      "source": [
        "## **Create Tables & Plots Functions**"
      ],
      "id": "sm4vbvlm-hsj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Names"
      ],
      "metadata": {
        "id": "Y7x2w8JT2a_D"
      },
      "id": "Y7x2w8JT2a_D"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Global Variables\n",
        "### Column Names\n",
        "Duration_Actual = \"Event Duration (s) [Actual Data]\"\n",
        "Duration_Custom = \"Event Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "Duration_Preset = \"Event Duration (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "Count_Actual = \"Event Count [Actual Data]\"\n",
        "Count_Custom = \"Event Count [Using Custom Settings - Theoretical Calculation]\"\n",
        "Count_Preset = \"Event Count (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "SumDuration_Actual = \"Cumulative Duration (s) [Actual Data]\"\n",
        "SumDuration_Custom = \"Cumulative Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "SumDuration_Preset = \"Cumulative Duration (s) [Using Preset Settings - Theoretical Calculation]\""
      ],
      "metadata": {
        "id": "CgzuYBvt8zNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981946dd-de4b-4c9e-e40d-5c7f7d600483"
      },
      "id": "CgzuYBvt8zNI",
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 907 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Tables"
      ],
      "metadata": {
        "id": "mcXFuo902gfD"
      },
      "id": "mcXFuo902gfD"
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "vsIRg70SdobY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8657909f-685b-499a-bb20-52b7047a6e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 798 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def createDataTables (data_path):\n",
        "    df_LOGs = compileLogFiles (data_path)\n",
        "\n",
        "    df_s, df_d = splitToDataAndSettingsDF (df_LOGs)\n",
        "    # os.chdir(analysis_path)\n",
        "    # df_d.to_csv (folder_name + \" - Data.xlsx\")\n",
        "\n",
        "    # df_s.to_csv (folder_name + \" - Settings.xlsx\")\n",
        "    # dataframe_to_pdf(df_s, folder_name + \" - Settings\")\n",
        "\n",
        "    df_d[\"Is_Valid_Data\"] = GetIsValidColumn(df_d);\n",
        "\n",
        "    df_j = pd.merge (df_d,df_s, on='Settings Index')\n",
        "    # df_j = AddNumActualStimulations(df_j)\n",
        "    # df_j = AnalyzeWithCustomThresholds (df_j)\n",
        "    # df_j = AnalyzeWithPresetThresholds (df_j)\n",
        "    return df_j, df_d, df_s"
      ],
      "id": "vsIRg70SdobY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Plots"
      ],
      "metadata": {
        "id": "qINEVzl52lDl"
      },
      "id": "qINEVzl52lDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createPlots (df_j):\n",
        "    df_j.dtypes\n",
        "    plotByDay (df_j)\n",
        "    # plotByHour (df_j)\n",
        "    # PlotApneaEventsGrid (df_j)"
      ],
      "metadata": {
        "id": "AGgoCri491oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28605c78-3146-4420-eec3-f3807c9fc59a"
      },
      "id": "AGgoCri491oc",
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 635 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Summary Tables"
      ],
      "metadata": {
        "id": "N_4X5RS92tGl"
      },
      "id": "N_4X5RS92tGl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createSummaryTables (df,df_s):\n",
        "\n",
        "  df_s_columns_dropped = df_s.drop(['Settings Date','Settings Time','Alarm intensity'], axis=1)\n",
        "\n",
        "  reportApneaCountBySetting (df,df_s_columns_dropped)\n",
        "  reportIndividualActualApneas (df)"
      ],
      "metadata": {
        "id": "Ihvpi8G2ze28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3149dfc2-2543-4608-d3ca-a5cc4e3c5f5f"
      },
      "id": "Ihvpi8G2ze28",
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 733 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "R0eILh2iyWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c177f0ef-e33e-4fe4-a8c3-b221ab795723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 359 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_j stands for df_joined\n",
        "# display (df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"] !=0])\n",
        "#df[\"Time (hours)\"]={len(df)*1/60/60)\n",
        "# df_j.to_csv (folder_name + \" All_Data_Joined_Table.csv\")\n",
        "# df_s.to_csv (folder_name + \" Settings_Index_Table.csv\")"
      ],
      "id": "R0eILh2iyWqc"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# display(df_j[df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]!= df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]])\n",
        "# display(df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"]==0])"
      ],
      "metadata": {
        "id": "k7sHLvRYA10J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53b4f66-fa28-4958-ec21-2331738c10cd"
      },
      "id": "k7sHLvRYA10J",
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 374 s (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkSqcl_eQfV_",
        "outputId": "58fcf439-d7d8-4f59-b4d7-c4014d1a490b"
      },
      "id": "YkSqcl_eQfV_",
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.78 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aCjiZ7l3Qfyv"
      },
      "id": "aCjiZ7l3Qfyv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clinical Analysis**"
      ],
      "metadata": {
        "id": "GXKhxms5QiML"
      },
      "id": "GXKhxms5QiML"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Summary"
      ],
      "metadata": {
        "id": "c1_bNt0BWjOt"
      },
      "id": "c1_bNt0BWjOt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "spo2_list = [85, 80, 75, 70, 65]\n",
        "hr_list = [110, 100, 90, 80]\n",
        "spo2_col_time_name_list = []\n",
        "hr_col_time_name_list = []\n",
        "\n",
        "spo2_col_percent_name_list = []\n",
        "hr_col_percent_name_list = []\n",
        "\n",
        "for spo2 in spo2_list:\n",
        "    spo2_col_time_name_list.append(\"Time SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "    spo2_col_percent_name_list.append(\"% Time SPO2 < \"+str(spo2)+\" (%)\")\n",
        "for hr in hr_list:\n",
        "    hr_col_time_name_list.append(\"Time HR < \"+str(hr)+\" (hrs)\")\n",
        "    hr_col_percent_name_list.append(\"% Time HR < \"+str(hr)+\" (%)\")\n",
        "\n",
        "def createClinicalSummaryTable (df_j, record_name):\n",
        "    num_seconds_per_data_point = 1;\n",
        "    if (AB_Model == \"M1\"):\n",
        "        num_seconds_per_data_point = 2; # Tuhin's model M1 measured every 2 seconds.\n",
        "    df_is_valid_data = df_j[df_j[\"Is_Valid_Data\"] == True]\n",
        "    df_clinical_summary = pd.DataFrame ()\n",
        "    df_clinical_summary [\"Name\"] = [record_name]\n",
        "    df_clinical_summary [\"Time ApneBoot System Was On (hrs)\"] = round (len(df_j.index) / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"Time with valid vital and status readings (hrs)\"] = round (df_j[\"Is_Valid_Data\"].sum()/60/60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"SPO2 - Avg\"] = round (df_is_valid_data['SPO2'].mean(),1)\n",
        "    df_clinical_summary [\"SPO2 - Std\"] = round (df_is_valid_data['SPO2'].std(),2)\n",
        "    df_clinical_summary [\"HR - Avg\"] = round (df_is_valid_data['HR'].mean(),1)\n",
        "    df_clinical_summary [\"HR - Std\"] = round (df_is_valid_data['HR'].std(),2)\n",
        "    df_clinical_summary ['Num Events (Preset Threshold)'] = countApneas (df_is_valid_data[Duration_Preset])\n",
        "    df_clinical_summary ['Cumulative Event Duration (Preset Threshold)'] = sumApneaTime (df_is_valid_data[Duration_Preset])\n",
        "\n",
        "    for spo2 in spo2_list:\n",
        "        df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"] = round(df_is_valid_data.query ('SPO2 < '+str(spo2))['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "        df_clinical_summary [\"% Time SPO2 < \"+str(spo2)+\" (%)\"] = round(df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "\n",
        "    for hr in hr_list:\n",
        "        df_clinical_summary [\"Time HR < \"+str(hr)+\" (hrs)\"] = round(df_is_valid_data.query ('HR < '+str(hr))['HR'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "        df_clinical_summary [\"% Time HR < \"+str(hr)+\" (%)\"] = round(df_clinical_summary [\"Time HR < \"+str(hr)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "\n",
        "    return df_clinical_summary"
      ],
      "metadata": {
        "id": "uRiSHGwMw5XT",
        "outputId": "cc00bea6-631a-41f6-fe1b-03b2f97082db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uRiSHGwMw5XT",
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.8 ms (started: 2023-11-15 09:07:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Match Table"
      ],
      "metadata": {
        "id": "PZ_oJn6SQmSJ"
      },
      "id": "PZ_oJn6SQmSJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def makeMatchTable ():\n",
        "    ### Match Table\n",
        "    startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "    lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "    clinical_fn = \"Overall Clinical Summary - Detailed.xlsx\"\n",
        "    # createClinicalSummaryTable()\n",
        "    os.chdir(startpath)\n",
        "    df_lookup = pd.read_csv(lookup_fn)\n",
        "    os.chdir(analysis_path)\n",
        "    df_clinical = pd.read_excel(clinical_fn)\n",
        "\n",
        "    df_match = df_lookup.set_index('shortpath').join(df_clinical.set_index('path'))\n",
        "    columns_to_keep = [\n",
        "    # \"Order\",\n",
        "    \"Institution Group\",\n",
        "    \"Baby of\",\n",
        "    \"Start date of enrollment\",\n",
        "    \"End date of enrollment\",\n",
        "    \"Device_type\",\n",
        "    \"Number of days of enrollment\",\n",
        "    \"Birth weight (grams)\",\n",
        "    \"GA\",\n",
        "    \"Sub-Group\",\n",
        "    # \"Total hypoxia duration (in secs)\",\n",
        "    # \"Total hypoxia duration (in hh:mm:ss)\",\n",
        "    \"Ventilation\",\n",
        "    # \"86,400\",\n",
        "    # \"Time Enrolled (S)\",\n",
        "    # \"#Seconds in a day\",\n",
        "    # \"% seconds in Hypoxia\",\n",
        "    # \"Notes\",\n",
        "    # \"Notes 2\",\n",
        "    # \"Unnamed: 0\",\n",
        "    # \"Name\",\n",
        "    \"Time ApneBoot System Was On (hrs)\",\n",
        "    \"Time with valid vital and status readings (hrs)\",\n",
        "    \"SPO2 - Avg\",\n",
        "    \"SPO2 - Std\",\n",
        "    \"HR - Avg\",\n",
        "    \"HR - Std\",\n",
        "    \"model\",\n",
        "    'Num Events (Preset Threshold)',\n",
        "    'Cumulative Event Duration (Preset Threshold)'\n",
        "    # \"data date-time\",\n",
        "    ]\n",
        "\n",
        "    columns_to_keep = columns_to_keep + spo2_col_time_name_list + hr_col_time_name_list + spo2_col_percent_name_list + hr_col_percent_name_list\n",
        "    print (columns_to_keep)\n",
        "    df_match = df_match [columns_to_keep]\n",
        "    df_match.to_excel (\"4 - Matched Table Summary.xlsx\")\n",
        "    return df_match"
      ],
      "metadata": {
        "id": "7SYrEoQoApav",
        "outputId": "57747ecf-b63f-4009-f51e-dc2caf0def7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7SYrEoQoApav",
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.18 ms (started: 2023-11-15 09:07:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clinical Analysis"
      ],
      "metadata": {
        "id": "mOMYLLGgQ2pK"
      },
      "id": "mOMYLLGgQ2pK"
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind\n",
        "import os\n",
        "!pip install xlsxwriter\n",
        "\n",
        "\n",
        "def makeAnalysisTable (df_match):\n",
        "    plot_opts = {\n",
        "        \"cutoff_val\": 5,\n",
        "        \"cutoff_type\": \"abs\",\n",
        "        \"label_fontsize\": \"small\",\n",
        "        \"label_rotation\": 30,\n",
        "    }\n",
        "\n",
        "    # exclude certain babies\n",
        "    # df_match = df_match[df_match['Baby of']!= 'Ramanamma']\n",
        "\n",
        "    drop_babies = [\n",
        "    'Ramanamma',\n",
        "    'Manjula',\n",
        "    'Shwetha 2',\n",
        "    'Noor Fathima T-1',\n",
        "    ]\n",
        "\n",
        "    for baby in drop_babies:\n",
        "        df_match = df_match[df_match['Baby of']!= baby]\n",
        "        # df_match.drop ((df_match['Baby of'] == baby).index, inplace = True)\n",
        "\n",
        "\n",
        "    # Creates a list of all columns that have number data:\n",
        "    # df_match.dtypes\n",
        "    analysis_columns = df_match.select_dtypes(include=['float64', 'int64']).columns\n",
        "    # print (analysis_columns)\n",
        "\n",
        "\n",
        "    # #  display (df_match)\n",
        "    # df_melt = df_match.melt (id_vars = ['Device_type'],value_vars= spo2_col_percent_name_list, var_name = 'Group', value_name = 'SPO2 Level')\n",
        "    # # display (df_melt)\n",
        "    # # fig = plt.figure(10,10)\n",
        "    # # ax = fig.add_subplot(111)\n",
        "    # fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    # sns.boxplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "    # # sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "    # fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
        "    # sns.catplot(data=df_melt, col = 'SPO2 Level', x = 'Group', y = 'SPO2 Level', hue = 'Device_type', aspect=.5, ax = ax2)\n",
        "\n",
        "    # df_stats = pd.DataFrame ( columns= ['Characteristic', 'Placebo (n)', 'Placebo (avg)', 'Placebo (std)', 'Intervention (n)', 'Intervention (avg)', 'Intervention (std)', 'statistic', 'p-value'])\n",
        "    df_stats = pd.DataFrame ()\n",
        "\n",
        "    # for col in spo2_col_percent_name_list:\n",
        "    for col in analysis_columns:\n",
        "        placebo = df_match[df_match['Device_type']=='Placebo']\n",
        "        intervention = df_match[df_match['Device_type']=='Intervention']\n",
        "        # print (\"col: \" + col)\n",
        "        # print(ttest_ind(placebo[col], intervention[col]))\n",
        "        statistic, p_value = ttest_ind(placebo[col], intervention[col])\n",
        "\n",
        "        # df_stats_current = pd.DataFrame ( columns= ['Characteristic', 'Placebo (n)', 'Placebo (avg)', 'Placebo (std)', 'Intervention (n)', 'Intervention (avg)', 'Intervention (std)', 'statistic', 'p-value'])\n",
        "        df_stats_current = {\n",
        "            'Characteristic': col,\n",
        "            'Placebo (n)': len(placebo.index),\n",
        "            'Placebo (min)': placebo[col].min (),\n",
        "            'Placebo (max)': placebo[col].max (),\n",
        "            'Placebo (median)': round(placebo[col].median(),2),\n",
        "            'Placebo (avg)': round (placebo[col].mean (),2),\n",
        "            'Placebo (std)': round (placebo[col].std(),2),\n",
        "            'Intervention (n)': len(intervention.index),\n",
        "            'Intervention (min)': intervention[col].min (),\n",
        "            'Intervention (max)': intervention[col].max (),\n",
        "            'Intervention (median)': round (intervention[col].median(),2),\n",
        "            'Intervention (avg)': round (intervention[col].mean(),2),\n",
        "            'Intervention (std)': round (intervention[col].std(),2),\n",
        "            'statistic': round (statistic,2),\n",
        "            'p-value': round (p_value,3)\n",
        "        }\n",
        "\n",
        "        df_stats_current = pd.DataFrame(df_stats_current, index=[0])\n",
        "        if len(df_stats) == 0:\n",
        "            df_stats = df_stats_current\n",
        "        else:\n",
        "            df_stats = pd.concat([df_stats, df_stats_current])\n",
        "        # df_stats_current = pdf.Dataframe (df_stats_current, )\n",
        "\n",
        "        # # display (placebo)\n",
        "        # df_stats_current ['Characteristic'][col] = col\n",
        "        # df_stats_current ['Placebo (n)'] = placebo.count\n",
        "        # df_stats = pd.concat ([df_stats, df_stats_current])\n",
        "\n",
        "\n",
        "        # df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "    return df_stats\n",
        "    # display (df_stats)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #perform independent two sample t-test\n",
        "\n",
        "    # sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', color = 'red')\n",
        "    # sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # df_beanplot = pd.DataFrame ()\n",
        "    # df_beanplot ['Baby of'] = df_match['Baby of']\n",
        "    # # df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'][df_match['Device_type'] == 'Intervention']\n",
        "    # df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Intervention')\n",
        "    # df_beanplot['Placebo'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Placebo')\n",
        "    # # plt.boxplot(df_match['Time SPO2 < 85(hrs)'])\n",
        "    # # display (df_beanplot)\n",
        "    # df_intervention = pd.DataFrame ()\n",
        "    # df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "    # # df_intervention['Intervention'] = df_beanplot['Intervention'].dropna();\n",
        "    # # df_intervention = df_intervention.dropna ()\n",
        "    # # df_placebo = pd.DataFrame ()\n",
        "    # # df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "    # # df_intervention = df_intervention.dropna ()\n",
        "    # # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "    # # sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "    # display (df_match)\n",
        "    # df_stack = df_match.stack()\n",
        "    # display (df_stack)\n",
        "    # # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "\n",
        "    # # df_intervention = df_intervention [df_intervention['Intervention'].]\n",
        "    # # display (df_intervention)\n",
        "    # # plt.boxplot(df_intervention['Intervention'])\n",
        "\n",
        "    # # plt.show()\n",
        "    # # display (df_beanplot)\n",
        "    # # data = sm.load_pandas()\n",
        "    # # data = sm.load()\n",
        "\n",
        "    # # sm.graphics.beanplot (df_beanplot., ax=ax, labels = ['Intervention', 'Placebo'], plot_opts=plot_opts)\n",
        "\n",
        "    # # sm.graphics.beanplot(age, ax=ax, labels=labels, plot_opts=plot_opts)\n",
        "\n",
        "def analyzeAllData (df_match):\n",
        "    startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "    # os.chdir(startpath)\n",
        "    analysis_path = startpath + \"/\" + \"Analysis_Files\"\n",
        "    os.chdir(analysis_path)\n",
        "    # filename = \"4 - Matched Table Summary - Analysis Backup.xlsx\"\n",
        "    filename = \"4 - Matched Table Summary.xlsx\"\n",
        "    df_match = pd.read_excel(filename)\n",
        "    df_p_values = makeAnalysisTable (df_match)\n",
        "\n",
        "    filter_list = ['Institution Group', 'Sub-Group','Ventilation']\n",
        "\n",
        "    df_p_values_by_setting = pd.DataFrame ()\n",
        "\n",
        "    for filter in filter_list:\n",
        "        print (filter)\n",
        "        filter_setpoints = df_match[filter].unique ()\n",
        "        for setpoint in filter_setpoints:\n",
        "            print (setpoint)\n",
        "            df_local = makeAnalysisTable (df_match[df_match[filter]==setpoint])\n",
        "            # display (df_local)\n",
        "            df_local.insert(0, \"Filter Setting\", setpoint, True)\n",
        "            df_local.insert(0, \"Filter Criteria\", filter, True)\n",
        "            if len(df_p_values_by_setting) == 0:\n",
        "                df_p_values_by_setting = df_local\n",
        "            else:\n",
        "                df_p_values_by_setting = pd.concat([df_p_values_by_setting, df_local])\n",
        "\n",
        "    with pd.ExcelWriter(\"5 - Analysis Summary.xlsx\", engine=\"xlsxwriter\") as writer:\n",
        "        writeExcelFormatted (df_match, writer, \"Summary Table\")\n",
        "        writeExcelFormatted (df_p_values, writer, \"Analysis\")\n",
        "        writeExcelFormatted (df_p_values_by_setting, writer, \"Subgroup Analysis\")\n",
        "        # df_match.to_excel(writer, sheet_name=\"Summary Table\", index=False)\n",
        "        # df_p_values.to_excel(writer, sheet_name=\"Analysis\", index=False)\n",
        "        # df_p_values_by_setting.to_excel(writer, sheet_name=\"Subgroup Analysis\", index=False)\n",
        "        # writer.sheets['Summary Table'].set_row(0, 30, formats['text_wrap'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hq6gb8jmW4af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e70a60-38a5-492e-d4f6-775e0194f7ad"
      },
      "id": "hq6gb8jmW4af",
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.1.9)\n",
            "time: 20.2 s (started: 2023-11-15 09:07:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_DoOIC5KdJbm"
      },
      "id": "_DoOIC5KdJbm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write to Excel File Formatted"
      ],
      "metadata": {
        "id": "v9jmrhOXdJg1"
      },
      "id": "v9jmrhOXdJg1"
    },
    {
      "cell_type": "code",
      "source": [
        "def writeExcelFormatted (df, writer, sheet):\n",
        "    # Write data\n",
        "    df.to_excel(writer, index=False, sheet_name=sheet, header=False, startrow=1)\n",
        "\n",
        "    # Write header\n",
        "\n",
        "    for colx, value in enumerate(df.columns.values):\n",
        "        writer.sheets[sheet].write(0, colx, value)\n",
        "\n",
        "    # Style header\n",
        "    workbook = writer.book\n",
        "    header_format = workbook.add_format({'bold': True, 'text_wrap': True, 'align': 'center'})\n",
        "    writer.sheets[sheet].set_row(0, 50, header_format)\n",
        "\n",
        "    # df.to_excel(writer, sheet_name=sheet, index=False)\n",
        "    # workbook=writer.book\n",
        "    # worksheet = writer.sheets[sheet]\n",
        "\n",
        "    # format = workbook.add_format({'bold': True, 'text_wrap': True, 'align': 'center'})\n",
        "\n",
        "    # # Setting the format but not setting the column width.\n",
        "    # worksheet.set_row(0, None, format)\n",
        "\n",
        "    # writer.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_EB62d7R4px",
        "outputId": "7ef39cf9-2bf4-4da9-ba17-07a5569b73a1"
      },
      "id": "f_EB62d7R4px",
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.08 ms (started: 2023-11-15 09:08:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main FOR LOOP Code**"
      ],
      "metadata": {
        "id": "CBYeLA0ecXMn"
      },
      "id": "CBYeLA0ecXMn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ignore/Include Babies / Paths"
      ],
      "metadata": {
        "id": "h_O_6rp3c3vX"
      },
      "id": "h_O_6rp3c3vX"
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_paths = [\n",
        "\"ation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha\",\n",
        "\"Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New\",\n",
        "\"dation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1\",\n",
        "\"ion/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data\",\n",
        "\"ion/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo\",\n",
        "\" Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha\",\n",
        "\"dation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma\",\n",
        "]\n",
        "\n",
        "do_path = [\n",
        "    # 'eport/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary'\n",
        "]\n",
        "\n",
        "# def bool skipAnalysis (shortpath):\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGid3lyQ7Y2",
        "outputId": "a2602044-deee-48fe-b870-fd41d7bbd99c"
      },
      "id": "BbGid3lyQ7Y2",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 649 s (started: 2023-11-15 09:08:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gXIUL2llc3hf"
      },
      "id": "gXIUL2llc3hf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for Main Loop"
      ],
      "metadata": {
        "id": "CxPyenoycyHu"
      },
      "id": "CxPyenoycyHu"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# folder_name = \"Geetha\"\n",
        "startpath = \"\"\n",
        "analysis_path = \"\"\n",
        "analysis_folder = \"\"\n",
        "folder_name = \"\"\n",
        "Data_Cleanup_SP02_LowCutOff = 50  #If the SPO2 value at the time of APnea is below 60, it must be a bad data point.\n",
        "Data_Cleanup_HR_LowCutOff = 50\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # Custom Callback To Include in Callbacks List At Training Time\n",
        "# class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "def main_function ():\n",
        "    global startpath\n",
        "    global analysis_path\n",
        "    global analysis_folder\n",
        "    global folder_name\n",
        "    startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai\"\n",
        "\n",
        "    time = pd.Timestamp.now(tz=None)\n",
        "    import traceback\n",
        "\n",
        "    AB_Model = \" \"\n",
        "\n",
        "    paths, folder_names = list_folders(startpath)\n",
        "    print (paths)\n",
        "    print (folder_names)\n",
        "\n",
        "    PRINT_TABLES = False\n",
        "    SAVE_DFJ = True\n",
        "    READ_SAVED_DFJ = False\n",
        "\n",
        "    os.chdir(startpath)\n",
        "    # os.makedirs(str(time) + \" - Analysis_Files\", exist_ok=True)\n",
        "    # analysis_path = startpath + \"/\" + str(time) + \" - Analysis_Files\"\n",
        "\n",
        "    os.makedirs(\"Analysis_Files\", exist_ok=True)\n",
        "    analysis_path = startpath + \"/\" + \"Analysis_Files\"\n",
        "\n",
        "    os.chdir(analysis_path)\n",
        "    # errors = pd.DataFrame (columns = ['Folder Name',\"Model\",'Exception', \"filename\", \"lineno\", \"funcname\", \"text\"])\n",
        "    errors = pd.DataFrame ()\n",
        "    df_overall_clinical_summary = pd.DataFrame ()\n",
        "    df_overall_clinical_summary_detailed = pd.DataFrame ()\n",
        "\n",
        "    i = 0;\n",
        "    for path in paths:\n",
        "        try:\n",
        "\n",
        "        # folder_name = folder_names[i]\n",
        "\n",
        "        # This code ignores the paths in the folder that are not worth analyzing - saves anaysis time.\n",
        "            short_path = path[-100:]\n",
        "            ignore = False;\n",
        "\n",
        "            for badpath in ignore_paths:\n",
        "                if short_path == badpath:\n",
        "                    ignore = True\n",
        "\n",
        "            if ignore == True:\n",
        "                print (\"Ignoring\" + folder_name)\n",
        "                continue\n",
        "\n",
        "        # short_path = path[-100:]\n",
        "            baby_name = getBabyName(short_path)\n",
        "            folder_name = baby_name #This was added later to differentiate between folder names that were the same like \"ApneBoot Data\"\n",
        "\n",
        "            i += 1\n",
        "            print (\"------ Folder \" + str(i) + ' of ' + str(len(paths)), end = \": \")\n",
        "            print (\"Baby of \" + baby_name)\n",
        "\n",
        "\n",
        "\n",
        "        # this code does only the path in \"do_path\" if there are any\n",
        "            if (len(do_path) > 0):\n",
        "              if (do_path[0]!= short_path):\n",
        "                continue\n",
        "\n",
        "            print (\"free mem start:\",end = \" \")\n",
        "            !free -h --si | awk  '/Mem:/{print $4}'\n",
        "\n",
        "        # try:\n",
        "            os.chdir(analysis_path)\n",
        "            analysis_folder = \"Analysis - \" + folder_name\n",
        "\n",
        "            os.makedirs(analysis_folder, exist_ok=True)\n",
        "            current_analysis_folder_path = analysis_path+ '/' + analysis_folder\n",
        "\n",
        "            os.chdir(current_analysis_folder_path)\n",
        "\n",
        "            if (READ_SAVED_DFJ == False):\n",
        "                df_j, df_d, df_s = createDataTables (path)\n",
        "            else:\n",
        "                os.chdir(current_analysis_folder_path)\n",
        "                # print (os.getcwd)\n",
        "                # print ('files:')\n",
        "                # print (os.listdir() )\n",
        "                df_j = pd.read_csv(folder_name + ' - df_j.csv')\n",
        "\n",
        "            if 'Settings Date-Time' not in df_j.columns:\n",
        "                print (\"1\")\n",
        "                df_j['Settings Date-Time'] = getDateTimeColumn (df_j[[\"Settings Date-Time\"]])\n",
        "            if 'Data Date-Time' not in df_j.columns:\n",
        "                print (\"2\")\n",
        "                df_j['Data Date-Time'] = getDateTimeColumn (df_j[[\"Data Date-Time\"]])\n",
        "            else: # assumes both settings and date are both in or out.\n",
        "                # print (\"3\", end =\" \")\n",
        "                df_j['Settings Date-Time']= pd.to_datetime(df_j['Settings Date-Time'])\n",
        "                df_j['Data Date-Time']= pd.to_datetime(df_j['Data Date-Time'])\n",
        "\n",
        "            if \"Is_Valid_Data\" not in df_j.columns:\n",
        "                df_j[\"Is_Valid_Data\"] = GetIsValidColumn(df_j)\n",
        "            if Duration_Preset not in df_j.columns:\n",
        "                AnalyzeWithPresetThresholds (df_j)\n",
        "            if (SAVE_DFJ == True):\n",
        "                os.chdir(current_analysis_folder_path)\n",
        "                df_j.to_csv (folder_name + ' - df_j.csv')\n",
        "\n",
        "            # print (df_j.dtypes)\n",
        "            # plotByDay (df_j)\n",
        "            # plotByHour (df_j)\n",
        "            # PlotApneaEventsGrid (df_j)\n",
        "            # createSummaryTables (df_j,df_s)\n",
        "            # print (df_j.columns)\n",
        "\n",
        "            # baby_name = getBabyName(short_path)\n",
        "            df_current_clinical_summary = pd.DataFrame ()\n",
        "            df_current_clinical_summary = createClinicalSummaryTable (df_j, baby_name)\n",
        "            df_current_clinical_summary[\"path\"] = path[-100:]\n",
        "            df_overall_clinical_summary = pd.concat([df_overall_clinical_summary, df_current_clinical_summary])\n",
        "            os.chdir(analysis_path)\n",
        "\n",
        "\n",
        "            #####\n",
        "            df_current_clinical_summary_detailed = df_current_clinical_summary\n",
        "            # df_current_clinical_summary_detailed[\"file_list\"] = file_list\n",
        "            df_current_clinical_summary_detailed[\"model\"] = AB_Model;\n",
        "            df_current_clinical_summary_detailed[\"data date-time\"] = df_j[\"Data Date-Time\"].iloc[0];\n",
        "            df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "\n",
        "            print (folder_name + \" success!\")\n",
        "\n",
        "        except Exception as exc:\n",
        "            print (\"ERROR FOR \" + folder_name + \":\")\n",
        "            filename, lineno, funcname, text = traceback.extract_tb(exc.__traceback__)[-1]\n",
        "            print (exc)\n",
        "            print(filename, lineno, funcname, text)\n",
        "            short_path = path[-100:]\n",
        "            current_error = pd.DataFrame (data = {'short_path': [short_path], 'Folder Name':[folder_name], \"Model\": [AB_Model], 'Exception':[exc], \"filename\": [filename], \"lineno\": [lineno], \"funcname\": [funcname], \"text\": [text], 'data header': [header], 'settings header': [settings_header], 'numcommas':[number_of_commas]})\n",
        "            errors = errors.append (current_error,ignore_index = True);\n",
        "            os.chdir(analysis_path)\n",
        "            errors.to_excel (\"Error Summary.xlsx\")\n",
        "\n",
        "        # print (\"free mem end before gc:\",end = \" \")\n",
        "        # !free -h --si | awk  '/Mem:/{print $4}'\n",
        "        # gc.collect()\n",
        "        # print (\"free mem end after gc:\",end = \" \")\n",
        "        # !free -h --si | awk  '/Mem:/{print $4}'\n",
        "\n",
        "    df_overall_clinical_summary.to_excel (\"Overall Clinical Summary.xlsx\")\n",
        "    df_overall_clinical_summary_detailed.to_excel (\"Overall Clinical Summary - Detailed.xlsx\")\n",
        "    print (\"errors table:\")\n",
        "    display (errors)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RtVUyZ_9ZcLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22aa92f9-ad57-4204-c7fb-c738f96f3747"
      },
      "id": "RtVUyZ_9ZcLO",
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8 ms (started: 2023-11-15 09:08:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getBabyName (short_path):\n",
        "    # Match the Baby Of Name\n",
        "    lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "    # createClinicalSummaryTable()\n",
        "    os.chdir(startpath)\n",
        "    df = pd.read_csv(lookup_fn)\n",
        "    os.chdir(analysis_path)\n",
        "    print (\" looking up short_path \"+short_path)\n",
        "\n",
        "    df = df[df['shortpath']==short_path]\n",
        "    baby_name = df['Baby of'].iloc[0]\n",
        "    print (\"Baby of\" + baby_name)\n",
        "    return baby_name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhHLYEz2pnmV",
        "outputId": "7a1d0e38-3a24-482a-ff26-c8d843436d4e"
      },
      "id": "zhHLYEz2pnmV",
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1 ms (started: 2023-11-15 09:09:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call Functions"
      ],
      "metadata": {
        "id": "lafBAULlcpL1"
      },
      "id": "lafBAULlcpL1"
    },
    {
      "cell_type": "code",
      "source": [
        "main_function()\n",
        "df_match = makeMatchTable ()\n",
        "analyzeAllData (df_match)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV0cBB_6cetE",
        "outputId": "2dc5366f-95e0-4167-c0ee-3d35da5f0856"
      },
      "id": "BV0cBB_6cetE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Parvati_intervention/Parvathi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Johnsi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Surya/surya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Suma/suma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sravani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sayeda', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Geetha/Geetha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Santoshini', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Shobha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Vaishali', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sudha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Remi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Humera', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Aruna', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Anusha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 1/BO Tadamarri twin 1 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Shwetha 2', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Ayesha Banu', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Manjula', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Prema/BO Prema Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /stj70221oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701/stj703_21oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702/stj70121oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Stj03_01-sep', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ702_Intervention_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ701_Placebo_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 2/BO Tadamari twin 2 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Chandrakala Twin 1/BO Chandrakala Twin 1 Raw Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Noor Fathima/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath /Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sravanthi/AB Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/VaraLaxmi/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sunitha/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai/Raw data of AB device', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Tehseen', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Vani/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ramanamma/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Saraswati/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Hafsa/AB Device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Mounika/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Bhavani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Heena/ApneBoot Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ahmedi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Jyothi/Apneboot data']\n",
            "['Parvathi', 'Johnsi', 'surya', 'suma', 'Sravani', 'Sayeda', 'Sneha', 'Geetha', 'Santoshini', 'Mary', 'Bhagya New', 'Soniya Mary', 'Shobha', 'Vaishali', 'Sujatha', 'Sudha', 'Remi', 'Sushma', 'Anitha', 'Baby of  Sujatha', 'Baby of Pavithra_placebo', 'Humera', 'Bhagya', 'Sushma', 'Aruna', 'Anitha', 'Anusha', 'Baby of Pavithra_placebo', 'Intervention_Unclear data', 'BO Hemabindu 2 data', 'BO Tadamarri twin 1 Raw data', 'BO Shwetha 2', 'BO Anitha', 'BO Ayesha Banu', 'BO Manjula', 'BO Prema Raw data', 'stj70221oct', 'stj703_21oct', 'st701', 'stj70121oct', 'st702', 'Stj03_01-sep', 'STJ702_Intervention_Clinical data_24_July-2020_4PM', 'STJ701_Placebo_Clinical data_24_July-2020_4PM', 'Baby 1', 'BO Tadamari twin 2 Raw data', 'BO Chandrakala Twin 1 Raw Data', 'Apneboot device data', 'Apneboot data', 'AB Data', 'AB device data', 'Apneboot device data', 'Raw data of AB device', 'Tehseen', 'AB device data', 'Apneboot data', 'AB device data', 'AB Device data', 'Apneboot data', 'Bhavani', 'ApneBoot Data', 'Ahmedi', 'Apneboot data']\n",
            " looking up short_path al Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Parvati_intervention/Parvathi\n",
            "Baby ofParvathi\n",
            "------ Folder 1 of 63: Baby of Parvathi\n",
            "free mem start: 5.9G\n",
            "['27log29.csv']\n",
            "27-06-2019, 22:39:32,163,255,127,0\n",
            "27-06-2019, 22:39:36,163,255,127,0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Parvathi success!\n",
            " looking up short_path eport/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Johnsi\n",
            "Baby ofJohnsi\n",
            "------ Folder 2 of 63: Baby of Johnsi\n",
            "free mem start: 5.8G\n",
            "['LOG00186.TXT']\n",
            "16/07/19,08:47:45,000,000,3,0000,0,0,0,\n",
            "16/07/19,08:47:47,150,095,0,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Johnsi success!\n",
            " looking up short_path /Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Surya/surya\n",
            "Baby ofSurya\n",
            "------ Folder 3 of 63: Baby of Surya\n",
            "free mem start: 5.2G\n",
            "['10log22.csv', '12log5.csv']\n",
            "10/6/2019 , 19:54:9, 171, 255, 127, 0\n",
            "10/6/2019 , 19:54:13, 129, 167, 100, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Surya success!\n",
            " looking up short_path rt/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Suma/suma\n",
            "Baby ofSuma\n",
            "------ Folder 4 of 63: Baby of Suma\n",
            "free mem start: 6.6G\n",
            "['10log7.csv', '12log2.csv', '7log11.csv', '8log1.csv']\n",
            "10/6/2019 , 17:25:12, 163, 255, 127, 0\n",
            "10/6/2019 , 17:25:16, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Suma success!\n",
            " looking up short_path port/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sravani\n",
            "Baby ofNandaluru Sravani\n",
            "------ Folder 5 of 63: Baby of Nandaluru Sravani\n",
            "free mem start: 6.7G\n",
            "['logRNSravani - for Colab.csv']\n",
            "22-02-2019, 19:4:23,163,255,127,0\n",
            "22-02-2019, 19:4:27,163,255,127,0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Nandaluru Sravani success!\n",
            " looking up short_path eport/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sayeda\n",
            "Baby ofSyeda\n",
            "------ Folder 6 of 63: Baby of Syeda\n",
            "free mem start: 6.7G\n",
            "['14log1.csv', '16log1.csv']\n",
            "14/6/2019 , 12:52:23, 227, 255, 127, 0\n",
            "14/6/2019 , 12:52:27, 227, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Syeda success!\n",
            " looking up short_path Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\n",
            "Baby ofSneha\n",
            "------ Folder 7 of 63: Baby of Sneha\n",
            "free mem start: 6.7G\n",
            "['12log5 - made from mona xls file - date reformatted.csv']\n",
            "12-6-19,19:35:57,163,255,127,0\n",
            "12-6-19,19:36:01,131,255,82,0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Sneha success!\n",
            " looking up short_path alidation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Geetha/Geetha\n",
            "Baby ofKonapalli Geetha\n",
            "------ Folder 8 of 63: Baby of Konapalli Geetha\n",
            "free mem start: 6.6G\n",
            "['LOG00184 (1).TXT', 'LOG00185 (1).TXT', 'LOG00187 (1).TXT']\n",
            "14/07/19,10:06:52,000,000,3,0000,0,0,0,\n",
            "14/07/19,10:06:54,000,000,3,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Konapalli Geetha success!\n",
            " looking up short_path t/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Santoshini\n",
            "Baby ofSantoshini\n",
            "------ Folder 9 of 63: Baby of Santoshini\n",
            "free mem start: 6.3G\n",
            "['logRNSantoshini - Colab Analysis.csv']\n",
            "7/2/19, 14:4:5,163,255,127,0\n",
            "7/2/19, 14:4:9,163,255,127,0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Santoshini success!\n",
            " looking up short_path  Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Mary\n",
            "Baby ofMarie Juliet\n",
            "------ Folder 10 of 63: Baby of Marie Juliet\n",
            "free mem start: 6.4G\n",
            "['logRNMaryJuliet - for Colab.csv']\n",
            "7/2/19, 13:55:22,163,255,127,3\n",
            "7/2/19, 13:55:26,129,188,100,3\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Marie Juliet success!\n",
            "IgnoringMarie Juliet\n",
            " looking up short_path eport/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary\n",
            "Baby ofSoniya Mary\n",
            "------ Folder 11 of 63: Baby of Soniya Mary\n",
            "free mem start: 6.5G\n",
            "['24log15.csv', '24log29.csv', '24log35.csv', '24log42.csv', '24log6.csv', '4log10.csv', '4log14.csv', '4log7.csv', '6log13.csv', '6log6.csv', '7log6.csv']\n",
            "24/1/2019 , 10:45:34, 163, 255, 127, 0\n",
            "24/1/2019 , 10:45:38, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Soniya Mary success!\n",
            " looking up short_path ion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Shobha\n",
            "Baby ofShobha\n",
            "------ Folder 12 of 63: Baby of Shobha\n",
            "free mem start: 6.3G\n",
            "['LOG00035.TXT', 'LOG00036.TXT', 'LOG00038.TXT', 'LOG00039.TXT']\n",
            "18/11/14,00:59:22,000,000,1,0000,0,0,0,00c2.97v;\n",
            "18/11/14,00:59:24,000,098,0,0000,0,0,0,00c3.71v;\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Shobha success!\n",
            " looking up short_path n Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Vaishali\n",
            "Baby ofVaishali Twin 2\n",
            "------ Folder 13 of 63: Baby of Vaishali Twin 2\n",
            "free mem start: 6.1G\n",
            "['14log18.csv']\n",
            "14/6/2019 , 15:25:0, 163, 255, 127, 0\n",
            "14/6/2019 , 15:25:4, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Vaishali Twin 2 success!\n",
            " looking up short_path on Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sujatha\n",
            "Baby ofSujata\n",
            "------ Folder 14 of 63: Baby of Sujata\n",
            "free mem start: 6.0G\n",
            "['LOG00089 (2).TXT', 'LOG00090 (1).TXT', 'LOG00184.TXT', 'LOG00185.TXT']\n",
            "10/07/19,16:33:05,000,000,3,0000,0,0,0,\n",
            "10/07/19,16:33:07,000,000,3,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Sujata success!\n",
            " looking up short_path tion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sudha\n",
            "Baby ofSudha\n",
            "------ Folder 15 of 63: Baby of Sudha\n",
            "free mem start: 5.5G\n",
            "['1log7.csv']\n",
            "1/3/2019 , 16:2:4, 163, 255, 127, 0\n",
            "1/3/2019 , 16:2:8, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Sudha success!\n",
            " looking up short_path ation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Remi\n",
            "Baby ofRani Remi\n",
            "------ Folder 16 of 63: Baby of Rani Remi\n",
            "free mem start: 5.6G\n",
            "['LOG00097.TXT', 'LOG00098.TXT', 'LOG00099.TXT', 'LOG00100.TXT']\n",
            "20/08/19,13:27:00,000,000,1,0000,0,0,0,\n",
            "20/08/19,13:27:02,000,000,2,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Rani Remi success!\n",
            "IgnoringRani Remi\n",
            "IgnoringRani Remi\n",
            "IgnoringRani Remi\n",
            "IgnoringRani Remi\n",
            " looking up short_path ion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Humera\n",
            "Baby ofHumera Taj\n",
            "------ Folder 17 of 63: Baby of Humera Taj\n",
            "free mem start: 5.6G\n",
            "['LOG00101.TXT', 'LOG00102.TXT', 'LOG00103.TXT', 'LOG00104.TXT', 'LOG00105.TXT', 'LOG00106.TXT']\n",
            "23/08/19,21:47:43,000,000,3,0000,0,0,0,\n",
            "23/08/19,21:47:45,000,000,3,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Humera Taj success!\n",
            " looking up short_path ion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya\n",
            "Baby ofBhagya\n",
            "------ Folder 18 of 63: Baby of Bhagya\n",
            "free mem start: 4.5G\n",
            "['LOG00041.TXT', 'LOG00050.TXT', 'LOG00051.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00056.TXT', 'LOG00057.TXT', 'LOG00058.TXT', 'LOG00059.TXT']\n",
            "21/11/14,23:49:28,000,000,1,0000,0,0,0,00c3.13v;\n",
            "21/11/14,23:49:29,000,000,3,0000,0,0,0,00c3.91v;\n",
            "Clinical M2 (Nonin, Satish) 2019\n",
            "Bhagya success!\n",
            " looking up short_path uct Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Sushma/Sushma\n",
            "Baby ofSushma\n",
            "------ Folder 19 of 63: Baby of Sushma\n",
            "free mem start: 4.5G\n",
            "['12log23.csv']\n",
            "12/6/2019 , 21:23:14, 163, 255, 127, 0\n",
            "12/6/2019 , 21:23:18, 129, 173, 95, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Sushma success!\n",
            " looking up short_path tion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Aruna\n",
            "Baby ofAruna\n",
            "------ Folder 20 of 63: Baby of Aruna\n",
            "free mem start: 4.6G\n",
            "['30log2.csv']\n",
            "30/4/2019 , 16:29:54, 227, 255, 127, 0\n",
            "30/4/2019 , 16:29:58, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Aruna success!\n",
            " looking up short_path ct Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Anitha_/Anitha\n",
            "Baby ofAnitha (A)\n",
            "------ Folder 21 of 63: Baby of Anitha (A)\n",
            "free mem start: 5.0G\n",
            "['28log.csv', '29log8.csv']\n",
            "28/5/2019 , 16:38:52, 163, 255, 127, 0\n",
            "28/5/2019 , 16:38:56, 171, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Anitha (A) success!\n",
            " looking up short_path ion Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Anusha\n",
            "Baby ofSake Anusha\n",
            "------ Folder 22 of 63: Baby of Sake Anusha\n",
            "free mem start: 5.0G\n",
            "['29log8.csv']\n",
            "29/5/2019 , 22:58:28, 163, 255, 127, 0\n",
            "29/5/2019 , 22:58:32, 133, 155, 98, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Sake Anusha success!\n",
            " looking up short_path  Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Pavithra_placebo\n",
            "Baby ofPavitra\n",
            "------ Folder 23 of 63: Baby of Pavitra\n",
            "free mem start: 4.9G\n",
            "['2log7.csv']\n",
            "2/5/2019 , 18:7:29, 163, 255, 127, 0\n",
            "2/5/2019 , 18:7:33, 163, 255, 127, 0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "Pavitra success!\n",
            "IgnoringPavitra\n",
            " looking up short_path cal Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\n",
            "Baby ofHemabindu 2\n",
            "------ Folder 24 of 63: Baby of Hemabindu 2\n",
            "free mem start: 4.9G\n",
            "['LOG00105.TXT', 'LOG00109.TXT', 'LOG00110.TXT', 'LOG00111.TXT']\n",
            "dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\n",
            "dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\n",
            "Clinical M3-Intervention (Nonin) 2019\n",
            "Hemabindu 2 success!\n",
            " looking up short_path n/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 1/BO Tadamarri twin 1 Raw data\n",
            "Baby ofTadimarri Swathi Twin 1\n",
            "------ Folder 25 of 63: Baby of Tadimarri Swathi Twin 1\n",
            "free mem start: 4.7G\n",
            "['LOG00052.TXT', 'LOG00053.TXT', 'LOG00054.TXT', 'LOG00055.TXT', 'LOG00056.TXT', 'LOG00090.TXT']\n",
            "dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\n",
            "dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\n",
            "Clinical M3-Intervention (Nonin) 2019\n",
            "Tadimarri Swathi Twin 1 success!\n",
            " looking up short_path oduct Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Shwetha 2\n",
            "Baby ofShwetha 2\n",
            "------ Folder 26 of 63: Baby of Shwetha 2\n",
            "free mem start: 4.4G\n",
            "['LOG00117.TXT', 'LOG00118.TXT', 'LOG00119.TXT', 'LOG00120.TXT', 'LOG00479.TXT', 'LOG00480.TXT', 'LOG00481.TXT', 'LOG00482.TXT', 'LOG00483.TXT']\n",
            "dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\n",
            "dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\n",
            "Clinical M3-Intervention (Nonin) 2019\n",
            "Shwetha 2 success!\n",
            " looking up short_path /Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Anitha\n",
            "Baby ofAnitha (B)\n",
            "------ Folder 27 of 63: Baby of Anitha (B)\n",
            "free mem start: 3.8G\n",
            "['LOG00045.TXT', 'LOG00046.TXT', 'LOG00047.TXT', 'LOG00048.TXT']\n",
            "dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\n",
            "dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\n",
            "Clinical M3-Placebo (Nonin) 2019\n",
            "Anitha (B) success!\n",
            " looking up short_path uct Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Ayesha Banu\n",
            "Baby ofAyesha Banu\n",
            "------ Folder 28 of 63: Baby of Ayesha Banu\n",
            "free mem start: 3.0G\n",
            "['LOG00121.TXT', 'LOG00122.TXT']\n",
            "dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\n",
            "dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\n",
            "Clinical M3-Intervention (Nonin) 2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nniyp_1baQUg"
      },
      "id": "Nniyp_1baQUg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4fmuhFuf5k"
      },
      "source": [
        "# DRAFT - New Section"
      ],
      "id": "5E4fmuhFuf5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdo3Bol12w2"
      },
      "source": [
        "## ** Not Used Code**"
      ],
      "id": "Ntdo3Bol12w2"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #fname = \"Report.pdf\"\n",
        "# with PdfPages(fname) as pdf:\n",
        "#   print(\"This is a test of the print function\")\n",
        "#   pdf.savefig()"
      ],
      "metadata": {
        "id": "0EU2cARS1Lsy"
      },
      "id": "0EU2cARS1Lsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# usage_pv_data_table = pd.pivot_table(data_table, index =['Data Date',\"Settings Index\"],\n",
        "#                          aggfunc = 'count')\n",
        "\n",
        "# print(usage_pv_data_table)\n",
        "# usage_pv_data_table.to_csv('Usage_pv_data_table.csv',index=True)\n",
        "# usage_pv_data_table.to_excel(\"Usage_pv_data_table.xlsx\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJ1x3Bq8bbc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pd.reset_option(\"all\")\n",
        "#df = stimulation_results_table_with_all_thresholds\n",
        "#print(df)\n",
        "#pivot = pd.pivot_table(stimulation_results_table_with_all_thresholds,\n",
        "                       #values=[\"Status\"],\n",
        "#                       index=['Status'])\n",
        "                       #aggfunc={'Status': np.count,\n",
        "                       # 'HR': [min, max, np.mean]})\n",
        "\n",
        "#df = df.Status.value_counts()\n",
        "#print(pivot)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "# pd.set_option(\"precision\", 4)\n",
        "\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#print(len (stimulation_results_table_with_all_thresholds))\n",
        "#filtered_results_table_all = df[(df[\"Status\"]==129) | (df[\"Status\"]==131)]\n",
        "#print(len (filtered_results_table_all))\n",
        "\n",
        "#data_table = filtered_results_table_all\n",
        "\n",
        "# pivot = pd.pivot_table(data_table,\n",
        "#                        values=['SPO2','HR'],\n",
        "#                        index=['Data Date'],\n",
        "#                        aggfunc={'SPO2': np.mean,\n",
        "#                         'HR': [min, max, np.mean]})\n",
        "\n",
        "#print(pivot)\n",
        "#filtered_results_table_all.to_csv(\"Filtered_Results_Table_All.csv\")\n",
        "\n",
        "# 129    91112\n",
        "# 153    49477\n",
        "# 131    32220\n"
      ],
      "id": "WYJ1x3Bq8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBwS6cI9JH6"
      },
      "source": [
        "\n",
        "Want\n",
        "- Date\n",
        "- Setting Index\n",
        "-\n",
        "\n"
      ],
      "id": "qlBwS6cI9JH6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # !sudo apt-get install wkhtmltopdf\n",
        "# # !yum install wkhtmltopdf\n",
        "# !apt-get install wkhtmltopdf\n",
        "# import pandas as pd\n",
        "# df_apnea_summary_table.to_html('HTMLTest.html')\n",
        "\n",
        "# import pdfkit\n",
        "\n",
        "# pdfkit.from_url('HTMLTest.html', 'HTMLTest.pdf')"
      ],
      "metadata": {
        "id": "k08O7_OMVpRX"
      },
      "id": "k08O7_OMVpRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Create a pandas dataframe with demo data:\n",
        "#!pip install -e git+https://github.com/mindee/doctr.git#egg=python-doctr[torch]\n",
        "#!pip install weasyprint\n",
        "!pip install django-weasyprint\n",
        "import pandas as pd\n",
        "demodata_csv = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
        "df = pd.read_csv(demodata_csv)\n",
        "\n",
        "def dfToPDF (df):\n",
        "  # Pretty print the dataframe as an html table to a file\n",
        "  intermediate_html = '/tmp/intermediate.html'\n",
        "  to_html_pretty(df,intermediate_html,'Iris Data')\n",
        "  # if you do not want pretty printing, just use pandas:\n",
        "  # df.to_html(intermediate_html)\n",
        "\n",
        "  # Convert the html file to a pdf file using weasyprint\n",
        "  import weasyprint\n",
        "  out_pdf= '/tmp/demo.pdf'\n",
        "  weasyprint.HTML(intermediate_html).write_pdf(out_pdf)\n",
        "\n",
        "  # This is the table pretty printer used above:\n",
        "\n",
        "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
        "    '''\n",
        "    Write an entire dataframe to an HTML file\n",
        "    with nice formatting.\n",
        "    Thanks to @stackoverflowuser2010 for the\n",
        "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
        "    '''\n",
        "    ht = ''\n",
        "    if title != '':\n",
        "        ht += '<h2> %s </h2>\\n' % title\n",
        "    ht += df.to_html(classes='wide', escape=False)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)\n",
        "\n",
        "HTML_TEMPLATE1 = '''\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "  h2 {\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "  }\n",
        "  table {\n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "  }\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "    font-size: 90%;\n",
        "  }\n",
        "  table tbody tr:hover {\n",
        "    background-color: #dddddd;\n",
        "  }\n",
        "  .wide {\n",
        "    width: 90%;\n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "'''\n",
        "\n",
        "HTML_TEMPLATE2 = '''\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "_4nxBzcnuBex"
      },
      "id": "_4nxBzcnuBex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # PRINT TABLES & DATA\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# #https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
        "# #df_apnea_summary_table.plot()\n",
        "# #dfToPDF (df)\n",
        "# # fig = convertDataframeToFigure (apnea_summary_table)\n",
        "# # pdf = PdfPages(\"foo.pdf\")\n",
        "# # pdf.savefig(fig, bbox_inches='tight')\n",
        "# # pdf.close()\n",
        "# # !pip install -c conda-forge python-pdfkit\n",
        "# !pip3 install wkhtmltopdf\n",
        "# !pip3 install pdfkit\n",
        "\n",
        "# import pandas as pd\n",
        "# import pdfkit as pdf\n",
        "# import sqlite3\n",
        "\n",
        "# # con=sqlite3.connect(\"baza.db\")\n",
        "\n",
        "# # df=pd.read_sql_query(\"select * from dobit\", con)\n",
        "# #df_apnea_summary_table.datetime = pd.to_datetime(apnea_summary_table.datetime)\n",
        "# display(df_apnea_summary_table)\n",
        "\n",
        "# df_apnea_summary_table.to_html('apnea_summary_table.html')\n",
        "# nazivFajla='test.pdf'\n",
        "# config = pdf.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "# pdf.from_url('apnea_summary_table.html', nazivFajla, configuration=config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kb94aQAehXxh"
      },
      "id": "Kb94aQAehXxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF  Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "os.chdir(startpath)\n",
        "file_name = '12log5 - made from mona xls file.csv'\n",
        "file_name = 'Book2.csv'\n",
        "df = pd.read_csv(file_name, header=None)"
      ],
      "metadata": {
        "id": "Qmiv2ryWUynD"
      },
      "id": "Qmiv2ryWUynD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "3FuNu9FnVX5F"
      },
      "id": "3FuNu9FnVX5F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTpOGQud6Max",
        "7VpeZHhf7O2V",
        "T3dPG9_2xoX3",
        "c9pqOw4FnVYA",
        "Ff704C-MwEsw",
        "4C39qoDxEcnt",
        "vFvsiREGpJ-8",
        "1uadoNfrjZUt",
        "bHJA2jljjdc-",
        "eoiLSOJ3jfmj",
        "kPbeaF7WOonR",
        "Y7x2w8JT2a_D",
        "qINEVzl52lDl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}