{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulbempu/ApneBoot-Clinical-Data-Analysis/blob/main/230301%20-%20AB%20Clinical%20Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-07-23 - I updated it so it loads logs and creates df_s and df_d faster. Also includes Log Source File. Works for Zug, need to check for nonin. \n",
        "Actual and Preset are slightly different because:\n",
        "- Preset mode number shows up at the start of the apnea, Stim shows at start of stim +1 (instead of 5s it looks like 6 sec+1. This may be a rounding issue. Would be nice if they were on the same line but ok. \n",
        "- This rounding issue may also cause different apnea stimulation lengths by a second or two.\n",
        "\n",
        "\n",
        "22-09-03 - \n",
        "- Added code to convert table to pdf\n",
        "\n",
        "22-09-10 -\n",
        "- Fix Smoothing Issue\n",
        "- Add Thresholds \n",
        "\n",
        "22-19-18\n",
        "Todo:\n",
        "- X make individual plots ouput to pdf\n",
        "- X - Good Enough - make summary table cleaner\n",
        "  - reduce number of columns\n",
        "  - increase overall font size\n",
        "- X test with custom thresholds\n",
        "- test and fix for nonin\n",
        "- combine relevent pdfs into a report.\n",
        "- test with Clinical Data\n",
        "\n",
        "23-03-01\n",
        "- want table with name, total time monitored, total time below X condition calculated), total stimulations, total stimulation time, total time under Y condition, total errorenous data. \n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "COmxc45t43_s"
      },
      "id": "COmxc45t43_s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2P7Ld8v0Zf"
      },
      "source": [
        "## **Initialize**"
      ],
      "id": "VY2P7Ld8v0Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Folder Name"
      ],
      "metadata": {
        "id": "s14DGNWX59Me"
      },
      "id": "s14DGNWX59Me"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Find Folders"
      ],
      "metadata": {
        "id": "KR-D_OFUQ4mK"
      },
      "id": "KR-D_OFUQ4mK"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "outputId": "e5fe160c-c0fb-4ee2-a2e8-a7462486541d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n432-4cQ4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "Imports done\n",
            "time: 2.7 ms (started: 2023-03-14 13:10:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import fileinput\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "import linecache\n",
        "from pathlib import Path\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "print (\"Imports done\")"
      ],
      "id": "6n432-4cQ4mR"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "outputId": "ba82fce4-4bbb-485f-a14d-6b2390b1b72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-ikFo4Q4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 35.3 s (started: 2023-03-14 13:10:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "aF-ikFo4Q4mR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Folders List"
      ],
      "metadata": {
        "id": "wu1Ny53mRFbR"
      },
      "id": "wu1Ny53mRFbR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "def list_folders(startpath):\n",
        "    list_path = []\n",
        "    list_folder = []\n",
        "    log = \"log\"\n",
        "    LOG = \"LOG\"\n",
        "    is_data_dir = 0;\n",
        "    previous_name_path = \"\"\n",
        "    for root, subdirs, files in os.walk(startpath):\n",
        "        is_data_dir = 0\n",
        "        for filename in files:\n",
        "            current_name_path = os.path.join(root)\n",
        "            if ((log in filename) | (LOG in filename)) & (previous_name_path != current_name_path):\n",
        "                full_path = os.path.join(root,filename)\n",
        "                list_folder.insert (0, os.path.basename (current_name_path))\n",
        "                list_path.insert(0, root)\n",
        "                previous_name_path = current_name_path\n",
        "\n",
        "    return list_path, list_folder\n"
      ],
      "metadata": {
        "id": "z6m2mfEt8Smu",
        "outputId": "1326e5c7-4ac9-49d4-f1ac-e1577aadd5e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z6m2mfEt8Smu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.71 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Initialize Folders"
      ],
      "metadata": {
        "id": "PTpOGQud6Max"
      },
      "id": "PTpOGQud6Max"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQuN0Iql7AUK"
      },
      "source": [
        "## **Convert Files to Data Frames**"
      ],
      "id": "LQuN0Iql7AUK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers for Different Logger Versions"
      ],
      "metadata": {
        "id": "7VpeZHhf7O2V"
      },
      "id": "7VpeZHhf7O2V"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "header = \"\"\n",
        "settings_header = \"\" \n",
        "AB_Model = \"default_string\"\n",
        "number_of_commas = 0\n",
        "\n",
        "\n",
        "def decideDataLoggerVersion (df):\n",
        "  # Read the third line's header and decide which data logger version is used\n",
        "  # Assumes that the third line is unique for each data logger version\n",
        "  # I need to check with Sourabh if the third line correlates with versions for the St. John's studies.\n",
        "  global header\n",
        "  global settings_header\n",
        "  global AB_Model\n",
        "  global number_of_commas\n",
        "  \n",
        "  raw_logfile_data_table_headers = [\"default\"]\n",
        "  settings_table_headers = [\"\"]\n",
        "  data_table_headers = [\"\"]\n",
        "  settings_columns_rename_dict = [\"\"]\n",
        "  settings_columns_to_drop = [\"\"]\n",
        "  version = \"unknown data code version\"\n",
        "\n",
        "  ZUG_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,PI,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Battery voltage;\"\n",
        "  NONIN_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\"\n",
        "  CLINICAL_SETTINGS_HEADER_INTERVENTION = \"dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\"\n",
        "  CLINICAL_SETTINGS_HEADER_PLACEBO = \"dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\"\n",
        "\n",
        "  settings_header = df.iat[0,0]\n",
        "  header = df.iat[2,0]\n",
        "  number_of_commas = header.count (',')\n",
        "  print (settings_header)\n",
        "  print (header)\n",
        "\n",
        "  if header == ZUG_DATA_HEADER:\n",
        "    version = \"ZUG Circa April 2022\"\n",
        "    # print (\"Detected Zug\")\n",
        "  elif (header == NONIN_DATA_HEADER):\n",
        "      if (settings_header == CLINICAL_SETTINGS_HEADER_INTERVENTION):\n",
        "          version = \"Clinical M3-Intervention (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Intervention\"\n",
        "      elif (settings_header == CLINICAL_SETTINGS_HEADER_PLACEBO):\n",
        "          version = \"Clinical M3-Placebo (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Placebo\"\n",
        "      else:\n",
        "          version = \"NONIN Circa April 2022\"\n",
        "    # print (\"Detected Nonin\")\n",
        "  elif number_of_commas == 5:\n",
        "      version = \"Clinical M1 (Nonin, Tuhin) 2019\"\n",
        "      AB_Model = \"M1\"\n",
        "  elif number_of_commas == 9:\n",
        "      version = \"Clinical M2 (Nonin, Satish) 2019\"\n",
        "      AB_Model = \"M2\"\n",
        "  else:\n",
        "    print (\"Not able to Detect Nonin Nor Zug\")\n",
        "    AB_Model = \"Unable to detect AB Model\"\n",
        "  \n",
        "  print (version)\n",
        "\n",
        "  if version == \"ZUG Circa April 2022\":\n",
        "    AB_Model = \"ZUG Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "            \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "                \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",   \n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Data Date-Time\": 'datetime64[ns]',\n",
        "                \"Data Date\": 'datetime64[ns]',\n",
        "                \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "                \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float\n",
        "                #,\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Settings Date-Time\": str,\n",
        "                \"Settings Date\": str,\n",
        "                'Settings Time':str,\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str}\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"PI\":\"HR Threshold\",\n",
        "            \"Status\":\"AND/OR\",\n",
        "            \"Pulse-ox mode\":\"Duration\",\n",
        "            \"Threshold Met\":\"Stimulator Intensity\",\n",
        "            \"Stimulator Error\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    \n",
        "    settings_columns_to_drop = [\"Stimulator ON/OFF\",\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\"]\n",
        "\n",
        "  if version == \"NONIN Circa April 2022\":\n",
        "    AB_Model = \"NONIN Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"Status\":\"HR Threshold\",\n",
        "            \"Pulse-ox mode\":\"AND/OR\",\n",
        "            \"Threshold Met\":\"Duration\",\n",
        "            \"Stimulator Error\":\"Stimulator Intensity\",\n",
        "            \"Stimulator ON/OFF\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "  if version == \"Clinical M1 (Nonin, Tuhin) 2019\":\n",
        "\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"Status\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [    \n",
        "                    \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",        \n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "  if version == \"Clinical M2 (Nonin, Satish) 2019\":\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Status\",\n",
        "            \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Unused Column 4\",\n",
        "             # <-- need to double check which column is stim off/on\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [            \n",
        "        \"HR\",\t\"SPO2\",\t\"Status\",\"Stimulator ON/OFF\",\n",
        "        \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Unused Column 4\",\n",
        "            ]\n",
        "\n",
        "################ M3 ###########\n",
        "  if ((version == \"Clinical M3-Intervention (Nonin) 2019\") | (version == \"Clinical M3-Placebo (Nonin) 2019\")):\n",
        "  \n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    ## Settings rename dictionary is different \n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Intervention or Placebo\", \n",
        "            \"HR\" : \"Stimulator Intensity\",\n",
        "            \"Status\":\"Alarm intensity\",\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "\n",
        "  return raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict"
      ],
      "metadata": {
        "id": "-OMUDW4FZpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5fcbfd-d8c6-475e-d4c8-8afc297d7e82"
      },
      "id": "-OMUDW4FZpEd",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.5 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile & Split Log Files to df_d and df_s"
      ],
      "metadata": {
        "id": "kns3IrBcDkdb"
      },
      "id": "kns3IrBcDkdb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Reference here: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
        "file_list = []\n",
        "\n",
        "def compileLogFiles (path):\n",
        "  global file_list\n",
        "#   print (path)\n",
        "  os.chdir(path)\n",
        "  file_list = sorted(glob.glob(\"*LOG*.csv\")) + sorted(glob.glob(\"*log*.csv\")) + sorted(glob.glob(\"*LOG*.txt\")) + sorted(glob.glob(\"*log*.txt\")) + sorted(glob.glob(\"*LOG*.TXT\")) + sorted(glob.glob(\"*log*.TXT\"))\n",
        "              # in 2019 clinical, some files are log and some are LOG\n",
        "#   file_list = sorted(glob.glob(\"*\"))\n",
        "  number_of_files = len(file_list)\n",
        "#   print(\"Number of Files:\" , len(file_list))\n",
        "  print (file_list)\n",
        "  li = []\n",
        "\n",
        "  for file_name in file_list:\n",
        "    # This could work faster potentially, but then the data logger identifier code for finding the zug/nonin code string has to be changed\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n', names=list(range(12)))\n",
        "    \n",
        "    print (\"about to work on: \"+file_name)\n",
        "    # df = pd.read_csv(file_name, header=None)\n",
        "    df = pd.read_csv(file_name, header=None, sep='\\0')\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n')\n",
        "    # df = pd.read_csv(file_name, header=None, sep=',')\n",
        "    df['Source File'] = file_name\n",
        "    li.append (df)\n",
        "  \n",
        "  frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "_MMQAV31zaJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bce7433-1194-40e0-a4ec-bf6da77f29c2"
      },
      "id": "_MMQAV31zaJk",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.49 ms (started: 2023-03-14 13:49:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def splitToDataAndSettingsDF (df_LOGs):\n",
        "  \n",
        "  raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict = decideDataLoggerVersion (df_LOGs)    \n",
        "\n",
        "  df_raw = df_LOGs[0].str.split(',', expand=True)\n",
        "  #display (df_raw)\n",
        "   \n",
        "  df_raw.columns = raw_logfile_data_table_headers\n",
        "  df_raw[\"Source File\"] = df_LOGs [\"Source File\"]\n",
        "\n",
        "  # Extract Settings\n",
        "  df_raw_shift = df_raw.shift(periods=-1)\n",
        "  df_s = df_raw_shift[(df_raw.iloc[:,2]==\"Preset mode\") | (df_raw.iloc[:,2]==\"Intervention\") | (df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  # For the clinical data - just use the rows with a new source file to keep the time/date and file. \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == 'M2')):\n",
        "    df_s = df_raw.drop_duplicates(subset=[\"Source File\"], keep='first')\n",
        "\n",
        "\n",
        "  # Delete settings and settings headers\n",
        "  df_raw_shift = df_raw.shift(periods=1)                                        #shift down one row as a way to find one line below the settings header\n",
        "  rows_below_header = df_raw[(df_raw_shift.iloc[:,2]==\"Preset mode\") |(df_raw_shift.iloc[:,2]==\"Intervention\")|(df_raw_shift.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop(rows_below_header.index)                                 #Drop all the setttings data lines \n",
        "  rows_with_header = df_raw[(df_raw.iloc[:,2]==\"Preset mode\") |(df_raw.iloc[:,2]==\"Intervention\")|(df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the settings headers\n",
        "  rows_with_header = df_raw[df_raw.iloc[:,2]==\"SPO2\"]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the DATA headers\n",
        "  \n",
        "  # Format Settings Files\n",
        "  df_s.drop(settings_columns_to_drop, axis=1, inplace=True)                     # Drop extra columns\n",
        "  df_s.rename(columns=settings_columns_rename_dict, inplace=True)\n",
        "  if 'Alarm Intensity' in df_s.columns:\n",
        "    df_s['Alarm intensity'].apply(lambda v: v.rstrip(';'))\n",
        "  \n",
        "  #What's left of df_raw is now df_d for data\n",
        "  df_d = df_raw\n",
        "  if (AB_Model == \"NONIN Circa April 2022\"):\n",
        "    df_d.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "    #df_s.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "\n",
        "  # In the clinical, Tuhin put P for the devices that were placebo and would have stimulated but actually didn't.\n",
        "  # Replace those with the number 1\n",
        "  df_d[\"Stimulator ON/OFF\"].mask(df_d[\"Stimulator ON/OFF\"] == \" P\", 1, inplace= True)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  if (AB_Model == \"M1\"):\n",
        "    format_day = '%d-%MM-%yyyy'\n",
        "    format_time = '%H:%m:%s'\n",
        "  else:\n",
        "    format_day = '%d/%m/%y'\n",
        "    format_time = '%H:%M:%S'\n",
        "    \n",
        "\n",
        "#   if (AB_Model == \"M1\"):\n",
        "#       try:\n",
        "#         display (df_s)\n",
        "#         display (df_d)\n",
        "#         # df_s.head()\n",
        "#         # df_d.head()\n",
        "        \n",
        "#         # print (df_d.columns)\n",
        "#         # print (\"df_s1 \" + df_s[\"Settings Date\"][3] + df_s[\"Settings Time\"][3])\n",
        "#         df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"df_d1 \" + df_d[\"Data Date\"][3] + df_d[\"Data Time\"][3])\n",
        "#         df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))   \n",
        "#         print (\"matched 1!\")\n",
        "#       except Exception as e:\n",
        "#           print (e)\n",
        "#           print (\"try alternate date format:\")\n",
        "#           display (df_s)\n",
        "#         #   print (df_d.columns)\n",
        "#           try:\n",
        "#             # df_s.drop (\"Settings Date-Time\")\n",
        "#             # df_d.drop (\"Data Date-Time\")\n",
        "#             # df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             # df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))  \n",
        "#             print (\"matched 2!\")\n",
        "#           except Exception as e2:\n",
        "#             print (e2)\n",
        "#             print (\"no more date formats to try!\")       \n",
        " \n",
        "\n",
        "#   else:\n",
        "#     df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#     df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#   print (\"inserting with \"+format_day + \" \" + format_time)\n",
        "#   display (df_s)\n",
        "\n",
        "#   print (\"df_s insert done, here's what it looks like\")\n",
        "#   display (df_s)\n",
        "#   display (df_d)\n",
        "\n",
        "#   print (\"df_d coerce done and now df_d looks like:\")\n",
        "#   display (df_d)\n",
        "#   print (\"inserts done\")\n",
        "\n",
        "# MARCH 9, 2023 - These two lines below work (infer_datetime_format=True needs to be checked bc some columns may have multiple date Time formats?) \n",
        "# but it's still slow so I'm commenting them out for now and replacing them with the two below\n",
        "\n",
        "#   df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "#   df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "\n",
        "  df_s.insert(loc=0, column=\"Settings Date-Time\", value=df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"])\n",
        "  df_d.insert(loc=0, column=\"Data Date-Time\", value=df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"])\n",
        "\n",
        "\n",
        "\n",
        "  if ((AB_Model == \"M1\") | (AB_Model == \"M2\") | (AB_Model == \"M3-Placebo\") | (AB_Model == \"M3-Intervention\")):\n",
        "      df_s.insert(loc = 3, column=\"Preset mode\", value = 1)\n",
        "      df_s.insert(loc = 4, column=\"SPO2 Threshold\", value = 0)\n",
        "      df_s.insert(loc = 5, column=\"HR Threshold\", value = 0)\n",
        "      df_s.insert(loc = 6, column=\"AND/OR\", value = 0)\n",
        "      df_s.insert(loc = 7, column=\"Duration\", value = 0)\n",
        "      if ((AB_Model == \"M1\") | (AB_Model == \"M2\")):\n",
        "        df_s.insert(loc = 8, column=\"Stimulator Intensity\", value = 0)\n",
        "        df_s.insert(loc = 9, column=\"Alarm intensity\", value = 0)\n",
        "\n",
        "  #Cleanup NaNs\n",
        "  df_d = df_d.fillna(0)\n",
        "  df_s = df_s.fillna(0)\n",
        "\n",
        "  #Convert to best datatypes\n",
        "\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format='%d/%m/%y')\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format='%H:%M:%S')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format='%d/%m/%y')\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format='%H:%M:%S')#.dt.time\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format=format_day)\n",
        "#   print (\"Settings Date Updated done\")\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Settings Time Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format=format_day)\n",
        "#   print (\"Data Date Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Data Time Updated done\")\n",
        "  \n",
        "## For Clinical Analysis I am not going to do these, since they are already done above when combined. \n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"])\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"], errors = 'coerce')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"])\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"], errors = 'coerce')#.dt.time\n",
        "  df_s.drop(columns = \"Settings Date\", axis = 1, inplace=True)\n",
        "  df_s.drop(columns = \"Settings Time\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Date\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Time\", axis = 1, inplace=True)\n",
        "  df_s=df_s.astype(settings_convert_dict, errors='raise')\n",
        "  df_d=df_d.astype(data_convert_dict, errors='raise')\n",
        "\n",
        "  #df_d = ResolveMidnightDateIssue (df_d) \n",
        "\n",
        "#  df_d[\"Data Date-Time\"]=pd.to_datetime(df_d[\"Data Date-Time\"],format='%d/%m/%y %H:%M:%S')\n",
        "\n",
        "  # For Settings Table delete the confusing default numbers left in place when \"preset\" condition is on.\n",
        "# \n",
        "  df_s = DeleteThresholdsForRowsUsingPresetConditions(df_s)\n",
        "  df_s, df_d = addSettingsIndex (df_s,df_d)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "_jiazNDlz1Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c624279-78cb-4cec-de89-3c8a2748d3d7"
      },
      "id": "_jiazNDlz1Dp",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.3 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XH-EgNxkPi",
        "outputId": "9bb39bc3-8c8a-40ac-f0eb-a7cbe2bc2ba1"
      },
      "id": "T9XH-EgNxkPi",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 20.3 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It was observed with Zug that for the first ~30 seconds after midnight, the date does not change. This needs to be fixed or \"smoothed\" with the code below.\n",
        "#import calendar\n",
        "\n",
        "#### This function is not finished.\n",
        "def ResolveMidnightDateIssue (df_above):\n",
        "  print (\"in the smooth\")\n",
        "  df_diff = pd.DataFrame ()\n",
        "  df_below = pd.DataFrame ()\n",
        "\n",
        "  df_below[\"Data Date-Time\"] = df_above[\"Data Date-Time\"].shift (periods=1, fill_value=0)\n",
        "  #df_below[\"Data Date\"] = df_above[\"Data Date\"].shift (periods=1, fill_value=0)\n",
        "  df_below [\"Date Diff\"] = df_above[\"Data Date-Time\"] < df_below[\"Data Date-Time\"]\n",
        "  df_below [\"Date Diff Num\"] = (df_above[\"Data Date-Time\"] - df_below[\"Data Date-Time\"]).dt.total_seconds()\n",
        "  print (df_below [\"Date Diff Num\"].dtype)\n",
        "  \n",
        "\n",
        "  # display(df_above)\n",
        "  # display(df_below)\n",
        "  # display (df_below[df_below[\"Date Diff\"]==1])\n",
        "  df_midnight_bounds = df_below[df_below[\"Date Diff Num\"].abs()>1000]\n",
        "  #display (df_midnight_bounds)\n",
        "  # for i in df_midnight_bounds.index:\n",
        "  #   print (i)\n",
        "\n",
        "\n",
        "\n",
        "  #display (df_below[df_below[\"Date Diff Num\"]!=1])\n",
        "  \n",
        "  print (\"Sum is: \" + df_below[\"Date Diff\"].astype(int).sum().astype(str))\n",
        "  \n",
        "  return df_above\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2noyZAXZNuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827d826b-8456-4cc3-e34a-f54aa594f0ee"
      },
      "id": "J2noyZAXZNuk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.05 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def addSettingsIndex (df_s,df_d):\n",
        "  #df_s[\"Settings Index\"] = np.arange(len(df_s))\n",
        "  df_s.insert(loc=0, column=\"Settings Index\", value=np.arange(len(df_s))+1)\n",
        "  df_d = pd.merge_asof (df_d,df_s[\"Settings Index\"],left_index=True, right_index=True)\n",
        "  SettingsIndexCol = df_d.pop('Settings Index')\n",
        "  df_d.insert(0, 'Settings Index', SettingsIndexCol)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "SeN4pRpcmoTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70172ed3-9c6b-4253-d38b-8c01166ab4ae"
      },
      "id": "SeN4pRpcmoTt",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.22 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c218dd41-224b-4fa5-f13a-f976ae1f7ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.44 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def DeleteThresholdsForRowsUsingPresetConditions (settings_table):\n",
        "    # display(settings_table)\n",
        "    for ind in settings_table.index:\n",
        "        if settings_table[\"Preset mode\"][ind] == 1:\n",
        "            settings_table[\"SPO2 Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"HR Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"AND/OR\"][ind] = np.NaN\n",
        "            settings_table[\"Duration\"][ind] = np.NaN\n",
        "                       #Preset mode\tSPO2 Threshold\tHR Threshold\tAND/OR\tDuration\n",
        "    return settings_table\n"
      ],
      "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dPG9_2xoX3"
      },
      "source": [
        "## **Analyze Thresholds**"
      ],
      "id": "T3dPG9_2xoX3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Only Valid Data\n",
        "This filters data based on device status. "
      ],
      "metadata": {
        "id": "YxecqEFREEhV"
      },
      "id": "YxecqEFREEhV"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6a9eeb-71bd-4b01-ca14-028874b5ace9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.19 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def GetIsValidColumn (df):\n",
        "    is_valid = pd.DataFrame ()\n",
        "    is_valid [\"valid_vitals\"] = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff) & (df[\"HR\"] !=255) & (df[\"SPO2\"] !=127))\n",
        "    # print (\"Num IsValid Vitals True:\")\n",
        "    # print (is_valid[\"valid_vitals\"].sum())\n",
        "    # print (is_valid [\"valid_vitals\"])\n",
        "    # is_valid['valid_vitals'].value_counts()\n",
        "    # print (\"num valid vitals: \" + is_valid [is_valid[\"valid_vitals\"]==True].count)\n",
        "\n",
        "    # Determine if status scale is 0-6 or 0-255...\n",
        "    max_status = df[\"Status\"].max()\n",
        "    print (\"about to check valid_status\")\n",
        "    display (df)\n",
        "    # if (AB_Model == \"M1\"):\n",
        "    if (max_status < 7):\n",
        "        print (\"eval status for 0-6 status\")\n",
        "        is_valid [\"valid_status\"] = (df['Status'] == 0);\n",
        "    elif (max_status >= 7):\n",
        "        print (\"eval status for 0-255 status\")\n",
        "        is_valid [\"valid_status\"] = ((df['Status'] == 129) | (df['Status'] == 131));  \n",
        "    \n",
        "    # print (\"Num IsValid Status True:\")\n",
        "    # print (is_valid[\"valid_status\"].sum())\n",
        "    \n",
        "    is_valid['Is_Valid_Data'] = np.where((is_valid['valid_status'] == True) & (is_valid[\"valid_vitals\"] == True), True, False)\n",
        "    # is_valid [\"Is_Valid_Data\"] = ((is_valid['valid_vitals'] == True) & (is_valid ['valid_status'] == True))\n",
        "    # is_valid['Is_Valid_Data'].value_counts()\n",
        "    # print (\"Num IsValid True:\")\n",
        "    # print (is_valid[\"Is_Valid_Data\"].sum())\n",
        "    return is_valid [\"Is_Valid_Data\"]\n",
        "\n",
        "\n"
      ],
      "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Against Custom Thresholds\n",
        "This function returns what is expected in the custom mode the user selected. It should match with actual stimulations in custom mode."
      ],
      "metadata": {
        "id": "dm2RieFwTAjS"
      },
      "id": "dm2RieFwTAjS"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa48f77-e57e-4b9b-b349-8a8a88c8eeeb",
        "id": "pndZJ_WATAja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.07 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def AnalyzeWithCustomThresholds (df):\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) & (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) | (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_result = (df[\"AND/OR\"]==0)*is_below_threshold_OR + (df[\"AND/OR\"]==1)*is_below_threshold_AND\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= df[\"Duration\"],0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "\n",
        "  df[Duration_Custom] = df_unmasked.mask(df_unmasked <= df[\"Duration\"],0)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "id": "pndZJ_WATAja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze With Preset Thresholds\n",
        "This function is useful to see how the system would have performed if it were operating in preset mode."
      ],
      "metadata": {
        "id": "c9pqOw4FnVYA"
      },
      "id": "c9pqOw4FnVYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "SPO2_threshold_AND_condition = 85\n",
        "HR_threshold_AND_condition = 100\n",
        "SP02_threshold_OR_condition = 75\n",
        "HR_threshold_OR_condition  = 90\n",
        "Preset_Mode_Duration = 5\n",
        "\n",
        "def AnalyzeWithPresetThresholds (df):\n",
        "  \n",
        "    \n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "  # is_below_threshold_result = ((df[\"AND/OR\"]==0))&(is_below_threshold_OR) | ((df[\"AND/OR\"]==1) &is_below_threshold_AND)\n",
        "  is_below_threshold_result = is_below_threshold_OR | is_below_threshold_AND\n",
        "  #print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "#   display (is_below_threshold_result)\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= Preset_Mode_Duration,0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  # print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "\n",
        "  # print (\"Total preset results are: \" + str(is_below_threshold_result.sum()))\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "  df[Duration_Preset] = df_unmasked.mask(df_unmasked <= Preset_Mode_Duration,0)\n",
        "\n",
        "  #print (\"Sum is:\" + str(sum(df[Duration_Preset])))\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "NFGvMndV_NLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a09a7c-8835-4634-b4d0-bf3d245a8633"
      },
      "id": "NFGvMndV_NLH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.4 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Actual Stimulations\n",
        "This function looks at Stim Off/On field and counts the apnea durations (assuming SPO2 & HR are not 0). It does not consider the Preset/Custom settings at all. "
      ],
      "metadata": {
        "id": "Ff704C-MwEsw"
      },
      "id": "Ff704C-MwEsw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Assumes it is being passed df_j\n",
        "def AddNumActualStimulations (df):\n",
        "  \n",
        "#   Valid_Stimulations = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff)*(df[\"HR\"]>Data_Cleanup_HR_LowCutOff)\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  Valid_Stimulations = df[\"Stimulator ON/OFF\"]*is_valid\n",
        "  df[Duration_Actual] = calcDurationsCrossedThreshold(pd.DataFrame(Valid_Stimulations))\n",
        "   \n",
        "  ## New code (22-07-23) - I later realized that with the new apnea duration counter, we don't need to \"Stimulation started column\" as it easily puts the apnea duration time where the stimulation started. \n",
        "  # df[\"Stimulator ON/OFF with Valid SPO2/HR\"] = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]!=0)*(df[\"HR\"]!=0) \n",
        "\n",
        "  # df_previousrow = df.shift(periods=1)\n",
        "  # isStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF with Valid SPO2/HR\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF with Valid SPO2/HR\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0)\n",
        "  #                         )  # This condition was added because there are some odd cases where the stimulator turns when HR/SPO2 are 0...\n",
        "\n",
        "  #This gives 408 rows, but the one above gives 411 rows. There are likely some times then the O2 or HR jumps to zero mid apnea but jumps back up and the stimulator is on the whole time? \n",
        "  # OldisStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0))\n",
        "\n",
        "  #Should be 408 Rows\n",
        "  \n",
        "  # df[\"Stimulation Triggered (Actual Stimulator ON Triggered)\"] = isStimulationStarted\n",
        "  # df[\"Actual - Stimulation Durations (s)\"] = calcDurationsCrossedThreshold(pd.DataFrame(df[\"Stimulator ON/OFF with Valid SPO2/HR\"]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "CI2GKzN15PZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76be1e1c-354c-4a70-ba57-94e45bfd53d2"
      },
      "id": "CI2GKzN15PZJ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.33 ms (started: 2023-03-14 13:11:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Cross Duration\n",
        "This takes an array of \"threshold crossed\" or \"stimulation on\" (0,0,0,1,1,1,1,0..etc) and returns an array with the time in the first place the threshold is cross i.e. (0,0,0,4,0,0,0,0...)"
      ],
      "metadata": {
        "id": "4C39qoDxEcnt"
      },
      "id": "4C39qoDxEcnt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Input: A df with 0s and 1s representing cross thresholds\n",
        "# see this -  https://stackoverflow.com/questions/62615666/how-to-sum-variable-ranges-in-a-pandas-column-to-another-column\n",
        "def calcDurationsCrossedThreshold (df):\n",
        "  \n",
        "  df = df.iloc[::-1]\n",
        "  a = df.iloc[:,0]==0\n",
        "  blocks = a.cumsum()\n",
        "  \n",
        "  m = blocks.duplicated(keep='last')\n",
        "  \n",
        "  df['Sum'] = df.iloc[:,0].groupby(blocks).cumsum().mask(m)\n",
        "  df = df.iloc[::-1]\n",
        "  df_return = df ['Sum'].fillna(0)\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "HIOGli41rAgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c72e7a0-c5dc-4720-e64c-c71afa311ed4"
      },
      "id": "HIOGli41rAgo",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.03 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Summary Tables**"
      ],
      "metadata": {
        "id": "vFvsiREGpJ-8"
      },
      "id": "vFvsiREGpJ-8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportApneaCountBySetting (df,df_s):\n",
        "  table = pd.pivot_table (df, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='sum')\n",
        "#   display (table)\n",
        "  table = table.rename (columns = {Duration_Actual:SumDuration_Actual, Duration_Preset:SumDuration_Preset, Duration_Custom:SumDuration_Preset})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "  \n",
        "\n",
        "  #Count function counts zeros too, so need to replace zeros with NAs for this to work.\n",
        "  df_nan = df.mask(df==0) # This will make all zeros into Nan\n",
        "  table = pd.pivot_table (df_nan, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='count')\n",
        "  \n",
        "  table = table.rename (columns = {Duration_Actual:Count_Actual, Duration_Preset:Count_Preset, Duration_Custom:Count_Custom})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "#   display (df_s)\n",
        "  \n",
        "  if (PRINT_TABLES == True):\n",
        "    df_s.to_excel (folder_name + \" - Summary of Events.xlsx\")\n",
        "    dataframe_to_pdf(df_s, folder_name + \" - Apnea Count By Setting\")\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McI1Xwv81qIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54dd46a3-ef3d-47af-cebc-715b4f332f5d"
      },
      "id": "McI1Xwv81qIh",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.52 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportIndividualActualApneas (df):\n",
        "  table_A = df[df[Duration_Actual]!=0]\n",
        "  table_P = df[df[Duration_Preset]!=0]\n",
        "  table_C = df[df[Duration_Custom]!=0]\n",
        "  table_A_P = df[ (df[\"Preset mode\"]==1 & (df[Duration_Actual]!=df[Duration_Preset]))]\n",
        "  table_A_C = df[ (df[\"Preset mode\"]==0 & (df[Duration_Actual]!=df[Duration_Custom]))]\n",
        "                   \n",
        "  if (PRINT_TABLES == True):\n",
        "    with pd.ExcelWriter(folder_name + \" - Individual Events.xlsx\") as writer:\n",
        "        table_A.to_excel (writer, sheet_name=\"Actual\")\n",
        "        table_P.to_excel (writer, sheet_name=\"Preset\")\n",
        "        table_C.to_excel (writer, sheet_name=\"Custom\")\n",
        "        table_A_P.to_excel (writer, sheet_name=\"Actual-Preset Discrepancy\")\n",
        "        table_A_C.to_excel (writer, sheet_name=\"Actual-Custom Discrepancey\")\n",
        "\n",
        "    dataframe_to_pdf(table_A, folder_name + \" - Individual Events (Actual)\")\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "IbdRSJx_MgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672d318b-8622-497a-da2f-49f26888e43e"
      },
      "id": "IbdRSJx_MgxZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.06 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def convertDataframeToFigure (df):\n",
        "  display (df)\n",
        "  fig, ax =plt.subplots(figsize =(20,20))\n",
        "  #fig, ax =plt.subplots(figsize=(len(df),len(df.columns)))\n",
        "  ax.axis('tight')\n",
        "  ax.axis('off')\n",
        "  the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "  return fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qxv3-8-3lsTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3862924f-5589-4cb7-b8f8-a20dd79f4ade"
      },
      "id": "Qxv3-8-3lsTZ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.26 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ## Print Tables to PDF **\n",
        "This code enables printing tables to pdf."
      ],
      "metadata": {
        "id": "Sb6hldAxxaXX"
      },
      "id": "Sb6hldAxxaXX"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import textwrap as twp\n",
        "\n",
        "# #create column headers with long text and apply textwrap with \\n after defined lenght\n",
        "# columns=[twp.fill('this is a long column header text',25), twp.fill('...and this is an even longer column header text',25)]\n",
        "\n",
        "# https://predictivehacks.com/?all-tips=save-a-pandas-dataframe-as-an-image\n",
        "# pip install dataframe-image\n",
        "# import pandas as pd\n",
        "# import dataframe_image as dfi\n",
        " \n",
        "# dfi.export(df, 'dataframe.png')\n",
        "\n",
        "def _draw_as_table(df, pagesize):\n",
        "    alternating_colors = [['white'] * len(df.columns), ['lightgray'] * len(df.columns)] * len(df)\n",
        "    alternating_colors = alternating_colors[:len(df)]\n",
        "    fig, ax = plt.subplots(figsize=pagesize)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    # df=df.to_string(line_width=5)\n",
        "    # .str.wrap(5)\n",
        "    col_headers=list(df.columns.str.wrap(15)) #df.columns#.map(\"str\")\n",
        "    #display (col_headers)\n",
        "    #print (\"Cols is \" + len(df[0]))\n",
        "    #display (df)\n",
        "    the_table = ax.table(cellText=df.values,\n",
        "                        rowLabels=df.index,\n",
        "                        colLabels=col_headers,\n",
        "                        #colLabels=df.columns,\n",
        "                        rowColours=['lightblue']*len(df),\n",
        "                        colColours=['lightblue']*len(df.columns),\n",
        "                        cellColours=alternating_colors,\n",
        "                        loc='center')\n",
        "    the_table.auto_set_column_width(col=list(range(len(df.columns)))) # Provide integer list of columns to adjust\n",
        "\n",
        "    # the_table.auto_set_font_size(False)\n",
        "    # the_table.set_fontsize(12)\n",
        "    return fig\n",
        "  \n",
        "\n",
        "def dataframe_to_pdf(df, filename, numpages=(1, 1), pagesize=(11, 8.5)):\n",
        "  with PdfPages(filename) as pdf:\n",
        "    # display (df)\n",
        "    # nh, nv = numpages\n",
        "    # rows_per_page = len(df) // nh\n",
        "    # cols_per_page = len(df.columns) // nv\n",
        "\n",
        "    # nh, nv = numpages\n",
        "    rows_per_page = 30\n",
        "    cols_per_page = len(df.columns)\n",
        "    nv = 1\n",
        "    \n",
        "    if len(df) % rows_per_page == 0: \n",
        "      nh = int(len(df) / rows_per_page)\n",
        "    else:\n",
        "      nh = int(len(df) / rows_per_page) +1\n",
        "    \n",
        "    # print ('num cols is ' + str(len(df.columns)))\n",
        "    # print ('num rows is ' + str(len(df)) + \"nv is \" + str(nv))\n",
        "\n",
        "    for i in range(0, nh):\n",
        "        for j in range(0, nv):\n",
        "            # print (\"i is \" + str(i) + \"and j is \" + str(j))\n",
        "            page = df.iloc[(i*rows_per_page):min((i+1)*rows_per_page, len(df)),\n",
        "                           (j*cols_per_page):min((j+1)*cols_per_page, len(df.columns))]\n",
        "            # display (page)\n",
        "            fig = _draw_as_table(page, pagesize)\n",
        "            if nh > 1 or nv > 1:\n",
        "                # Add a part/page number at bottom-center of page\n",
        "                fig.text(0.5, 0.5/pagesize[0],\n",
        "                         \"Part-{}x{}: Page-{}\".format(i+1, j+1, i*nv + j + 1),\n",
        "                         ha='center', fontsize=8)\n",
        "            \n",
        "            pdf.savefig(fig, bbox_inches='tight')\n",
        "            # plt.show ()\n",
        "            plt.close()\n"
      ],
      "metadata": {
        "id": "BQDht-5kNQpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5cc348-3246-4676-8ef3-06ce0fe9d5cc"
      },
      "id": "BQDht-5kNQpD",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 345 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AZp6q5Z8Aq"
      },
      "source": [
        "## **Plots**"
      ],
      "id": "X_AZp6q5Z8Aq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot AB Data"
      ],
      "metadata": {
        "id": "1uadoNfrjZUt"
      },
      "id": "1uadoNfrjZUt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotApneBootData (df,plot_title,x_axis_start,x_axis_end):\n",
        "    #display (df)\n",
        "    \n",
        "    f, (ax, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 1]})\n",
        "\n",
        "    ax2 = df.plot(x=\"Data Date-Time\", y=\"Status\", rot=0,ax=ax2)\n",
        "    \n",
        "    plotSPO2AndHR(df,plot_title,x_axis_start,x_axis_end,ax)\n",
        "       \n",
        "    f.tight_layout()\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xxrNme8yvvkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08cf870-3b94-4a99-c59d-f62177203eb6"
      },
      "id": "xxrNme8yvvkW",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.13 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotSPO2AndHR (df,plot_title,x_axis_start,x_axis_end,ax):\n",
        "  df[\"Stimulator ON/OFF Plot\"] = df[\"Stimulator ON/OFF\"]*20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ax = df.plot(x=\"Data Date-Time\", y=\"SPO2\", \n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                            rot=0,\n",
        "                            #kind='scatter',\n",
        "                            color = 'red',\n",
        "                            label = \"SPO2\",\n",
        "                            linewidth=1, \n",
        "                            #s=2,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df.plot(x=\"Data Date-Time\", y=\"HR\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=True,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'blue',\n",
        "                          label = \"HR\",\n",
        "                          linewidth=1,\n",
        "                          #s=2,\n",
        "                          ax=ax)\n",
        "  \n",
        "  df.plot.line(x=\"Data Date-Time\", y=\"Stimulator ON/OFF Plot\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          linewidth=4,\n",
        "                          alpha=0.2,\n",
        "               \n",
        "                          #fmt ='+',\n",
        "                          color = 'Orange',\n",
        "                          label = \"Stim ON\",\n",
        "                          #s=30,\n",
        "                          ax=ax)\n",
        "                          \n",
        "  df_t = getThresholdTable (df)\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"SPO2 Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkRed',\n",
        "                          label = \"SPO2 Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dashed',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"HR Threshold\", \n",
        "                          #figsize=(20,5),\n",
        "                          #title = current_date,\n",
        "                          #ylim=(-5,150),\n",
        "                          #xlim= (x_axis_start, x_axis_end),\n",
        "                          #grid=1 ,\n",
        "                          #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "                          #rot=1,\n",
        "                          #kind='scatter',\n",
        "                          color = 'DarkBlue',\n",
        "                          label = \"HR Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dotted',\n",
        "                          alpha=0.2,\n",
        "                          #s=2,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  x_offset = (x_axis_end - x_axis_start)/10\n",
        "  df_a = df[(df[Duration_Actual] > 0)]\n",
        "  #df_a[\"Text X Position\"] = df_a[\"Data Date-Time\"][ind] - x_offset\n",
        "  df_a=df_a.reset_index(drop=True)\n",
        "  df_a[\"Arrow Offet\"] = df_a[\"Data Date-Time\"] - x_offset\n",
        "\n",
        "  for ind in df_a.index:\n",
        "    if df_a[\"Arrow Offet\"][ind] <= x_axis_start:\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than \" + str(x_axis_start))\n",
        "      df_a[\"Arrow Offet\"][ind] = df_a[\"Arrow Offet\"][ind] + x_offset*2\n",
        "      print (\"so we replace with: \" + str(df_a[\"Arrow Offet\"][ind]))\n",
        "    #print (ind)\n",
        "    ax.annotate(\"Event For \" + df_a[Duration_Actual][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "            xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "            fontsize = 10, \n",
        "            xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "            arrowprops = dict(facecolor = 'yellow'),\n",
        "            color = 'black',\n",
        "            backgroundcolor='white')\n",
        "    \n",
        "  #df.plot.annotate(df[Duration_Actual].str(), xy=\"Data Date-Time\", y=100, , fontsize = 10, color = 'g')\n",
        "\n",
        "  #### PRINT THresholds\n",
        "  \n",
        "  # ax.plot.line (x=df[\"Data Date-Time\"], y=df_t[\"HR Threshold\"], \n",
        "  #                         #figsize=(20,5),\n",
        "  #                         #title = current_date,\n",
        "  #                         #ylim=(-5,150),\n",
        "  #                         #xlim= (x_axis_start, x_axis_end),\n",
        "  #                         #grid=1 ,\n",
        "  #                         #xticks=pd.date_range(x_axis_start, x_axis_end,24),\n",
        "  #                         #rot=1,\n",
        "  #                         #kind='scatter',\n",
        "  #                         color = 'Orange',\n",
        "  #                         label = \"HR Threshold\",\n",
        "  #                         linewidth=1,\n",
        "  #                         #s=2,\n",
        "  #                         ax=ax\n",
        "  #                         )\n",
        "\n",
        "\n",
        "\n",
        "  ax.grid('on', which='major')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "br-rk3f9_P2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283b0f58-37ad-436f-eb31-69e616bc7906"
      },
      "id": "br-rk3f9_P2G",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.13 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Threshold Table"
      ],
      "metadata": {
        "id": "qYEzi3M-S0K6"
      },
      "id": "qYEzi3M-S0K6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def getThresholdTable (df):\n",
        "  SPO2_threshold_AND_condition = 85\n",
        "  HR_threshold_AND_condition = 100\n",
        "  SP02_threshold_OR_condition = 75\n",
        "  HR_threshold_OR_condition  = 90\n",
        "  Preset_Mode_Duration = 5\n",
        "\n",
        "  df_t = pd.DataFrame()\n",
        "  #df_t = df\n",
        "  # df_t [\"HR Threshold\"] = 60\n",
        "  # df_t [\"SPO2 Threshold\"] = 64\n",
        "  df_t [\"Data Date-Time\"] = df[\"Data Date-Time\"]\n",
        "  df_t [\"HR Threshold\"] = df[\"Preset mode\"]*HR_threshold_OR_condition\n",
        "  df_t [\"SPO2 Threshold\"] = df[\"Preset mode\"]*SP02_threshold_OR_condition\n",
        "  df_t[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]=df[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]\n",
        "  df_t[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]=df[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]\n",
        "\n",
        "  # df_t [\"HR Custom\"] = df[\"HR Threshold\"]\n",
        "  # df[\"SPO2 Threshold\"].notna().astype(int)*df[\"SPO2 Threshold\"]\n",
        "  # display (df_t)\n",
        "\n",
        "  #is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  \n",
        "  #print (\"df_t is: \")\n",
        "  #display (df_t)\n",
        "\n",
        "  return df_t"
      ],
      "metadata": {
        "id": "oDhFqjhBjY20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1d4eef-a26f-42f1-c4cc-1838cdb86982"
      },
      "id": "oDhFqjhBjY20",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.95 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot by Day"
      ],
      "metadata": {
        "id": "bHJA2jljjdc-"
      },
      "id": "bHJA2jljjdc-"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ea3a1SQZLQB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90522779-d992-4667-bf1e-4a30ebf4c8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.89 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_plot=df_j\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "def plotByDay (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    length = len(date_list)\n",
        "\n",
        "    fname = folder_name + ' plot_by_day.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "        for i in range(length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "          \n",
        "          # x axis start and end\n",
        "          x_axis_start = current_date.replace(second = 1)\n",
        "          #print(x_axis_start)\n",
        "          x_axis_end = current_date.replace(hour = 23, minute=59, second = 59)\n",
        "          \n",
        "          \n",
        "          ##### Sept 7 - Not sure if this below has to be commented or fixed\n",
        "          # df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"].astype(str)).dt.time\n",
        "          # #df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"])\n",
        "          df_current_date[\"Data Time\"] = df_current_date[\"Data Time\"].dt.time\n",
        "          df_current_date.set_index('Data Time')\n",
        "          #display(df_current_date.dtypes)\n",
        "          #display (df_current_date)\n",
        "          \n",
        "          plotApneBootData (df_current_date,current_date_64,x_axis_start,x_axis_end)\n",
        "          pdf.savefig()\n",
        "          plt.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "2ea3a1SQZLQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot By Hour"
      ],
      "metadata": {
        "id": "eoiLSOJ3jfmj"
      },
      "id": "eoiLSOJ3jfmj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotByHour (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    df[\"Data Time\"] = pd.to_datetime(df[\"Data Time\"])\n",
        "    df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "    # display(df)\n",
        "    # return\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    date_length = len(date_list)\n",
        "    fname = folder_name + ' plot_by_hour.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "\n",
        "        firstPage = plt.figure(figsize=(11.69,8.27))\n",
        "        firstPage.clf()\n",
        "        txt = 'This is the title page'\n",
        "        firstPage.text(0.5,0.5,txt, transform=firstPage.transFigure, size=24, ha=\"center\")\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(date_length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "      \n",
        "          hour_list = np.unique(df_current_date[\"Data Time-Hour\"])\n",
        "          hour_length = len(hour_list)\n",
        "          #print (hour_list)\n",
        "\n",
        "          for j in range(hour_length):\n",
        "              current_hour_64 = hour_list[j]\n",
        "              #current_date=pd.to_datetime(current_date_64)\n",
        "              df_current_hour = df_current_date[(df_current_date[\"Data Time-Hour\"]==current_hour_64)]\n",
        "              x_start = current_date + pd.offsets.Hour(current_hour_64)\n",
        "              x_end = current_date + pd.offsets.Hour(current_hour_64+1)\n",
        "              df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              \n",
        "              # x_start = df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              title = str (current_date) + ' ' + str(x_start)\n",
        "              plotApneBootData (df_current_hour,x_start,x_start,x_end)\n",
        "              # plotApneBootData (df_current_hour,current_date,current_hour_64,current_hour_64+1)\n",
        "              pdf.savefig()\n",
        "              plt.close()\n"
      ],
      "metadata": {
        "id": "kNpgyduy7ulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d80c773-3f1b-4683-fff2-1dff41b61518"
      },
      "id": "kNpgyduy7ulE",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.24 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubPlot Grids of Apnea Events "
      ],
      "metadata": {
        "id": "kPbeaF7WOonR"
      },
      "id": "kPbeaF7WOonR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "### Plot multiple subplots\n",
        "\n",
        "def PlotApneaEventsGrid (df):\n",
        "  \n",
        "  start_offset = dt.timedelta (seconds=15)\n",
        "  end_offset = dt.timedelta (seconds=45)\n",
        "  num_rows = 2\n",
        "  num_cols = 2\n",
        "  num_subplots = num_rows * num_cols\n",
        "\n",
        "  df_list_of_apnea_events = df[(df[Duration_Actual] != 0)]\n",
        "  \n",
        "  num_events = len(df_list_of_apnea_events)\n",
        "  # print (\"div \" + str(num_events/num_subplots))\n",
        "  # print (\"div \" + str(9/4))\n",
        "  # print (\"div \" + str(np.ceil(9/4)))\n",
        "  # #num_pages = int(num_events/num_subplots + 1)\n",
        "  num_pages = int(np.ceil(num_events/num_subplots))\n",
        "  #print (\"number of pages is \" + str (num_pages))\n",
        "  #print (\"number of events is \" + str (num_events))\n",
        "  current_page = 0\n",
        "  current_event = 0\n",
        " \n",
        "  fname = folder_name + ' plot_individual_events.pdf'\n",
        "  with PdfPages(fname) as pdf:\n",
        "    for page in range (num_pages):\n",
        "      fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols)\n",
        "      # print (axes.flat)\n",
        "      for ax in axes.flat:\n",
        "        if (current_event < num_events):\n",
        "          event_time = df_list_of_apnea_events.iloc[current_event].at[\"Data Date-Time\"]\n",
        "          plot_start = event_time - start_offset\n",
        "          plot_end = event_time + end_offset\n",
        "          df_event_data = df[((df[\"Data Date-Time\"] > plot_start) & (df[\"Data Date-Time\"] < plot_end))]\n",
        "          #print (\"Current Event Index is \" + str(current_event))\n",
        "          current_event = current_event + 1\n",
        "          plot_title = folder_name + \" Event \" + str(current_event) + \":  \" + str(event_time)\n",
        "          plotSPO2AndHR (df_event_data,plot_title,plot_start,plot_end,ax)\n",
        "    #   print (\"tight layout\")\n",
        "      fig.tight_layout()\n",
        "      pdf.savefig()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "C5DBtqMI2WTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f378f5-338d-4118-80b2-ceadb21e888e"
      },
      "id": "C5DBtqMI2WTB",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.73 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4vbvlm-hsj"
      },
      "source": [
        "## **Create Tables & Plots Functions**"
      ],
      "id": "sm4vbvlm-hsj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Names"
      ],
      "metadata": {
        "id": "Y7x2w8JT2a_D"
      },
      "id": "Y7x2w8JT2a_D"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Global Variables\n",
        "### Column Names\n",
        "Duration_Actual = \"Event Duration (s) [Actual Data]\"\n",
        "Duration_Custom = \"Event Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "Duration_Preset = \"Event Duration (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "Count_Actual = \"Event Count [Actual Data]\"\n",
        "Count_Custom = \"Event Count [Using Custom Settings - Theoretical Calculation]\"\n",
        "Count_Preset = \"Event Count (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "SumDuration_Actual = \"Cumulative Duration (s) [Actual Data]\"\n",
        "SumDuration_Custom = \"Cumulative Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "SumDuration_Preset = \"Cumulative Duration (s) [Using Preset Settings - Theoretical Calculation]\""
      ],
      "metadata": {
        "id": "CgzuYBvt8zNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637228db-6220-4a7c-d01f-6398f128cff6"
      },
      "id": "CgzuYBvt8zNI",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.56 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Tables"
      ],
      "metadata": {
        "id": "mcXFuo902gfD"
      },
      "id": "mcXFuo902gfD"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vsIRg70SdobY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1581b5-b70b-4c3c-c3df-b7b73d470492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.68 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def createDataTables (data_path):\n",
        "    df_LOGs = compileLogFiles (data_path)\n",
        "\n",
        "    df_s, df_d = splitToDataAndSettingsDF (df_LOGs)\n",
        "    # os.chdir(analysis_path)\n",
        "    # df_d.to_csv (folder_name + \" - Data.xlsx\")\n",
        "\n",
        "    # df_s.to_csv (folder_name + \" - Settings.xlsx\")\n",
        "    # dataframe_to_pdf(df_s, folder_name + \" - Settings\")\n",
        "\n",
        "    df_d[\"Is_Valid_Data\"] = GetIsValidColumn(df_d);\n",
        "\n",
        "    df_j = pd.merge (df_d,df_s, on='Settings Index')\n",
        "    # df_j = AddNumActualStimulations(df_j)\n",
        "    # df_j = AnalyzeWithCustomThresholds (df_j)\n",
        "    # df_j = AnalyzeWithPresetThresholds (df_j)\n",
        "    return df_j, df_d, df_s"
      ],
      "id": "vsIRg70SdobY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Plots"
      ],
      "metadata": {
        "id": "qINEVzl52lDl"
      },
      "id": "qINEVzl52lDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createPlots (df_j):\n",
        "    df_j.dtypes\n",
        "    plotByDay (df_j)\n",
        "    plotByHour (df_j)\n",
        "    PlotApneaEventsGrid (df_j)"
      ],
      "metadata": {
        "id": "AGgoCri491oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fa8524-b477-4bea-d8d6-74bfe553d475"
      },
      "id": "AGgoCri491oc",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 966 µs (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Summary Tables"
      ],
      "metadata": {
        "id": "N_4X5RS92tGl"
      },
      "id": "N_4X5RS92tGl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createSummaryTables (df,df_s):\n",
        "  \n",
        "  df_s_columns_dropped = df_s.drop(['Settings Date','Settings Time','Alarm intensity'], axis=1)\n",
        "  \n",
        "  reportApneaCountBySetting (df,df_s_columns_dropped)\n",
        "  reportIndividualActualApneas (df)"
      ],
      "metadata": {
        "id": "Ihvpi8G2ze28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c1a19a-4bef-4961-eee2-f3c0f190c1c4"
      },
      "id": "Ihvpi8G2ze28",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.21 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Summary"
      ],
      "metadata": {
        "id": "c1_bNt0BWjOt"
      },
      "id": "c1_bNt0BWjOt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "spo2_list = [85, 80, 75, 70, 65]\n",
        "hr_list = [110, 100, 90, 80]\n",
        "\n",
        "def createClinicalSummaryTable (df_j, record_name):\n",
        "    num_seconds_per_data_point = 1;\n",
        "    if (AB_Model == \"M1\"):\n",
        "        num_seconds_per_data_point = 2; # Tuhin's model M1 measured every 2 seconds. \n",
        "    # df_j[\"Is_Valid_Data\"] = GetIsValidColumn (df_j)\n",
        "    df_is_valid_data = df_j[df_j[\"Is_Valid_Data\"] == True]\n",
        "    df_clinical_summary = pd.DataFrame ()\n",
        "    df_clinical_summary [\"Name\"] = [record_name]\n",
        "    df_clinical_summary [\"Time ApneBoot System Was On (hrs)\"] = round (len(df_j.index) / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"Time with valid vital and status readings (hrs)\"] = round (df_j[\"Is_Valid_Data\"].sum()/60/60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"SPO2 - Avg\"] = round (df_is_valid_data['SPO2'].mean(),1)\n",
        "    df_clinical_summary [\"SPO2 - Std\"] = round (df_is_valid_data['SPO2'].std(),2)\n",
        "    df_clinical_summary [\"HR - Avg\"] = round (df_is_valid_data['HR'].mean(),1)\n",
        "    df_clinical_summary [\"HR - Std\"] = round (df_is_valid_data['HR'].std(),2)\n",
        "    \n",
        "    for spo2 in spo2_list:\n",
        "        df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\"(hrs)\"] = round(df_is_valid_data.query ('SPO2 < '+str(spo2))['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "    # df_clinical_summary [\"Time SPO2 < 85 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 85')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 80 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 80')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 75 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 75')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 70 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 70')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 65 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 65')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    return df_clinical_summary\n",
        "#   df_s.insert(loc = 3, column=\"Preset mode\", value = 1)"
      ],
      "metadata": {
        "id": "uRiSHGwMw5XT",
        "outputId": "8784708b-60f2-4060-cfd0-37958bedc604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uRiSHGwMw5XT",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.65 ms (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "R0eILh2iyWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16a3939-5d67-4976-ca90-a672b4c3fb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 483 µs (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_j stands for df_joined\n",
        "# display (df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"] !=0])\n",
        "#df[\"Time (hours)\"]={len(df)*1/60/60)\n",
        "# df_j.to_csv (folder_name + \" All_Data_Joined_Table.csv\")\n",
        "# df_s.to_csv (folder_name + \" Settings_Index_Table.csv\")"
      ],
      "id": "R0eILh2iyWqc"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# display(df_j[df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]!= df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]])\n",
        "# display(df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"]==0])"
      ],
      "metadata": {
        "id": "k7sHLvRYA10J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03159b9-1d77-49e2-93ad-980c8d57046e"
      },
      "id": "k7sHLvRYA10J",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 651 µs (started: 2023-03-14 13:11:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main FOR LOOP Code**\n",
        "\n"
      ],
      "metadata": {
        "id": "Nniyp_1baQUg"
      },
      "id": "Nniyp_1baQUg"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# folder_name = \"Geetha\"\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\"\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/\"\n",
        "\n",
        "# startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath \"\n",
        "\n",
        "import traceback\n",
        "\n",
        "Data_Cleanup_SP02_LowCutOff = 50  #If the SPO2 value at the time of APnea is below 60, it must be a bad data point. \n",
        "Data_Cleanup_HR_LowCutOff = 50\n",
        "AB_Model = \" \"\n",
        "\n",
        "paths, folder_names = list_folders(startpath)\n",
        "print (paths)\n",
        "print (folder_names)\n",
        "\n",
        "PRINT_TABLES = False\n",
        "os.chdir(startpath)\n",
        "os.makedirs(\"Analysis_Files\", exist_ok=True)\n",
        "analysis_path = startpath + \"/Analysis_Files/\"\n",
        "os.chdir(analysis_path)\n",
        "# errors = pd.DataFrame (columns = ['Folder Name',\"Model\",'Exception', \"filename\", \"lineno\", \"funcname\", \"text\"])\n",
        "errors = pd.DataFrame ()\n",
        "df_overall_clinical_summary = pd.DataFrame ()\n",
        "df_overall_clinical_summary_detailed = pd.DataFrame ()\n",
        "\n",
        "i = 0;\n",
        "for path in paths:\n",
        "    folder_name = folder_names[i]\n",
        "    i += 1\n",
        "    print (\"on file \" + str(i) + ' of ' + str(len(paths)))\n",
        "    try:\n",
        "        print (\"Working on \" + folder_name)\n",
        "        print (\"analysis path: \"+analysis_path)\n",
        "        os.chdir(analysis_path)\n",
        "        analysis_folder = \"Analysis - \" + folder_name\n",
        "        print (\"analysis folder: \" + analysis_folder)\n",
        "        os.makedirs(analysis_folder, exist_ok=True)\n",
        "        current_analysis_folder_path = analysis_path+ analysis_folder\n",
        "        print (\"Current analysis_folder_path: \" + current_analysis_folder_path)\n",
        "        os.chdir(current_analysis_folder_path)\n",
        "        \n",
        "        df_j, df_d, df_s = createDataTables (path)\n",
        "        # print (\"df_j - main\")\n",
        "        # display (df_j)\n",
        "        # createPlots (df_j)\n",
        "        # createSummaryTables (df_j,df_s)\n",
        "        #####\n",
        "        df_current_clinical_summary = pd.DataFrame ()\n",
        "        df_current_clinical_summary = createClinicalSummaryTable (df_j, folder_name)\n",
        "        df_current_clinical_summary[\"path\"] = path[-100:]\n",
        "        df_overall_clinical_summary = pd.concat([df_overall_clinical_summary, df_current_clinical_summary])\n",
        "        os.chdir(analysis_path)\n",
        "        df_overall_clinical_summary.to_excel (\"Overall Clinical Summary.xlsx\")\n",
        "        \n",
        "        #####\n",
        "        df_current_clinical_summary_detailed = df_current_clinical_summary\n",
        "        # df_current_clinical_summary_detailed[\"file_list\"] = file_list\n",
        "        df_current_clinical_summary_detailed[\"model\"] = AB_Model;\n",
        "        df_current_clinical_summary_detailed[\"data date-time\"] = df_j[\"Data Date-Time\"].iloc[0];\n",
        "        df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "        df_overall_clinical_summary_detailed.to_excel (\"Overall Clinical Summary - Detailed.xlsx\")\n",
        "        print (folder_name + \" success!\")\n",
        "\n",
        "    except Exception as exc: \n",
        "         print (\"ERROR FOR \" + folder_name + \":\")\n",
        "         filename, lineno, funcname, text = traceback.extract_tb(exc.__traceback__)[-1]\n",
        "         print (exc)\n",
        "         short_path = path[-100:]\n",
        "         current_error = pd.DataFrame (data = {'short_path': [short_path], 'Folder Name':[folder_name], \"Model\": [AB_Model], 'Exception':[exc], \"filename\": [filename], \"lineno\": [lineno], \"funcname\": [funcname], \"text\": [text], 'data header': [header], 'settings header': [settings_header], 'numcommas':[number_of_commas]})\n",
        "         errors = errors.append (current_error,ignore_index = True);\n",
        "         os.chdir(analysis_path)\n",
        "         errors.to_excel (\"Error Summary.xlsx\")\n",
        "\n",
        "\n",
        "print (\"errors table:\")\n",
        "display (errors)\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "RtVUyZ_9ZcLO",
        "outputId": "b22b8f0d-e4a1-4aa9-d36a-6ec1e0485325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "RtVUyZ_9ZcLO",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Parvati_intervention/Parvathi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Johnsi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Surya/surya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Suma/suma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sayeda', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Geetha/Geetha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Shobha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Vaishali', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sudha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Remi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Humera', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Aruna', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Anusha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 1/BO Tadamarri twin 1 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Shwetha 2', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Ayesha Banu', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Manjula', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Prema/BO Prema Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /stj70221oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701/stj703_21oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702/stj70121oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Stj03_01-sep', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ702_Intervention_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ701_Placebo_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 2/BO Tadamari twin 2 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Chandrakala Twin 1/BO Chandrakala Twin 1 Raw Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Noor Fathima/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath /Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sravanthi/AB Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/VaraLaxmi/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sunitha/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai/Raw data of AB device', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Tehseen', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Vani/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ramanamma/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Saraswati/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Hafsa/AB Device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Mounika/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Bhavani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Heena/ApneBoot Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ahmedi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Jyothi/Apneboot data']\n",
            "['Parvathi', 'Johnsi', 'surya', 'suma', 'Sayeda', 'Sneha', 'Geetha', 'Bhagya New', 'Soniya Mary', 'Shobha', 'Vaishali', 'Sujatha', 'Sudha', 'Remi', 'Sushma', 'Anitha', 'Baby of  Sujatha', 'Baby of Pavithra_placebo', 'Humera', 'Bhagya', 'Sushma', 'Aruna', 'Anitha', 'Anusha', 'Baby of Pavithra_placebo', 'Intervention_Unclear data', 'BO Hemabindu 2 data', 'BO Tadamarri twin 1 Raw data', 'BO Shwetha 2', 'BO Anitha', 'BO Ayesha Banu', 'BO Manjula', 'BO Prema Raw data', 'stj70221oct', 'stj703_21oct', 'st701', 'stj70121oct', 'st702', 'Stj03_01-sep', 'STJ702_Intervention_Clinical data_24_July-2020_4PM', 'STJ701_Placebo_Clinical data_24_July-2020_4PM', 'Baby 1', 'BO Tadamari twin 2 Raw data', 'BO Chandrakala Twin 1 Raw Data', 'Apneboot device data', 'Apneboot data', 'AB Data', 'AB device data', 'Apneboot device data', 'Raw data of AB device', 'Tehseen', 'AB device data', 'Apneboot data', 'AB device data', 'AB Device data', 'Apneboot data', 'Bhavani', 'ApneBoot Data', 'Ahmedi', 'Apneboot data']\n",
            "on file 1 of 60\n",
            "Working on Parvathi\n",
            "analysis path: /content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Analysis_Files/\n",
            "analysis folder: Analysis - Parvathi\n",
            "Current analysis_folder_path: /content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Analysis_Files/Analysis - Parvathi\n",
            "['27log29.csv']\n",
            "about to work on: 27log29.csv\n",
            "27-06-2019, 22:39:32,163,255,127,0\n",
            "27-06-2019, 22:39:36,163,255,127,0\n",
            "Clinical M1 (Nonin, Tuhin) 2019\n",
            "about to check valid_status\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Settings Index        Data Date-Time  Status   HR  SPO2  \\\n",
              "0                    1  27-06-2019  22:39:32     163  255   127   \n",
              "1                    1  27-06-2019  22:39:34     167  255   127   \n",
              "2                    1  27-06-2019  22:39:36     163  255   127   \n",
              "3                    1  27-06-2019  22:39:38     167  255   127   \n",
              "4                    1  27-06-2019  22:39:40     135  255    80   \n",
              "...                ...                   ...     ...  ...   ...   \n",
              "112074               1  30-06-2019  12:58:13     163  255   127   \n",
              "112075               1  30-06-2019  12:58:15     227  255   127   \n",
              "112076               1  30-06-2019  12:58:17     163  255   127   \n",
              "112077               1  30-06-2019  12:58:19     167  255   127   \n",
              "112078               1  30-06-2019  12:58:21     167  255   127   \n",
              "\n",
              "        Stimulator ON/OFF  Source File  \n",
              "0                       0  27log29.csv  \n",
              "1                       0  27log29.csv  \n",
              "2                       0  27log29.csv  \n",
              "3                       0  27log29.csv  \n",
              "4                       0  27log29.csv  \n",
              "...                   ...          ...  \n",
              "112074                  0  27log29.csv  \n",
              "112075                  0  27log29.csv  \n",
              "112076                  0  27log29.csv  \n",
              "112077                  0  27log29.csv  \n",
              "112078                  0  27log29.csv  \n",
              "\n",
              "[112079 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f7f8065-ec8f-49f1-bab2-2197ac05d9ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Settings Index</th>\n",
              "      <th>Data Date-Time</th>\n",
              "      <th>Status</th>\n",
              "      <th>HR</th>\n",
              "      <th>SPO2</th>\n",
              "      <th>Stimulator ON/OFF</th>\n",
              "      <th>Source File</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>27-06-2019  22:39:32</td>\n",
              "      <td>163</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>27-06-2019  22:39:34</td>\n",
              "      <td>167</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>27-06-2019  22:39:36</td>\n",
              "      <td>163</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>27-06-2019  22:39:38</td>\n",
              "      <td>167</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>27-06-2019  22:39:40</td>\n",
              "      <td>135</td>\n",
              "      <td>255</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112074</th>\n",
              "      <td>1</td>\n",
              "      <td>30-06-2019  12:58:13</td>\n",
              "      <td>163</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112075</th>\n",
              "      <td>1</td>\n",
              "      <td>30-06-2019  12:58:15</td>\n",
              "      <td>227</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112076</th>\n",
              "      <td>1</td>\n",
              "      <td>30-06-2019  12:58:17</td>\n",
              "      <td>163</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112077</th>\n",
              "      <td>1</td>\n",
              "      <td>30-06-2019  12:58:19</td>\n",
              "      <td>167</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112078</th>\n",
              "      <td>1</td>\n",
              "      <td>30-06-2019  12:58:21</td>\n",
              "      <td>167</td>\n",
              "      <td>255</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>27log29.csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112079 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f7f8065-ec8f-49f1-bab2-2197ac05d9ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f7f8065-ec8f-49f1-bab2-2197ac05d9ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f7f8065-ec8f-49f1-bab2-2197ac05d9ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval status for 0-255 status\n",
            "Parvathi success!\n",
            "on file 2 of 60\n",
            "Working on Johnsi\n",
            "analysis path: /content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Analysis_Files/\n",
            "analysis folder: Analysis - Johnsi\n",
            "Current analysis_folder_path: /content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Analysis_Files/Analysis - Johnsi\n",
            "['LOG00186.TXT']\n",
            "about to work on: LOG00186.TXT\n",
            "16/07/19,08:47:45,000,000,3,0000,0,0,0,\n",
            "16/07/19,08:47:47,150,095,0,0000,0,0,0,\n",
            "Clinical M2 (Nonin, Satish) 2019\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-829cc2d92c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_analysis_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdf_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateDataTables\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# print (\"df_j - main\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# display (df_j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-ddadae5daf60>\u001b[0m in \u001b[0;36mcreateDataTables\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf_LOGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompileLogFiles\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitToDataAndSettingsDF\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_LOGs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# os.chdir(analysis_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# df_d.to_csv (folder_name + \" - Data.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-f3c7cba0bcef>\u001b[0m in \u001b[0;36msplitToDataAndSettingsDF\u001b[0;34m(df_LOGs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;31m#Cleanup NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mdf_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mdf_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   5221\u001b[0m         \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5222\u001b[0m     ) -> DataFrame | None:\n\u001b[0;32m-> 5223\u001b[0;31m         return super().fillna(\n\u001b[0m\u001b[1;32m   5224\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5225\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6419\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_fillna_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6421\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6423\u001b[0m         \u001b[0;31m# set the default here, so functions examining the signaure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5655\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5639\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5640\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5641\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5650\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5651\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m#  BlockManager objects not yet attached to a DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2096\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[1;32m   2099\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2123\u001b[0m             \u001b[0;31m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0;31m# Sequence[Sequence[Any]], SupportsArray]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m             \u001b[0mbvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.8 s (started: 2023-03-14 13:49:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Match Table\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "clinical_fn = \"Overall Clinical Summary - Detailed.xlsx\"\n",
        "\n",
        "os.chdir(startpath)\n",
        "df_lookup = pd.read_csv(lookup_fn)\n",
        "os.chdir(analysis_path)\n",
        "df_clinical = pd.read_excel(clinical_fn)\n",
        "\n",
        "df_match = df_lookup.set_index('shortpath').join(df_clinical.set_index('path'))\n",
        "columns_to_keep = [\n",
        "# \"Order\",\n",
        "\"Unnamed: 1\",\n",
        "\"Baby of\",\n",
        "\"Start date of enrollment\",\n",
        "\"End date of enrollment\",\n",
        "\"Device_type\",\n",
        "\"Number of days of enrollment\",\n",
        "\"Birth weight (grams)\",\n",
        "\"GA\",\n",
        "\"Sub-Group\",\n",
        "# \"Total hypoxia duration (in secs)\",\n",
        "# \"Total hypoxia duration (in hh:mm:ss)\",\n",
        "\"Ventilation\",\n",
        "# \"86,400\",\n",
        "# \"Time Enrolled (S)\",\n",
        "# \"#Seconds in a day\",\n",
        "# \"% seconds in Hypoxia\",\n",
        "# \"Notes\",\n",
        "# \"Notes 2\",\n",
        "# \"Unnamed: 0\",\n",
        "# \"Name\",\n",
        "\"Time ApneBoot System Was On (hrs)\",\n",
        "\"Time with valid vital and status readings (hrs)\",\n",
        "\"SPO2 - Avg\",\n",
        "\"SPO2 - Std\",\n",
        "\"HR - Avg\",\n",
        "\"HR - Std\",\n",
        "\"Time SPO2 < 85 (hrs)\",\n",
        "\"Time SPO2 < 80 (hrs)\",\n",
        "\"Time SPO2 < 75 (hrs)\",\n",
        "\"Time SPO2 < 70 (hrs)\",\n",
        "\"Time SPO2 < 65 (hrs)\",\n",
        "\"model\",\n",
        "# \"data date-time\",\n",
        "]\n",
        "\n",
        "df_match = df_match [columns_to_keep]\n",
        "display (df_match)\n",
        "df_match.to_excel (\"4 - Matched Table Summary.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7SYrEoQoApav",
        "outputId": "73a83fea-05d4-4bae-a3a3-194c74db782c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "id": "7SYrEoQoApav",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-27c28dd16430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m ]\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdf_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_match\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mdf_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"4 - Matched Table Summary.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Time SPO2 < 85 (hrs)', 'Time SPO2 < 80 (hrs)', 'Time SPO2 < 75 (hrs)', 'Time SPO2 < 70 (hrs)', 'Time SPO2 < 65 (hrs)'] not in index\""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 263 ms (started: 2023-03-14 13:22:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4fmuhFuf5k"
      },
      "source": [
        "# DRAFT - New Section"
      ],
      "id": "5E4fmuhFuf5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdo3Bol12w2"
      },
      "source": [
        "## ** Not Used Code**"
      ],
      "id": "Ntdo3Bol12w2"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #fname = \"Report.pdf\"\n",
        "# with PdfPages(fname) as pdf:\n",
        "#   print(\"This is a test of the print function\")\n",
        "#   pdf.savefig()"
      ],
      "metadata": {
        "id": "0EU2cARS1Lsy"
      },
      "id": "0EU2cARS1Lsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# usage_pv_data_table = pd.pivot_table(data_table, index =['Data Date',\"Settings Index\"],\n",
        "#                          aggfunc = 'count')\n",
        "\n",
        "# print(usage_pv_data_table)\n",
        "# usage_pv_data_table.to_csv('Usage_pv_data_table.csv',index=True)\n",
        "# usage_pv_data_table.to_excel(\"Usage_pv_data_table.xlsx\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJ1x3Bq8bbc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pd.reset_option(\"all\")\n",
        "#df = stimulation_results_table_with_all_thresholds\n",
        "#print(df)\n",
        "#pivot = pd.pivot_table(stimulation_results_table_with_all_thresholds,\n",
        "                       #values=[\"Status\"], \n",
        "#                       index=['Status'])\n",
        "                       #aggfunc={'Status': np.count,\n",
        "                       # 'HR': [min, max, np.mean]})\n",
        "\n",
        "#df = df.Status.value_counts()\n",
        "#print(pivot)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "# pd.set_option(\"precision\", 4)\n",
        "\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#print(len (stimulation_results_table_with_all_thresholds))\n",
        "#filtered_results_table_all = df[(df[\"Status\"]==129) | (df[\"Status\"]==131)]\n",
        "#print(len (filtered_results_table_all))\n",
        "\n",
        "#data_table = filtered_results_table_all\n",
        "\n",
        "# pivot = pd.pivot_table(data_table,\n",
        "#                        values=['SPO2','HR'], \n",
        "#                        index=['Data Date'],\n",
        "#                        aggfunc={'SPO2': np.mean,\n",
        "#                         'HR': [min, max, np.mean]})\n",
        "\n",
        "#print(pivot)\n",
        "#filtered_results_table_all.to_csv(\"Filtered_Results_Table_All.csv\")\n",
        "\n",
        "# 129    91112\n",
        "# 153    49477\n",
        "# 131    32220\n"
      ],
      "id": "WYJ1x3Bq8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBwS6cI9JH6"
      },
      "source": [
        "\n",
        "Want \n",
        "- Date\n",
        "- Setting Index\n",
        "- \n",
        "\n"
      ],
      "id": "qlBwS6cI9JH6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # !sudo apt-get install wkhtmltopdf\n",
        "# # !yum install wkhtmltopdf\n",
        "# !apt-get install wkhtmltopdf\n",
        "# import pandas as pd \n",
        "# df_apnea_summary_table.to_html('HTMLTest.html')  \n",
        "\n",
        "# import pdfkit \n",
        "\n",
        "# pdfkit.from_url('HTMLTest.html', 'HTMLTest.pdf')"
      ],
      "metadata": {
        "id": "k08O7_OMVpRX"
      },
      "id": "k08O7_OMVpRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df = pd.DataFrame({'Col': [1,4,5,6,7],\n",
        "                   'Col2': [1,4,5,6,7],\n",
        "                   })\n",
        "display (df)\n",
        "New_Col = \"Col3\"\n",
        "df [New_Col] = df[\"Col\"] +1\n",
        "\n",
        "display (df)\n",
        "display (df[New_Col])"
      ],
      "metadata": {
        "id": "1gwuIXkd74XG"
      },
      "id": "1gwuIXkd74XG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Create a pandas dataframe with demo data:\n",
        "#!pip install -e git+https://github.com/mindee/doctr.git#egg=python-doctr[torch]\n",
        "#!pip install weasyprint\n",
        "!pip install django-weasyprint\n",
        "import pandas as pd\n",
        "demodata_csv = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
        "df = pd.read_csv(demodata_csv)\n",
        "\n",
        "def dfToPDF (df):\n",
        "  # Pretty print the dataframe as an html table to a file\n",
        "  intermediate_html = '/tmp/intermediate.html'\n",
        "  to_html_pretty(df,intermediate_html,'Iris Data')\n",
        "  # if you do not want pretty printing, just use pandas:\n",
        "  # df.to_html(intermediate_html)\n",
        "\n",
        "  # Convert the html file to a pdf file using weasyprint\n",
        "  import weasyprint\n",
        "  out_pdf= '/tmp/demo.pdf'\n",
        "  weasyprint.HTML(intermediate_html).write_pdf(out_pdf)\n",
        "\n",
        "  # This is the table pretty printer used above:\n",
        "\n",
        "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
        "    '''\n",
        "    Write an entire dataframe to an HTML file\n",
        "    with nice formatting.\n",
        "    Thanks to @stackoverflowuser2010 for the\n",
        "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
        "    '''\n",
        "    ht = ''\n",
        "    if title != '':\n",
        "        ht += '<h2> %s </h2>\\n' % title\n",
        "    ht += df.to_html(classes='wide', escape=False)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)\n",
        "\n",
        "HTML_TEMPLATE1 = '''\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "  h2 {\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "  }\n",
        "  table { \n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "  }\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "    font-size: 90%;\n",
        "  }\n",
        "  table tbody tr:hover {\n",
        "    background-color: #dddddd;\n",
        "  }\n",
        "  .wide {\n",
        "    width: 90%; \n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "'''\n",
        "\n",
        "HTML_TEMPLATE2 = '''\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "_4nxBzcnuBex"
      },
      "id": "_4nxBzcnuBex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # PRINT TABLES & DATA\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# #https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
        "# #df_apnea_summary_table.plot()\n",
        "# #dfToPDF (df)\n",
        "# # fig = convertDataframeToFigure (apnea_summary_table)\n",
        "# # pdf = PdfPages(\"foo.pdf\")\n",
        "# # pdf.savefig(fig, bbox_inches='tight')\n",
        "# # pdf.close()\n",
        "# # !pip install -c conda-forge python-pdfkit\n",
        "# !pip3 install wkhtmltopdf\n",
        "# !pip3 install pdfkit\n",
        "\n",
        "# import pandas as pd\n",
        "# import pdfkit as pdf\n",
        "# import sqlite3\n",
        "\n",
        "# # con=sqlite3.connect(\"baza.db\")\n",
        "\n",
        "# # df=pd.read_sql_query(\"select * from dobit\", con)\n",
        "# #df_apnea_summary_table.datetime = pd.to_datetime(apnea_summary_table.datetime)\n",
        "# display(df_apnea_summary_table)\n",
        "\n",
        "# df_apnea_summary_table.to_html('apnea_summary_table.html')\n",
        "# nazivFajla='test.pdf'\n",
        "# config = pdf.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "# pdf.from_url('apnea_summary_table.html', nazivFajla, configuration=config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kb94aQAehXxh"
      },
      "id": "Kb94aQAehXxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "os.chdir(startpath)\n",
        "file_name = '12log5 - made from mona xls file.csv'\n",
        "file_name = 'Book2.csv'\n",
        "df = pd.read_csv(file_name, header=None)"
      ],
      "metadata": {
        "id": "Qmiv2ryWUynD",
        "outputId": "c36d9acd-345a-486c-e44b-bfb07dba906b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Qmiv2ryWUynD",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 413 ms (started: 2023-03-14 13:42:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "3FuNu9FnVX5F",
        "outputId": "07d68f79-4277-4925-936d-53bfc8262c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3FuNu9FnVX5F",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\n",
            "'12log5 - made from mona xls file.csv'\t Book2.csv\n",
            " 12log5.xlsx\t\t\t\t\"Sneha_St John's_Analysis by Mona.xlsx\"\n",
            " Analysis_Files\n",
            "time: 345 ms (started: 2023-03-14 13:42:00 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTpOGQud6Max",
        "7VpeZHhf7O2V",
        "T3dPG9_2xoX3",
        "c9pqOw4FnVYA",
        "Ff704C-MwEsw",
        "4C39qoDxEcnt",
        "vFvsiREGpJ-8",
        "1uadoNfrjZUt",
        "bHJA2jljjdc-",
        "eoiLSOJ3jfmj",
        "kPbeaF7WOonR",
        "Y7x2w8JT2a_D",
        "qINEVzl52lDl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}