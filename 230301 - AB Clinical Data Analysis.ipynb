{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulbempu/ApneBoot-Clinical-Data-Analysis/blob/main/230301%20-%20AB%20Clinical%20Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-07-23 - I updated it so it loads logs and creates df_s and df_d faster. Also includes Log Source File. Works for Zug, need to check for nonin. \n",
        "Actual and Preset are slightly different because:\n",
        "- Preset mode number shows up at the start of the apnea, Stim shows at start of stim +1 (instead of 5s it looks like 6 sec+1. This may be a rounding issue. Would be nice if they were on the same line but ok. \n",
        "- This rounding issue may also cause different apnea stimulation lengths by a second or two.\n",
        "\n",
        "\n",
        "22-09-03 - \n",
        "- Added code to convert table to pdf\n",
        "\n",
        "22-09-10 -\n",
        "- Fix Smoothing Issue\n",
        "- Add Thresholds \n",
        "\n",
        "22-19-18\n",
        "Todo:\n",
        "- X make individual plots ouput to pdf\n",
        "- X - Good Enough - make summary table cleaner\n",
        "  - reduce number of columns\n",
        "  - increase overall font size\n",
        "- X test with custom thresholds\n",
        "- test and fix for nonin\n",
        "- combine relevent pdfs into a report.\n",
        "- test with Clinical Data\n",
        "\n",
        "23-03-01\n",
        "- want table with name, total time monitored, total time below X condition calculated), total stimulations, total stimulation time, total time under Y condition, total errorenous data. \n",
        "\n",
        "23-03-15\n",
        "- check against Mona's numbers\n",
        "- \n",
        "\n"
      ],
      "metadata": {
        "id": "COmxc45t43_s"
      },
      "id": "COmxc45t43_s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2P7Ld8v0Zf"
      },
      "source": [
        "## **Initialize**"
      ],
      "id": "VY2P7Ld8v0Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Folder Name"
      ],
      "metadata": {
        "id": "s14DGNWX59Me"
      },
      "id": "s14DGNWX59Me"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Find Folders"
      ],
      "metadata": {
        "id": "KR-D_OFUQ4mK"
      },
      "id": "KR-D_OFUQ4mK"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "outputId": "52a317dc-4aed-4732-dc5d-1da20908b830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n432-4cQ4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (67.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->ipython-autotime) (2.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "Imports done\n",
            "time: 12.7 ms (started: 2023-03-27 16:26:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import fileinput\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "import linecache\n",
        "from pathlib import Path\n",
        "# Garbage Collector - use it like gc.collect()\n",
        "import gc\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "print (\"Imports done\")"
      ],
      "id": "6n432-4cQ4mR"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "outputId": "895d3941-771a-4a20-d96e-52d5feb36e8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-ikFo4Q4mR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 26 s (started: 2023-03-27 16:26:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "aF-ikFo4Q4mR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Folders List"
      ],
      "metadata": {
        "id": "wu1Ny53mRFbR"
      },
      "id": "wu1Ny53mRFbR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "def list_folders(startpath):\n",
        "    list_path = []\n",
        "    list_folder = []\n",
        "    log = \"log\"\n",
        "    LOG = \"LOG\"\n",
        "    is_data_dir = 0;\n",
        "    previous_name_path = \"\"\n",
        "    for root, subdirs, files in os.walk(startpath):\n",
        "        is_data_dir = 0\n",
        "        for filename in files:\n",
        "            current_name_path = os.path.join(root)\n",
        "            if ((log in filename) | (LOG in filename)) & (previous_name_path != current_name_path):\n",
        "                full_path = os.path.join(root,filename)\n",
        "                list_folder.insert (0, os.path.basename (current_name_path))\n",
        "                list_path.insert(0, root)\n",
        "                previous_name_path = current_name_path\n",
        "\n",
        "    return list_path, list_folder\n"
      ],
      "metadata": {
        "id": "z6m2mfEt8Smu",
        "outputId": "d8000671-5f5b-40b1-cf66-c562615ef3a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z6m2mfEt8Smu",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 18.3 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Initialize Folders"
      ],
      "metadata": {
        "id": "PTpOGQud6Max"
      },
      "id": "PTpOGQud6Max"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQuN0Iql7AUK"
      },
      "source": [
        "## **Convert Files to Data Frames**"
      ],
      "id": "LQuN0Iql7AUK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers for Different Logger Versions"
      ],
      "metadata": {
        "id": "7VpeZHhf7O2V"
      },
      "id": "7VpeZHhf7O2V"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "header = \"\"\n",
        "settings_header = \"\" \n",
        "AB_Model = \"default_string\"\n",
        "number_of_commas = 0\n",
        "\n",
        "\n",
        "def decideDataLoggerVersion (df):\n",
        "  # Read the third line's header and decide which data logger version is used\n",
        "  # Assumes that the third line is unique for each data logger version\n",
        "  # I need to check with Sourabh if the third line correlates with versions for the St. John's studies.\n",
        "  global header\n",
        "  global settings_header\n",
        "  global AB_Model\n",
        "  global number_of_commas\n",
        "  \n",
        "  raw_logfile_data_table_headers = [\"default\"]\n",
        "  settings_table_headers = [\"\"]\n",
        "  data_table_headers = [\"\"]\n",
        "  settings_columns_rename_dict = [\"\"]\n",
        "  settings_columns_to_drop = [\"\"]\n",
        "  version = \"unknown data code version\"\n",
        "\n",
        "  ZUG_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,PI,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Battery voltage;\"\n",
        "  NONIN_DATA_HEADER = \"dd/mm/yy,hh:mm:ss,SPO2,HR,Status,Pulse-ox mode,Threshold Met,Stimulator Error,Stimulator ON/OFF,Power Mode,Probe Off patient,Battery voltage\"\n",
        "  CLINICAL_SETTINGS_HEADER_INTERVENTION = \"dd/mm/yy,hh:mm:ss,Intervention,Stimulator Intensity,Alarm intensity;\"\n",
        "  CLINICAL_SETTINGS_HEADER_PLACEBO = \"dd/mm/yy,hh:mm:ss,Placebo,Stimulator Intensity,Alarm intensity;\"\n",
        "\n",
        "  settings_header = df.iat[0,0]\n",
        "  header = df.iat[2,0]\n",
        "  number_of_commas = header.count (',')\n",
        "  print (settings_header)\n",
        "  print (header)\n",
        "\n",
        "  if header == ZUG_DATA_HEADER:\n",
        "    version = \"ZUG Circa April 2022\"\n",
        "    # print (\"Detected Zug\")\n",
        "  elif (header == NONIN_DATA_HEADER):\n",
        "      if (settings_header == CLINICAL_SETTINGS_HEADER_INTERVENTION):\n",
        "          version = \"Clinical M3-Intervention (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Intervention\"\n",
        "      elif (settings_header == CLINICAL_SETTINGS_HEADER_PLACEBO):\n",
        "          version = \"Clinical M3-Placebo (Nonin) 2019\"\n",
        "          AB_Model = \"M3-Placebo\"\n",
        "      else:\n",
        "          version = \"NONIN Circa April 2022\"\n",
        "    # print (\"Detected Nonin\")\n",
        "  elif number_of_commas == 5:\n",
        "      version = \"Clinical M1 (Nonin, Tuhin) 2019\"\n",
        "      AB_Model = \"M1\"\n",
        "  elif number_of_commas == 9:\n",
        "      version = \"Clinical M2 (Nonin, Satish) 2019\"\n",
        "      AB_Model = \"M2\"\n",
        "  else:\n",
        "    print (\"Not able to Detect Nonin Nor Zug\")\n",
        "    AB_Model = \"Unable to detect AB Model\"\n",
        "  \n",
        "  print (version)\n",
        "\n",
        "  if version == \"ZUG Circa April 2022\":\n",
        "    AB_Model = \"ZUG Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "            \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "                \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",   \n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Data Date-Time\": 'datetime64[ns]',\n",
        "                \"Data Date\": 'datetime64[ns]',\n",
        "                \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "                \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float\n",
        "                #,\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "#                \"Settings Index\": int,\n",
        "                \"Settings Date-Time\": str,\n",
        "                \"Settings Date\": str,\n",
        "                'Settings Time':str,\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str}\n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"PI\":\"HR Threshold\",\n",
        "            \"Status\":\"AND/OR\",\n",
        "            \"Pulse-ox mode\":\"Duration\",\n",
        "            \"Threshold Met\":\"Stimulator Intensity\",\n",
        "            \"Stimulator Error\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    \n",
        "    settings_columns_to_drop = [\"Stimulator ON/OFF\",\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\"]\n",
        "\n",
        "  if version == \"NONIN Circa April 2022\":\n",
        "    AB_Model = \"NONIN Circa April 2022\"\n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "        #     \"Probe Off patient\", - July 22, 2022 - RN checked this with Sourabh - this value was not being recorded although it is in the header\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"\n",
        "            #\"Settings Index\" # This is added at the end and is blank until filled\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                'Preset mode':int,\n",
        "                'SPO2 Threshold':int,\n",
        "                \"HR Threshold\":int,\n",
        "                \"AND/OR\":int,\n",
        "                \"Duration\":int,\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Preset mode\",\n",
        "            \"HR\":\"SPO2 Threshold\",\n",
        "            \"Status\":\"HR Threshold\",\n",
        "            \"Pulse-ox mode\":\"AND/OR\",\n",
        "            \"Threshold Met\":\"Duration\",\n",
        "            \"Stimulator Error\":\"Stimulator Intensity\",\n",
        "            \"Stimulator ON/OFF\":\"Alarm intensity\"\n",
        "        #     \"Stimulator ON/OFF\",\n",
        "        #     \"Power Mode\",\n",
        "        # #     \"Probe Off patient\",\n",
        "        #     \"Battery voltage\",\n",
        "        #     \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "           \"Power Mode\",\n",
        "            \"Battery voltage\",\n",
        "            \"Extra Column\"]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "  if version == \"Clinical M1 (Nonin, Tuhin) 2019\":\n",
        "\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"Status\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [    \n",
        "                    \"Status\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Stimulator ON/OFF\",        \n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "  if version == \"Clinical M2 (Nonin, Satish) 2019\":\n",
        "    raw_logfile_data_table_headers = [\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"HR\",\n",
        "            \"SPO2\",\n",
        "            \"Status\",\n",
        "            \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Unused Column 4\",\n",
        "             # <-- need to double check which column is stim off/on\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"HR\",\n",
        "                \"SPO2\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "            #     \"Pulse-ox mode\":int,\n",
        "            #     \"Threshold Met\":int,\n",
        "            #     \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int\n",
        "            #     \"Power Mode\":int,\n",
        "            # #     \"Probe Off patient\":int,\n",
        "            #     \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "\n",
        "    settings_convert_dict = {\n",
        "                # \"Settings Date-Time\": 'datetime64[ns]',\n",
        "                # \"Settings Date\": 'datetime64[ns]',\n",
        "                # 'Settings Time':'datetime64[ns]',\n",
        "                # 'Preset mode':int,\n",
        "                # 'SPO2 Threshold':int,\n",
        "                # \"HR Threshold\":int,\n",
        "                # \"AND/OR\":int,\n",
        "                # \"Duration\":int,\n",
        "                # \"Stimulator Intensity\":int\n",
        "                # \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    settings_columns_rename_dict = {\n",
        "\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            # \"Stimulator ON/OFF\",\n",
        "            # \"Power Mode\",\n",
        "        #     \"Probe Off patient\",\n",
        "            # \"Battery voltage\",\n",
        "            # \"Settings Index\" # This is added at the end and is blank until filled\n",
        "        }\n",
        "    settings_columns_to_drop = [            \n",
        "        \"HR\",\t\"SPO2\",\t\"Status\",\"Stimulator ON/OFF\",\n",
        "        \"Unused Column 1\",\n",
        "            \"Unused Column 2\",\n",
        "            \"Unused Column 3\",\n",
        "            \"Unused Column 4\",\n",
        "            ]\n",
        "\n",
        "################ M3 ###########\n",
        "  if ((version == \"Clinical M3-Intervention (Nonin) 2019\") | (version == \"Clinical M3-Placebo (Nonin) 2019\")):\n",
        "  \n",
        "    raw_logfile_data_table_headers = [#\"Settings Index\",\n",
        "                          #\"Data Date-Time\",\n",
        "                           \"Data Date\",\n",
        "             \"Data Time\",\n",
        "            \"SPO2\",\n",
        "            \"HR\",\n",
        "         #   \"PI\",\n",
        "            \"Status\",\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "            ]\n",
        "    data_table_headers = [\"Settings Index\",\n",
        "                \"Data Date-Time\",\n",
        "                \"Data Date\",\n",
        "                \"Data Time\",\n",
        "                \"SPO2\",\n",
        "                \"HR\",\n",
        "          #      \"PI\",\n",
        "                \"Status\",\n",
        "                \"Pulse-ox mode\",\n",
        "                \"Threshold Met\",\n",
        "                \"Stimulator Error\",\n",
        "                \"Stimulator ON/OFF\",\n",
        "               \"Power Mode\",\n",
        "            #   \"Probe Off patient\",\n",
        "                \"Battery voltage\"\n",
        "                ]\n",
        "    settings_table_headers = [#'Settings Date-Time'\n",
        "                              'Settings Index',\n",
        "                                  'Settings Date',\n",
        "                'Settings Time',\n",
        "                'Preset mode',\n",
        "                'SPO2 Threshold',\n",
        "                \"HR Threshold\",\n",
        "                \"AND/OR\",\n",
        "                \"Duration\",\n",
        "                \"Stimulator Intensity\",\n",
        "                \"Alarm intensity\"]\n",
        "\n",
        "    data_convert_dict = {\n",
        "                #\"Settings Index\": int,\n",
        "                # \"Data Date-Time\": 'datetime64[ns]',\n",
        "                # \"Data Date\": 'datetime64[ns]',\n",
        "                # \"Data Time\": 'datetime64[ns]',\n",
        "                \"SPO2\": int,\n",
        "                \"HR\": int,\n",
        "           #     \"PI\": float,\n",
        "                \"Status\": int,\n",
        "                \"Pulse-ox mode\":int,\n",
        "                \"Threshold Met\":int,\n",
        "                \"Stimulator Error\":int,\n",
        "                \"Stimulator ON/OFF\":int,\n",
        "                \"Power Mode\":int,\n",
        "            #     \"Probe Off patient\":int,\n",
        "                \"Battery voltage\": float}\n",
        "                #\"Settings Index\": int}\n",
        "\n",
        "    settings_convert_dict = {\n",
        "\n",
        "                \"Stimulator Intensity\":int,\n",
        "                \"Alarm intensity\":str\n",
        "                #\"Settings Index\": int\n",
        "                }\n",
        "    ## Settings rename dictionary is different \n",
        "    settings_columns_rename_dict = {\n",
        "             \"Data Date\":\"Settings Date\",\n",
        "             \"Data Time\": \"Settings Time\",\n",
        "            \"SPO2\":\"Intervention or Placebo\", \n",
        "            \"HR\" : \"Stimulator Intensity\",\n",
        "            \"Status\":\"Alarm intensity\",\n",
        "        }\n",
        "    settings_columns_to_drop = [\n",
        "            \"Pulse-ox mode\",\n",
        "            \"Threshold Met\",\n",
        "            \"Stimulator Error\",\n",
        "            \"Stimulator ON/OFF\",\n",
        "            \"Power Mode\",\n",
        "            \"Probe Off patient\", # clinical version has this column matching up, not sure if it is actually recording the correct data though\n",
        "            \"Battery voltage\",\n",
        "]\n",
        "\n",
        "#   elif number_of_commas == 5:\n",
        "#       version = \"Nonin Clinical Study Model 2019\"\n",
        "\n",
        "\n",
        "  return raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict"
      ],
      "metadata": {
        "id": "-OMUDW4FZpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec714ce9-e406-485a-8c79-6907bc600d88"
      },
      "id": "-OMUDW4FZpEd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 21.4 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile & Split Log Files to df_d and df_s"
      ],
      "metadata": {
        "id": "kns3IrBcDkdb"
      },
      "id": "kns3IrBcDkdb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Reference here: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
        "file_list = []\n",
        "\n",
        "def compileLogFiles (path):\n",
        "  global file_list\n",
        "#   print (path)\n",
        "  os.chdir(path)\n",
        "  file_list = sorted(glob.glob(\"*LOG*.csv\")) + sorted(glob.glob(\"*log*.csv\")) + sorted(glob.glob(\"*Log*.csv\")) + sorted(glob.glob(\"*LOG*.txt\")) + sorted(glob.glob(\"*log*.txt\")) + sorted(glob.glob(\"*Log*.txt\")) + sorted(glob.glob(\"*LOG*.TXT\")) + sorted(glob.glob(\"*log*.TXT\")) + sorted(glob.glob(\"*Log*.TXT\"))\n",
        "              # in 2019 clinical, some files are log and some are LOG\n",
        "#   file_list = sorted(glob.glob(\"*\"))\n",
        "  number_of_files = len(file_list)\n",
        "#   print(\"Number of Files:\" , len(file_list))\n",
        "  print (file_list)\n",
        "  li = []\n",
        "\n",
        "  for file_name in file_list:\n",
        "    # This could work faster potentially, but then the data logger identifier code for finding the zug/nonin code string has to be changed\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n', names=list(range(12)))\n",
        "    \n",
        "    # df = pd.read_csv(file_name, header=None)\n",
        "    df = pd.read_csv(file_name, header=None, sep='\\0')\n",
        "    # df = pd.read_csv(file_name, header=None, sep='\\n')\n",
        "    # df = pd.read_csv(file_name, header=None, sep=',')\n",
        "    df['Source File'] = file_name\n",
        "    li.append (df)\n",
        "  \n",
        "  frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "_MMQAV31zaJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981e14f8-ceac-47a6-b11b-e2cc359c4dbb"
      },
      "id": "_MMQAV31zaJk",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.02 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def splitToDataAndSettingsDF (df_LOGs):\n",
        "  \n",
        "  raw_logfile_data_table_headers, settings_table_headers, data_table_headers, settings_columns_rename_dict, settings_columns_to_drop, settings_convert_dict, data_convert_dict = decideDataLoggerVersion (df_LOGs)    \n",
        "\n",
        "  df_raw = df_LOGs[0].str.split(',', expand=True)\n",
        "  #display (df_raw)\n",
        "   \n",
        "  df_raw.columns = raw_logfile_data_table_headers\n",
        "  df_raw[\"Source File\"] = df_LOGs [\"Source File\"]\n",
        "\n",
        "  # Extract Settings\n",
        "  df_raw_shift = df_raw.shift(periods=-1)\n",
        "  df_s = df_raw_shift[(df_raw.iloc[:,2]==\"Preset mode\") | (df_raw.iloc[:,2]==\"Intervention\") | (df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  # For the clinical data - just use the rows with a new source file to keep the time/date and file. \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == 'M2')):\n",
        "    df_s = df_raw.drop_duplicates(subset=[\"Source File\"], keep='first')\n",
        "\n",
        "\n",
        "  # Delete settings and settings headers\n",
        "  df_raw_shift = df_raw.shift(periods=1)                                        #shift down one row as a way to find one line below the settings header\n",
        "  rows_below_header = df_raw[(df_raw_shift.iloc[:,2]==\"Preset mode\") |(df_raw_shift.iloc[:,2]==\"Intervention\")|(df_raw_shift.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop(rows_below_header.index)                                 #Drop all the setttings data lines \n",
        "  rows_with_header = df_raw[(df_raw.iloc[:,2]==\"Preset mode\") |(df_raw.iloc[:,2]==\"Intervention\")|(df_raw.iloc[:,2]==\"Placebo\")]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the settings headers\n",
        "  rows_with_header = df_raw[df_raw.iloc[:,2]==\"SPO2\"]\n",
        "  df_raw = df_raw.drop (rows_with_header.index)                                 #Drops all the DATA headers\n",
        "  \n",
        "  # Format Settings Files\n",
        "  df_s.drop(settings_columns_to_drop, axis=1, inplace=True)                     # Drop extra columns\n",
        "  df_s.rename(columns=settings_columns_rename_dict, inplace=True)\n",
        "  if 'Alarm Intensity' in df_s.columns:\n",
        "    df_s['Alarm intensity'].apply(lambda v: v.rstrip(';'))\n",
        "  \n",
        "  #What's left of df_raw is now df_d for data\n",
        "  df_d = df_raw\n",
        "  if (AB_Model == \"NONIN Circa April 2022\"):\n",
        "    df_d.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "    #df_s.drop (columns = \"Extra Column\", axis = 1, inplace=True)\n",
        "\n",
        "  # In the clinical, Tuhin put P for the devices that were placebo and would have stimulated but actually didn't.\n",
        "  # Replace those with the number 1\n",
        "  df_d[\"Stimulator ON/OFF\"].mask(df_d[\"Stimulator ON/OFF\"] == \" P\", 1, inplace= True)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  if (AB_Model == \"M1\"):\n",
        "    format_day = '%d-%MM-%yyyy'\n",
        "    format_time = '%H:%m:%s'\n",
        "  else:\n",
        "    format_day = '%d/%m/%y'\n",
        "    format_time = '%H:%M:%S'\n",
        "    \n",
        "\n",
        "#   if (AB_Model == \"M1\"):\n",
        "#       try:\n",
        "#         display (df_s)\n",
        "#         display (df_d)\n",
        "#         # df_s.head()\n",
        "#         # df_d.head()\n",
        "        \n",
        "#         # print (df_d.columns)\n",
        "#         # print (\"df_s1 \" + df_s[\"Settings Date\"][3] + df_s[\"Settings Time\"][3])\n",
        "#         df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))\n",
        "#         print (\"df_d1 \" + df_d[\"Data Date\"][3] + df_d[\"Data Time\"][3])\n",
        "#         df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d-%MM-%yyyy %H:%m:%s'))   \n",
        "#         print (\"matched 1!\")\n",
        "#       except Exception as e:\n",
        "#           print (e)\n",
        "#           print (\"try alternate date format:\")\n",
        "#           display (df_s)\n",
        "#         #   print (df_d.columns)\n",
        "#           try:\n",
        "#             # df_s.drop (\"Settings Date-Time\")\n",
        "#             # df_d.drop (\"Data Date-Time\")\n",
        "#             # df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + df_s[\"Settings Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))\n",
        "#             # df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + df_d[\"Data Time\"] ,format='%d/%M/%yyyy %H:%m:%s'))  \n",
        "#             print (\"matched 2!\")\n",
        "#           except Exception as e2:\n",
        "#             print (e2)\n",
        "#             print (\"no more date formats to try!\")       \n",
        " \n",
        "\n",
        "#   else:\n",
        "#     df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#     df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"] ,format='%d/%m/%y %H:%M:%S'))\n",
        "#   print (\"inserting with \"+format_day + \" \" + format_time)\n",
        "#   display (df_s)\n",
        "\n",
        "#   print (\"df_s insert done, here's what it looks like\")\n",
        "#   display (df_s)\n",
        "#   display (df_d)\n",
        "\n",
        "#   print (\"df_d coerce done and now df_d looks like:\")\n",
        "#   display (df_d)\n",
        "#   print (\"inserts done\")\n",
        "\n",
        "# MARCH 9, 2023 - These two lines below work (infer_datetime_format=True needs to be checked bc some columns may have multiple date Time formats?) \n",
        "# but it's still slow so I'm commenting them out for now and replacing them with the two below\n",
        "\n",
        "#   df_s.insert(loc=0, column=\"Settings Date-Time\", value=pd.to_datetime(df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "#   df_d.insert(loc=0, column=\"Data Date-Time\", value=pd.to_datetime(df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"], infer_datetime_format = True, errors = 'coerce'))\n",
        "\n",
        "  df_s.insert(loc=0, column=\"Settings Date-Time\", value=df_s[\"Settings Date\"] + ' ' + df_s[\"Settings Time\"])\n",
        "  df_d.insert(loc=0, column=\"Data Date-Time\", value=df_d[\"Data Date\"] + ' ' + df_d[\"Data Time\"])\n",
        "\n",
        "  \n",
        "  if ((AB_Model == \"M1\") | (AB_Model == \"M2\") | (AB_Model == \"M3-Placebo\") | (AB_Model == \"M3-Intervention\")):\n",
        "      df_s.insert(loc = 3, column=\"Preset mode\", value = 1)\n",
        "      df_s.insert(loc = 4, column=\"SPO2 Threshold\", value = 0)\n",
        "      df_s.insert(loc = 5, column=\"HR Threshold\", value = 0)\n",
        "      df_s.insert(loc = 6, column=\"AND/OR\", value = 0)\n",
        "      df_s.insert(loc = 7, column=\"Duration\", value = 0)\n",
        "      if ((AB_Model == \"M1\") | (AB_Model == \"M2\")):\n",
        "        df_s.insert(loc = 8, column=\"Stimulator Intensity\", value = 0)\n",
        "        df_s.insert(loc = 9, column=\"Alarm intensity\", value = 0)\n",
        "\n",
        "  #Cleanup NaNs\n",
        "  df_d = df_d.fillna(0)\n",
        "  df_s = df_s.fillna(0)\n",
        "\n",
        "  #Convert to best datatypes\n",
        "\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format='%d/%m/%y')\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format='%H:%M:%S')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format='%d/%m/%y')\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format='%H:%M:%S')#.dt.time\n",
        "\n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"],format=format_day)\n",
        "#   print (\"Settings Date Updated done\")\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Settings Time Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"],format=format_day)\n",
        "#   print (\"Data Date Updated done\")\n",
        "  \n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"],format=format_time)#.dt.time\n",
        "#   print (\"Data Time Updated done\")\n",
        "  \n",
        "## For Clinical Analysis I am not going to do these, since they are already done above when combined. \n",
        "#   df_s[\"Settings Date\"]=pd.to_datetime(df_s[\"Settings Date\"])\n",
        "#   df_s[\"Settings Time\"]=pd.to_datetime(df_s[\"Settings Time\"], errors = 'coerce')#.dt.time\n",
        "#   df_d[\"Data Date\"]=pd.to_datetime(df_d[\"Data Date\"])\n",
        "#   df_d[\"Data Time\"]=pd.to_datetime(df_d[\"Data Time\"], errors = 'coerce')#.dt.time\n",
        "  df_s.drop(columns = \"Settings Date\", axis = 1, inplace=True)\n",
        "  df_s.drop(columns = \"Settings Time\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Date\", axis = 1, inplace=True)\n",
        "  df_d.drop(columns = \"Data Time\", axis = 1, inplace=True)\n",
        "  df_s=df_s.astype(settings_convert_dict, errors='raise')\n",
        "  df_d=df_d.astype(data_convert_dict, errors='raise')\n",
        "\n",
        "  #df_d = ResolveMidnightDateIssue (df_d) \n",
        "\n",
        "#  df_d[\"Data Date-Time\"]=pd.to_datetime(df_d[\"Data Date-Time\"],format='%d/%m/%y %H:%M:%S')\n",
        "\n",
        "  # For Settings Table delete the confusing default numbers left in place when \"preset\" condition is on.\n",
        "# \n",
        "  df_s = DeleteThresholdsForRowsUsingPresetConditions(df_s)\n",
        "  df_s, df_d = addSettingsIndex (df_s,df_d)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "_jiazNDlz1Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fecaaa2-2a70-4f3a-d0f8-6a3a66f71e6f"
      },
      "id": "_jiazNDlz1Dp",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.8 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XH-EgNxkPi",
        "outputId": "40a61de6-27fa-4906-a49d-a8ae5e181d4a"
      },
      "id": "T9XH-EgNxkPi",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 38.1 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It was observed with Zug that for the first ~30 seconds after midnight, the date does not change. This needs to be fixed or \"smoothed\" with the code below.\n",
        "#import calendar\n",
        "\n",
        "#### This function is not finished.\n",
        "def ResolveMidnightDateIssue (df_above):\n",
        "  print (\"in the smooth\")\n",
        "  df_diff = pd.DataFrame ()\n",
        "  df_below = pd.DataFrame ()\n",
        "\n",
        "  df_below[\"Data Date-Time\"] = df_above[\"Data Date-Time\"].shift (periods=1, fill_value=0)\n",
        "  #df_below[\"Data Date\"] = df_above[\"Data Date\"].shift (periods=1, fill_value=0)\n",
        "  df_below [\"Date Diff\"] = df_above[\"Data Date-Time\"] < df_below[\"Data Date-Time\"]\n",
        "  df_below [\"Date Diff Num\"] = (df_above[\"Data Date-Time\"] - df_below[\"Data Date-Time\"]).dt.total_seconds()\n",
        "  print (df_below [\"Date Diff Num\"].dtype)\n",
        "  \n",
        "\n",
        "  # display(df_above)\n",
        "  # display(df_below)\n",
        "  # display (df_below[df_below[\"Date Diff\"]==1])\n",
        "  df_midnight_bounds = df_below[df_below[\"Date Diff Num\"].abs()>1000]\n",
        "  #display (df_midnight_bounds)\n",
        "  # for i in df_midnight_bounds.index:\n",
        "  #   print (i)\n",
        "\n",
        "\n",
        "\n",
        "  #display (df_below[df_below[\"Date Diff Num\"]!=1])\n",
        "  \n",
        "  print (\"Sum is: \" + df_below[\"Date Diff\"].astype(int).sum().astype(str))\n",
        "  \n",
        "  return df_above\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2noyZAXZNuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e98b58b-976f-424e-f8f3-eeb37f34b7c6"
      },
      "id": "J2noyZAXZNuk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.42 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def addSettingsIndex (df_s,df_d):\n",
        "  #df_s[\"Settings Index\"] = np.arange(len(df_s))\n",
        "  df_s.insert(loc=0, column=\"Settings Index\", value=np.arange(len(df_s))+1)\n",
        "  df_d = pd.merge_asof (df_d,df_s[\"Settings Index\"],left_index=True, right_index=True)\n",
        "  SettingsIndexCol = df_d.pop('Settings Index')\n",
        "  df_d.insert(0, 'Settings Index', SettingsIndexCol)\n",
        "  \n",
        "  return df_s, df_d"
      ],
      "metadata": {
        "id": "SeN4pRpcmoTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b809ff63-20c5-4760-e200-66b48bb2565c"
      },
      "id": "SeN4pRpcmoTt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.64 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48ad95b-57b9-4571-e749-39a8e6a4b839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.59 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def DeleteThresholdsForRowsUsingPresetConditions (settings_table):\n",
        "    # display(settings_table)\n",
        "    for ind in settings_table.index:\n",
        "        if settings_table[\"Preset mode\"][ind] == 1:\n",
        "            settings_table[\"SPO2 Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"HR Threshold\"][ind] = np.NaN\n",
        "            settings_table[\"AND/OR\"][ind] = np.NaN\n",
        "            settings_table[\"Duration\"][ind] = np.NaN\n",
        "                       #Preset mode\tSPO2 Threshold\tHR Threshold\tAND/OR\tDuration\n",
        "    return settings_table\n"
      ],
      "id": "a827d79e-1ed4-4735-906a-fa76fd32f9ba"
    },
    {
      "cell_type": "code",
      "source": [
        "# Send an unformatted clinical data column and returns a date-time column\n",
        "def getDateTimeColumn (df):\n",
        "    df2 = pd.DataFrame ()\n",
        "    df[df. columns[0]] = df[df. columns[0]].str.replace('/',' ').str.replace('-',' ').str.replace(':',' ')\n",
        "    \n",
        "    df[['Day','Month','Year','Hour','Minute','Second']] = df[df. columns[0]].str.split(expand = True)\n",
        "    df = df.drop([df. columns[0]], axis=1)\n",
        "    df=df.astype(int)\n",
        "    \n",
        "    df['Year'].where(df[\"Year\"] > 2000, other = df[\"Year\"] + 2000, inplace = True)\n",
        "    \n",
        "    df2['Datetime'] = pd.to_datetime(df[['Day','Month','Year','Hour','Minute','Second']])\n",
        "    return df2\n",
        "\n",
        "# dftest = pd.DataFrame ()\n",
        "# getDateTimeColumn (dftest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPPshOYtN8Aq",
        "outputId": "3ddb2074-ec22-4de3-839b-ecf3764c2d6b"
      },
      "id": "zPPshOYtN8Aq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.93 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dPG9_2xoX3"
      },
      "source": [
        "## **Analyze Thresholds**"
      ],
      "id": "T3dPG9_2xoX3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Only Valid Data\n",
        "This filters data based on device status. "
      ],
      "metadata": {
        "id": "YxecqEFREEhV"
      },
      "id": "YxecqEFREEhV"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04830af-e316-4579-aba9-51afd15efb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.4 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def GetIsValidColumn (df):\n",
        "    is_valid = pd.DataFrame ()\n",
        "    is_valid [\"valid_vitals\"] = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff) & (df[\"HR\"] !=255) & (df[\"SPO2\"] !=127))\n",
        "    # print (\"Num IsValid Vitals True:\")\n",
        "    # print (is_valid[\"valid_vitals\"].sum())\n",
        "    # print (is_valid [\"valid_vitals\"])\n",
        "    # is_valid['valid_vitals'].value_counts()\n",
        "    # print (\"num valid vitals: \" + is_valid [is_valid[\"valid_vitals\"]==True].count)\n",
        "\n",
        "    # Determine if status scale is 0-6 or 0-255...\n",
        "    max_status = df[\"Status\"].max()\n",
        "    # print (\"about to check valid_status\")\n",
        "    # display (df)\n",
        "    # if (AB_Model == \"M1\"):\n",
        "    if (max_status < 7):\n",
        "        # print (\"eval status for 0-6 status\")\n",
        "        is_valid [\"valid_status\"] = (df['Status'] == 0);\n",
        "    elif (max_status >= 7):\n",
        "        # print (\"eval status for 0-255 status\")\n",
        "        is_valid [\"valid_status\"] = ((df['Status'] == 129) | (df['Status'] == 131));  \n",
        "    \n",
        "    # print (\"Num IsValid Status True:\")\n",
        "    # print (is_valid[\"valid_status\"].sum())\n",
        "    \n",
        "    is_valid['Is_Valid_Data'] = np.where((is_valid['valid_status'] == True) & (is_valid[\"valid_vitals\"] == True), True, False)\n",
        "    # is_valid [\"Is_Valid_Data\"] = ((is_valid['valid_vitals'] == True) & (is_valid ['valid_status'] == True))\n",
        "    # is_valid['Is_Valid_Data'].value_counts()\n",
        "    # print (\"Num IsValid True:\")\n",
        "    # print (is_valid[\"Is_Valid_Data\"].sum())\n",
        "    return is_valid [\"Is_Valid_Data\"]\n",
        "\n",
        "\n"
      ],
      "id": "bbd083b1-063d-4dd4-9ee4-c330e1b991e8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Against Custom Thresholds\n",
        "This function returns what is expected in the custom mode the user selected. It should match with actual stimulations in custom mode."
      ],
      "metadata": {
        "id": "dm2RieFwTAjS"
      },
      "id": "dm2RieFwTAjS"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfc40d1-4401-4e53-e839-a319b08ce98c",
        "id": "pndZJ_WATAja"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "def AnalyzeWithCustomThresholds (df):\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  is_below_threshold_AND = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) & (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< df[\"SPO2 Threshold\"]) | (df[\"HR\"]< df[\"HR Threshold\"]))\n",
        "  is_below_threshold_result = (df[\"AND/OR\"]==0)*is_below_threshold_OR + (df[\"AND/OR\"]==1)*is_below_threshold_AND\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= df[\"Duration\"],0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "\n",
        "  df[Duration_Custom] = df_unmasked.mask(df_unmasked <= df[\"Duration\"],0)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "id": "pndZJ_WATAja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze With Preset Thresholds\n",
        "This function is useful to see how the system would have performed if it were operating in preset mode."
      ],
      "metadata": {
        "id": "c9pqOw4FnVYA"
      },
      "id": "c9pqOw4FnVYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "SPO2_threshold_AND_condition = 85\n",
        "HR_threshold_AND_condition = 100\n",
        "SP02_threshold_OR_condition = 75\n",
        "HR_threshold_OR_condition  = 90\n",
        "Preset_Mode_Duration = 5\n",
        "\n",
        "def AnalyzeWithPresetThresholds (df):\n",
        "  \n",
        "#   orubt (\"started\")\n",
        "#   is_valid = ((df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff) & (df[\"HR\"]>Data_Cleanup_HR_LowCutOff))\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "#   is_valid[\"\"] = df['Is_Valid_Data']\n",
        "#   print (\"in Analyze with Preset Thresholds\")\n",
        "#   is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "#   is_below_threshold_OR = is_valid & ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "\n",
        "  is_below_threshold_AND = df['Is_Valid_Data'] & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  is_below_threshold_OR = df['Is_Valid_Data']& ((df[\"SPO2\"]< SP02_threshold_OR_condition) | (df[\"HR\"]< HR_threshold_OR_condition))\n",
        "\n",
        "  # is_below_threshold_result = ((df[\"AND/OR\"]==0))&(is_below_threshold_OR) | ((df[\"AND/OR\"]==1) &is_below_threshold_AND)\n",
        "  is_below_threshold_result = is_below_threshold_OR | is_below_threshold_AND\n",
        "  #print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "#   display (is_below_threshold_result)\n",
        "  # is_below_threshold_result = is_below_threshold_result.mask (is_below_threshold_result <= Preset_Mode_Duration,0) #This statement removes any apnea durations that are below the threshold at that row where the apnea started.\n",
        "  # print (\"Sum is:\" + str(sum(is_below_threshold_result)))\n",
        "\n",
        "  # print (\"Total preset results are: \" + str(is_below_threshold_result.sum()))\n",
        "  df_unmasked = calcDurationsCrossedThreshold(pd.DataFrame(is_below_threshold_result))\n",
        "  df[Duration_Preset] = df_unmasked.mask(df_unmasked <= Preset_Mode_Duration,0)\n",
        "#   print (\"finished Analyze with Preset Thresholds\")\n",
        "  #print (\"Sum is:\" + str(sum(df[Duration_Preset])))\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "NFGvMndV_NLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c695a692-7a27-41ef-d4be-fcc1c454bb16"
      },
      "id": "NFGvMndV_NLH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.48 ms (started: 2023-03-27 16:26:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Actual Stimulations\n",
        "This function looks at Stim Off/On field and counts the apnea durations (assuming SPO2 & HR are not 0). It does not consider the Preset/Custom settings at all. "
      ],
      "metadata": {
        "id": "Ff704C-MwEsw"
      },
      "id": "Ff704C-MwEsw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Assumes it is being passed df_j\n",
        "def AddNumActualStimulations (df):\n",
        "  \n",
        "#   Valid_Stimulations = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]>Data_Cleanup_SP02_LowCutOff)*(df[\"HR\"]>Data_Cleanup_HR_LowCutOff)\n",
        "#   is_valid = GetIsValidColumn (df)\n",
        "  Valid_Stimulations = df[\"Stimulator ON/OFF\"]*is_valid\n",
        "  df[Duration_Actual] = calcDurationsCrossedThreshold(pd.DataFrame(Valid_Stimulations))\n",
        "   \n",
        "  ## New code (22-07-23) - I later realized that with the new apnea duration counter, we don't need to \"Stimulation started column\" as it easily puts the apnea duration time where the stimulation started. \n",
        "  # df[\"Stimulator ON/OFF with Valid SPO2/HR\"] = df[\"Stimulator ON/OFF\"]*(df[\"SPO2\"]!=0)*(df[\"HR\"]!=0) \n",
        "\n",
        "  # df_previousrow = df.shift(periods=1)\n",
        "  # isStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF with Valid SPO2/HR\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF with Valid SPO2/HR\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0)\n",
        "  #                         )  # This condition was added because there are some odd cases where the stimulator turns when HR/SPO2 are 0...\n",
        "\n",
        "  #This gives 408 rows, but the one above gives 411 rows. There are likely some times then the O2 or HR jumps to zero mid apnea but jumps back up and the stimulator is on the whole time? \n",
        "  # OldisStimulationStarted = (\n",
        "  #                         (df[\"Stimulator ON/OFF\"]==1) & \n",
        "  #                         (df_previousrow[\"Stimulator ON/OFF\"] == 0) &\n",
        "  #                         (df[\"SPO2\"]!=0) & \n",
        "  #                         (df[\"HR\"]!=0))\n",
        "\n",
        "  #Should be 408 Rows\n",
        "  \n",
        "  # df[\"Stimulation Triggered (Actual Stimulator ON Triggered)\"] = isStimulationStarted\n",
        "  # df[\"Actual - Stimulation Durations (s)\"] = calcDurationsCrossedThreshold(pd.DataFrame(df[\"Stimulator ON/OFF with Valid SPO2/HR\"]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "CI2GKzN15PZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3185e412-1c25-4921-ff1e-db3061c3e805"
      },
      "id": "CI2GKzN15PZJ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.41 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Cross Duration\n",
        "This takes an array of \"threshold crossed\" or \"stimulation on\" (0,0,0,1,1,1,1,0..etc) and returns an array with the time in the first place the threshold is cross i.e. (0,0,0,4,0,0,0,0...)"
      ],
      "metadata": {
        "id": "4C39qoDxEcnt"
      },
      "id": "4C39qoDxEcnt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Input: A df with 0s and 1s representing cross thresholds\n",
        "# see this -  https://stackoverflow.com/questions/62615666/how-to-sum-variable-ranges-in-a-pandas-column-to-another-column\n",
        "def calcDurationsCrossedThreshold (df):\n",
        "  \n",
        "  df = df.iloc[::-1]\n",
        "  a = df.iloc[:,0]==0\n",
        "  blocks = a.cumsum()\n",
        "  \n",
        "  m = blocks.duplicated(keep='last')\n",
        "  \n",
        "  df['Sum'] = df.iloc[:,0].groupby(blocks).cumsum().mask(m)\n",
        "  df = df.iloc[::-1]\n",
        "  df_return = df ['Sum'].fillna(0)\n",
        "  return df_return"
      ],
      "metadata": {
        "id": "HIOGli41rAgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a710f2-a715-4c49-ef00-c5b359128671"
      },
      "id": "HIOGli41rAgo",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.84 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Summary Tables**"
      ],
      "metadata": {
        "id": "vFvsiREGpJ-8"
      },
      "id": "vFvsiREGpJ-8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportApneaCountBySetting (df,df_s):\n",
        "  table = pd.pivot_table (df, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='sum')\n",
        "#   display (table)\n",
        "  table = table.rename (columns = {Duration_Actual:SumDuration_Actual, Duration_Preset:SumDuration_Preset, Duration_Custom:SumDuration_Preset})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "  \n",
        "\n",
        "  #Count function counts zeros too, so need to replace zeros with NAs for this to work.\n",
        "  df_nan = df.mask(df==0) # This will make all zeros into Nan\n",
        "  table = pd.pivot_table (df_nan, values = [Duration_Actual, Duration_Preset, Duration_Custom],\n",
        "                          index = \"Settings Index\",\n",
        "                          aggfunc='count')\n",
        "  \n",
        "  table = table.rename (columns = {Duration_Actual:Count_Actual, Duration_Preset:Count_Preset, Duration_Custom:Count_Custom})\n",
        "  df_s=df_s.join(table, on=\"Settings Index\")\n",
        "#   display (df_s)\n",
        "  \n",
        "  if (PRINT_TABLES == True):\n",
        "    df_s.to_excel (folder_name + \" - Summary of Events.xlsx\")\n",
        "    dataframe_to_pdf(df_s, folder_name + \" - Apnea Count By Setting\")\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McI1Xwv81qIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd88783b-4bad-40b1-f688-e1ad141a8176"
      },
      "id": "McI1Xwv81qIh",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.73 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def reportIndividualActualApneas (df):\n",
        "  table_A = df[df[Duration_Actual]!=0]\n",
        "  table_P = df[df[Duration_Preset]!=0]\n",
        "  table_C = df[df[Duration_Custom]!=0]\n",
        "  table_A_P = df[ (df[\"Preset mode\"]==1 & (df[Duration_Actual]!=df[Duration_Preset]))]\n",
        "  table_A_C = df[ (df[\"Preset mode\"]==0 & (df[Duration_Actual]!=df[Duration_Custom]))]\n",
        "                   \n",
        "  if (PRINT_TABLES == True):\n",
        "    with pd.ExcelWriter(folder_name + \" - Individual Events.xlsx\") as writer:\n",
        "        table_A.to_excel (writer, sheet_name=\"Actual\")\n",
        "        table_P.to_excel (writer, sheet_name=\"Preset\")\n",
        "        table_C.to_excel (writer, sheet_name=\"Custom\")\n",
        "        table_A_P.to_excel (writer, sheet_name=\"Actual-Preset Discrepancy\")\n",
        "        table_A_C.to_excel (writer, sheet_name=\"Actual-Custom Discrepancey\")\n",
        "\n",
        "    dataframe_to_pdf(table_A, folder_name + \" - Individual Events (Actual)\")\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "IbdRSJx_MgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d459df5-d812-4f0e-bbf0-66b7eccd7db4"
      },
      "id": "IbdRSJx_MgxZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.6 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def countApneas (df):\n",
        "   df_nan = df.mask(df==0)\n",
        "   count = np.sum(df_nan.count())\n",
        "   print (\"Num Apneas is:\" + str(count))\n",
        "   return count\n",
        "\n",
        "def sumApneaTime (df):\n",
        "    # print (\"sumApneaTime-start\")\n",
        "    # sum = df.sum(df[df.columns[0]])\n",
        "    sum = df.sum()\n",
        "    print (\"Sum Apnea Time is:\" + str (sum))\n",
        "    return sum\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SvGB35kvb-z",
        "outputId": "331b3d5f-d953-445f-dc76-a56c8083c5fd"
      },
      "id": "4SvGB35kvb-z",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.07 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def convertDataframeToFigure (df):\n",
        "#   display (df)\n",
        "  fig, ax =plt.subplots(figsize =(20,20))\n",
        "  #fig, ax =plt.subplots(figsize=(len(df),len(df.columns)))\n",
        "  ax.axis('tight')\n",
        "  ax.axis('off')\n",
        "  the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "  return fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qxv3-8-3lsTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1926da1-6785-48aa-be7e-243f7654beee"
      },
      "id": "Qxv3-8-3lsTZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.89 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ## Print Tables to PDF **\n",
        "This code enables printing tables to pdf."
      ],
      "metadata": {
        "id": "Sb6hldAxxaXX"
      },
      "id": "Sb6hldAxxaXX"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import textwrap as twp\n",
        "\n",
        "# #create column headers with long text and apply textwrap with \\n after defined lenght\n",
        "# columns=[twp.fill('this is a long column header text',25), twp.fill('...and this is an even longer column header text',25)]\n",
        "\n",
        "# https://predictivehacks.com/?all-tips=save-a-pandas-dataframe-as-an-image\n",
        "# pip install dataframe-image\n",
        "# import pandas as pd\n",
        "# import dataframe_image as dfi\n",
        " \n",
        "# dfi.export(df, 'dataframe.png')\n",
        "\n",
        "def _draw_as_table(df, pagesize):\n",
        "    alternating_colors = [['white'] * len(df.columns), ['lightgray'] * len(df.columns)] * len(df)\n",
        "    alternating_colors = alternating_colors[:len(df)]\n",
        "    fig, ax = plt.subplots(figsize=pagesize)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    # df=df.to_string(line_width=5)\n",
        "    # .str.wrap(5)\n",
        "    col_headers=list(df.columns.str.wrap(15)) #df.columns#.map(\"str\")\n",
        "    #display (col_headers)\n",
        "    #print (\"Cols is \" + len(df[0]))\n",
        "    #display (df)\n",
        "    the_table = ax.table(cellText=df.values,\n",
        "                        rowLabels=df.index,\n",
        "                        colLabels=col_headers,\n",
        "                        #colLabels=df.columns,\n",
        "                        rowColours=['lightblue']*len(df),\n",
        "                        colColours=['lightblue']*len(df.columns),\n",
        "                        cellColours=alternating_colors,\n",
        "                        loc='center')\n",
        "    the_table.auto_set_column_width(col=list(range(len(df.columns)))) # Provide integer list of columns to adjust\n",
        "\n",
        "    # the_table.auto_set_font_size(False)\n",
        "    # the_table.set_fontsize(12)\n",
        "    return fig\n",
        "  \n",
        "\n",
        "def dataframe_to_pdf(df, filename, numpages=(1, 1), pagesize=(11, 8.5)):\n",
        "  with PdfPages(filename) as pdf:\n",
        "    # display (df)\n",
        "    # nh, nv = numpages\n",
        "    # rows_per_page = len(df) // nh\n",
        "    # cols_per_page = len(df.columns) // nv\n",
        "\n",
        "    # nh, nv = numpages\n",
        "    rows_per_page = 30\n",
        "    cols_per_page = len(df.columns)\n",
        "    nv = 1\n",
        "    \n",
        "    if len(df) % rows_per_page == 0: \n",
        "      nh = int(len(df) / rows_per_page)\n",
        "    else:\n",
        "      nh = int(len(df) / rows_per_page) +1\n",
        "    \n",
        "    # print ('num cols is ' + str(len(df.columns)))\n",
        "    # print ('num rows is ' + str(len(df)) + \"nv is \" + str(nv))\n",
        "\n",
        "    for i in range(0, nh):\n",
        "        for j in range(0, nv):\n",
        "            # print (\"i is \" + str(i) + \"and j is \" + str(j))\n",
        "            page = df.iloc[(i*rows_per_page):min((i+1)*rows_per_page, len(df)),\n",
        "                           (j*cols_per_page):min((j+1)*cols_per_page, len(df.columns))]\n",
        "            # display (page)\n",
        "            fig = _draw_as_table(page, pagesize)\n",
        "            if nh > 1 or nv > 1:\n",
        "                # Add a part/page number at bottom-center of page\n",
        "                fig.text(0.5, 0.5/pagesize[0],\n",
        "                         \"Part-{}x{}: Page-{}\".format(i+1, j+1, i*nv + j + 1),\n",
        "                         ha='center', fontsize=8)\n",
        "            \n",
        "            pdf.savefig(fig, bbox_inches='tight')\n",
        "            # plt.show ()\n",
        "            plt.close()\n"
      ],
      "metadata": {
        "id": "BQDht-5kNQpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078aadfd-60da-465a-9992-ffa72b1d8ce3"
      },
      "id": "BQDht-5kNQpD",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 674 ms (started: 2023-03-27 16:26:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AZp6q5Z8Aq"
      },
      "source": [
        "## **Plots**"
      ],
      "id": "X_AZp6q5Z8Aq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot AB Data"
      ],
      "metadata": {
        "id": "1uadoNfrjZUt"
      },
      "id": "1uadoNfrjZUt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotApneBootData (df,plot_title,x_axis_start,x_axis_end):\n",
        "    #display (df)\n",
        "    \n",
        "    f, (ax, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 1]})\n",
        "\n",
        "    ax2 = df.plot(x=\"Data Date-Time\", y=\"Status\", rot=0,ax=ax2)\n",
        "    \n",
        "    plotSPO2AndHR(df,plot_title,x_axis_start,x_axis_end,ax)\n",
        "       \n",
        "    f.tight_layout()\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xxrNme8yvvkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e191bf8-9871-45c4-df40-dad94fb2ab38"
      },
      "id": "xxrNme8yvvkW",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.9 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "#@title\n",
        "def plotSPO2AndHR (df,plot_title,x_axis_start,x_axis_end,ax):\n",
        "  plot_type = 'scatter'\n",
        "  \n",
        "#   Setup plots to show which data is valid and invalid.\n",
        "  df_invalid = df [df[\"Is_Valid_Data\"]==0]\n",
        "  df = df [df[\"Is_Valid_Data\"]==1]\n",
        "  \n",
        "#   This is y value to show for these.\n",
        "  df_invalid['Is_Valid_Data'] = 43\n",
        "  df[\"Stimulator ON/OFF Plot\"] = df[\"Stimulator ON/OFF\"]*20\n",
        "\n",
        "  ax = df.plot(x=\"Data Date-Time\", y=\"SPO2\", \n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            rot=0,\n",
        "                            color = 'orangered',\n",
        "                            label = \"SPO2 Valid\",\n",
        "                            linewidth=1, \n",
        "                            kind = plot_type,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df.plot(x=\"Data Date-Time\", y=\"HR\", \n",
        "                          color = 'cornflowerblue',\n",
        "                          label = \"HR Valid\",\n",
        "                          linewidth=1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "  \n",
        "  df.plot.line(x=\"Data Date-Time\", y=\"Stimulator ON/OFF Plot\", \n",
        "                          linewidth=4,\n",
        "                          alpha=0.2,\n",
        "                          color = 'Orange',\n",
        "                          label = \"Stim ON\",\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax)\n",
        "                          \n",
        "  df_t = getThresholdTable (df)\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"SPO2 Threshold\", \n",
        "                          color = 'DarkRed',\n",
        "                          label = \"SPO2 Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dashed',\n",
        "                          alpha=0.2,\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  \n",
        "  df_t.plot.line(x=\"Data Date-Time\", y=\"HR Threshold\", \n",
        "                          color = 'DarkBlue',\n",
        "                          label = \"HR Threshold\",\n",
        "                          linewidth=3,\n",
        "                          linestyle='dotted',\n",
        "                          alpha=0.2,\n",
        "                        #   kind = plot_type,\n",
        "                          ax=ax\n",
        "                          )\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y=\"SPO2\", \n",
        "                            figsize=(30,20),\n",
        "                            title = plot_title,\n",
        "                            ylim=(-5,150),\n",
        "                            xlim= (x_axis_start, x_axis_end),\n",
        "                            grid=True,\n",
        "                            rot=0,\n",
        "                            c = 'maroon',\n",
        "                            s = 1,\n",
        "                            # color = 'black',\n",
        "                            label = \"SPO2 Invalid\",\n",
        "                            linewidth=1, \n",
        "                            kind = plot_type,\n",
        "                            ax=ax)\n",
        "    #ax.grid()\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y=\"HR\", \n",
        "                        #   color = 'black',\n",
        "                          c = 'midnightblue',\n",
        "                          label = \"HR Invalid\",\n",
        "                          linewidth=1,\n",
        "                           s = 1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "  df_invalid.plot(x=\"Data Date-Time\", y='Is_Valid_Data', \n",
        "                        #   color = 'black',\n",
        "                          c = 'black',\n",
        "                          label = \"Data Invalid\",\n",
        "                          linewidth=1,\n",
        "                           s = 1,\n",
        "                          kind = plot_type,\n",
        "                          ax=ax)\n",
        "\n",
        "  \n",
        "  x_offset = (x_axis_end - x_axis_start)/10\n",
        "  df_a = df[(df[Duration_Preset] > 0)]\n",
        "  df_a=df_a.reset_index(drop=True)\n",
        "  df_a[\"Arrow Offet\"] = df_a[\"Data Date-Time\"] - x_offset\n",
        "\n",
        "  for ind in df_a.index:\n",
        "    if df_a[\"Arrow Offet\"][ind] <= x_axis_start:\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than \" + str(x_axis_start))\n",
        "    #   print (str(df_a[\"Arrow Offet\"][ind]) + \"is less than\" + str(x_axis_start)) \n",
        "      df_a[\"Arrow Offet\"][ind] = df_a[\"Arrow Offet\"][ind] + x_offset*2\n",
        "    #   print (\"and the arrow didn't fit in the screen so we replace with: \" + str(df_a[\"Arrow Offet\"][ind]))\n",
        "    #print (ind)\n",
        "    # ax.annotate(\"Event For \" + df_a[Duration_Actual][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "    #         xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "    #         fontsize = 10, \n",
        "    #         xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "    #         arrowprops = dict(facecolor = 'yellow'),\n",
        "    #         color = 'black',\n",
        "    #         backgroundcolor='white')\n",
        "\n",
        "    ax.annotate(\"Event For \" + df_a[Duration_Preset][ind].astype(int).astype(str) + 's\\n' + df_a[\"Data Date-Time\"][ind].strftime('%Y-%m-%d %X') + '\\n SPO2:' + df_a[\"SPO2\"][ind].astype(str) + \" HR:\" + df_a[\"HR\"][ind].astype(str),\n",
        "            xy = (df_a[\"Data Date-Time\"][ind], df_a[\"SPO2\"][ind]), \n",
        "            fontsize = 10, \n",
        "            xytext = (df_a[\"Data Date-Time\"][ind] - x_offset, ind%4*15+20), \n",
        "            arrowprops = dict(facecolor = 'yellow'),\n",
        "            color = 'black',\n",
        "            backgroundcolor='white')\n",
        "\n",
        "  del df\n",
        "  del df_invalid\n",
        "  gc.collect()\n",
        "  ax.grid('on', which='major')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "br-rk3f9_P2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e041ca-4112-4cc2-beff-d03fd48e2195"
      },
      "id": "br-rk3f9_P2G",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.5 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Threshold Table"
      ],
      "metadata": {
        "id": "qYEzi3M-S0K6"
      },
      "id": "qYEzi3M-S0K6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def getThresholdTable (df):\n",
        "  SPO2_threshold_AND_condition = 85\n",
        "  HR_threshold_AND_condition = 100\n",
        "  SP02_threshold_OR_condition = 75\n",
        "  HR_threshold_OR_condition  = 90\n",
        "  Preset_Mode_Duration = 5\n",
        "\n",
        "  df_t = pd.DataFrame()\n",
        "  #df_t = df\n",
        "  # df_t [\"HR Threshold\"] = 60\n",
        "  # df_t [\"SPO2 Threshold\"] = 64\n",
        "  df_t [\"Data Date-Time\"] = df[\"Data Date-Time\"]\n",
        "  df_t [\"HR Threshold\"] = df[\"Preset mode\"]*HR_threshold_OR_condition\n",
        "  df_t [\"SPO2 Threshold\"] = df[\"Preset mode\"]*SP02_threshold_OR_condition\n",
        "  df_t[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]=df[\"HR Threshold\"][df_t[\"HR Threshold\"]==0]\n",
        "  df_t[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]=df[\"SPO2 Threshold\"][df_t[\"SPO2 Threshold\"]==0]\n",
        "\n",
        "  # df_t [\"HR Custom\"] = df[\"HR Threshold\"]\n",
        "  # df[\"SPO2 Threshold\"].notna().astype(int)*df[\"SPO2 Threshold\"]\n",
        "  # display (df_t)\n",
        "\n",
        "  #is_below_threshold_AND = is_valid & ((df[\"SPO2\"] < SPO2_threshold_AND_condition) & (df[\"HR\"]< HR_threshold_AND_condition))\n",
        "  \n",
        "  #print (\"df_t is: \")\n",
        "  #display (df_t)\n",
        "\n",
        "  return df_t"
      ],
      "metadata": {
        "id": "oDhFqjhBjY20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7196d49-f698-482d-9d3b-59b04d702123"
      },
      "id": "oDhFqjhBjY20",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.5 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot by Day"
      ],
      "metadata": {
        "id": "bHJA2jljjdc-"
      },
      "id": "bHJA2jljjdc-"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2ea3a1SQZLQB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91415a92-0444-44e6-8b2f-c4490873ed40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.86 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_plot=df_j\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "def plotByDay (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    df[\"Data Date\"] = df[\"Data Date-Time\"].dt.date\n",
        "    # df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    length = len(date_list)\n",
        "    print (\"Number of days is\" + str(length))\n",
        "    print (\"Working on / free mem: \")\n",
        "    fname = folder_name + ' plot_by_day.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "        for i in range(length):\n",
        "          print (str(i), end = ' / ')\n",
        "          !free -h --si | awk  '/Mem:/{print $4} '\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "          \n",
        "          # x axis start and end\n",
        "          x_axis_start = current_date.replace(second = 1)\n",
        "          #print(x_axis_start)\n",
        "          x_axis_end = current_date.replace(hour = 23, minute=59, second = 59)\n",
        "          \n",
        "          \n",
        "          ##### Sept 7 - Not sure if this below has to be commented or fixed\n",
        "          # df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"].astype(str)).dt.time\n",
        "          # #df_current_date[\"Data Time\"] = pd.to_datetime(df_current_date[\"Data Time\"])\n",
        "        #   df_current_date[\"Data Time\"] = df_current_date[\"Data Time\"].dt.time\n",
        "          \n",
        "          df_current_date[\"Data Time\"] = df_current_date[\"Data Date-Time\"].dt.time\n",
        "          df_current_date.set_index('Data Time')\n",
        "          #display(df_current_date.dtypes)\n",
        "          #display (df_current_date)\n",
        "          \n",
        "          plotApneBootData (df_current_date,current_date_64,x_axis_start,x_axis_end)\n",
        "          pdf.savefig()\n",
        "          plt.close()\n",
        "          del df_current_date\n",
        "          gc.collect()\n",
        "          \n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "2ea3a1SQZLQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot By Hour"
      ],
      "metadata": {
        "id": "eoiLSOJ3jfmj"
      },
      "id": "eoiLSOJ3jfmj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plotByHour (df):\n",
        "    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n",
        "    formatter = mdates.ConciseDateFormatter(locator)\n",
        "\n",
        "    # df[\"Data Date\"] = pd.to_datetime(df[\"Data Date\"])\n",
        "    # df[\"Data Time\"] = pd.to_datetime(df[\"Data Time\"])\n",
        "    # df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "\n",
        "    df[\"Data Date\"] = df[\"Data Date-Time\"].dt.date\n",
        "    df[\"Data Time\"] = df[\"Data Date-Time\"].dt.date\n",
        "    df[\"Data Time-Hour\"] = df[\"Data Date-Time\"].dt.hour\n",
        "\n",
        "    # display(df)\n",
        "    # return\n",
        "    date_list = np.unique(df[\"Data Date\"])\n",
        "    date_length = len(date_list)\n",
        "    fname = folder_name + ' plot_by_hour.pdf'\n",
        "    with PdfPages(fname) as pdf:\n",
        "\n",
        "        firstPage = plt.figure(figsize=(11.69,8.27))\n",
        "        firstPage.clf()\n",
        "        txt = 'This is the title page'\n",
        "        firstPage.text(0.5,0.5,txt, transform=firstPage.transFigure, size=24, ha=\"center\")\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "\n",
        "        for i in range(date_length):\n",
        "          current_date_64 = date_list[i]\n",
        "          current_date=pd.to_datetime(current_date_64)\n",
        "          \n",
        "          # Create a dataframe of only one date\n",
        "          df_current_date = df[(df[\"Data Date\"] == current_date)]\n",
        "          #display(df_current_date)\n",
        "      \n",
        "          hour_list = np.unique(df_current_date[\"Data Time-Hour\"])\n",
        "          hour_length = len(hour_list)\n",
        "          #print (hour_list)\n",
        "\n",
        "          for j in range(hour_length):\n",
        "              current_hour_64 = hour_list[j]\n",
        "              #current_date=pd.to_datetime(current_date_64)\n",
        "              df_current_hour = df_current_date[(df_current_date[\"Data Time-Hour\"]==current_hour_64)]\n",
        "              x_start = current_date + pd.offsets.Hour(current_hour_64)\n",
        "              x_end = current_date + pd.offsets.Hour(current_hour_64+1)\n",
        "              df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              \n",
        "              # x_start = df_current_hour['Data Date-Time'].loc[df_current_hour.index[0]]\n",
        "              # x_end = x_start + pd.offsets.Hour()\n",
        "              title = str (current_date) + ' ' + str(x_start)\n",
        "              plotApneBootData (df_current_hour,x_start,x_start,x_end)\n",
        "              # plotApneBootData (df_current_hour,current_date,current_hour_64,current_hour_64+1)\n",
        "              pdf.savefig()\n",
        "              plt.close()\n",
        "              del df_current_hour\n",
        "              gc.collect()\n",
        "    \n",
        "    del df\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "id": "kNpgyduy7ulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da2482b-1bfb-4159-eb68-a3e99730d37a"
      },
      "id": "kNpgyduy7ulE",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.91 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubPlot Grids of Apnea Events "
      ],
      "metadata": {
        "id": "kPbeaF7WOonR"
      },
      "id": "kPbeaF7WOonR"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "### Plot multiple subplots\n",
        "\n",
        "def PlotApneaEventsGrid (df):\n",
        "  \n",
        "  start_offset = dt.timedelta (seconds=15)\n",
        "  end_offset = dt.timedelta (seconds=45)\n",
        "  num_rows = 2\n",
        "  num_cols = 2\n",
        "  num_subplots = num_rows * num_cols\n",
        "\n",
        "#   df_list_of_apnea_events = df[(df[Duration_Actual] != 0)]\n",
        "  df_list_of_apnea_events = df[(df[Duration_Preset] != 0)]\n",
        "  \n",
        "  num_events = len(df_list_of_apnea_events)\n",
        "  # print (\"div \" + str(num_events/num_subplots))\n",
        "  # print (\"div \" + str(9/4))\n",
        "  # print (\"div \" + str(np.ceil(9/4)))\n",
        "  # #num_pages = int(num_events/num_subplots + 1)\n",
        "  num_pages = int(np.ceil(num_events/num_subplots))\n",
        "  #print (\"number of pages is \" + str (num_pages))\n",
        "  #print (\"number of events is \" + str (num_events))\n",
        "  current_page = 0\n",
        "  current_event = 0\n",
        " \n",
        "  fname = folder_name + ' plot_individual_events.pdf'\n",
        "  with PdfPages(fname) as pdf:\n",
        "    for page in range (num_pages):\n",
        "      fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols)\n",
        "      # print (axes.flat)\n",
        "      for ax in axes.flat:\n",
        "        if (current_event < num_events):\n",
        "          event_time = df_list_of_apnea_events.iloc[current_event].at[\"Data Date-Time\"]\n",
        "          plot_start = event_time - start_offset\n",
        "          plot_end = event_time + end_offset\n",
        "          df_event_data = df[((df[\"Data Date-Time\"] > plot_start) & (df[\"Data Date-Time\"] < plot_end))]\n",
        "          #print (\"Current Event Index is \" + str(current_event))\n",
        "          current_event = current_event + 1\n",
        "          plot_title = folder_name + \" Event \" + str(current_event) + \":  \" + str(event_time)\n",
        "          plotSPO2AndHR (df_event_data,plot_title,plot_start,plot_end,ax)\n",
        "    #   print (\"tight layout\")\n",
        "      fig.tight_layout()\n",
        "      pdf.savefig()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "C5DBtqMI2WTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34d7681-4eb1-4344-9245-f0a97b7dbd0a"
      },
      "id": "C5DBtqMI2WTB",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.89 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4vbvlm-hsj"
      },
      "source": [
        "## **Create Tables & Plots Functions**"
      ],
      "id": "sm4vbvlm-hsj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Names"
      ],
      "metadata": {
        "id": "Y7x2w8JT2a_D"
      },
      "id": "Y7x2w8JT2a_D"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Global Variables\n",
        "### Column Names\n",
        "Duration_Actual = \"Event Duration (s) [Actual Data]\"\n",
        "Duration_Custom = \"Event Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "Duration_Preset = \"Event Duration (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "Count_Actual = \"Event Count [Actual Data]\"\n",
        "Count_Custom = \"Event Count [Using Custom Settings - Theoretical Calculation]\"\n",
        "Count_Preset = \"Event Count (s) [Using Preset Settings - Theoretical Calculation]\"\n",
        "\n",
        "SumDuration_Actual = \"Cumulative Duration (s) [Actual Data]\"\n",
        "SumDuration_Custom = \"Cumulative Duration (s) [Using Custom Settings - Theoretical Calculation]\"\n",
        "SumDuration_Preset = \"Cumulative Duration (s) [Using Preset Settings - Theoretical Calculation]\""
      ],
      "metadata": {
        "id": "CgzuYBvt8zNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b530ea7-6e0b-4d87-ce2c-cb8a79ccddab"
      },
      "id": "CgzuYBvt8zNI",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.49 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Tables"
      ],
      "metadata": {
        "id": "mcXFuo902gfD"
      },
      "id": "mcXFuo902gfD"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vsIRg70SdobY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf20b71-2aff-4731-b4b2-164c2ed20903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.54 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def createDataTables (data_path):\n",
        "    df_LOGs = compileLogFiles (data_path)\n",
        "\n",
        "    df_s, df_d = splitToDataAndSettingsDF (df_LOGs)\n",
        "    # os.chdir(analysis_path)\n",
        "    # df_d.to_csv (folder_name + \" - Data.xlsx\")\n",
        "\n",
        "    # df_s.to_csv (folder_name + \" - Settings.xlsx\")\n",
        "    # dataframe_to_pdf(df_s, folder_name + \" - Settings\")\n",
        "\n",
        "    df_d[\"Is_Valid_Data\"] = GetIsValidColumn(df_d);\n",
        "\n",
        "    df_j = pd.merge (df_d,df_s, on='Settings Index')\n",
        "    # df_j = AddNumActualStimulations(df_j)\n",
        "    # df_j = AnalyzeWithCustomThresholds (df_j)\n",
        "    # df_j = AnalyzeWithPresetThresholds (df_j)\n",
        "    return df_j, df_d, df_s"
      ],
      "id": "vsIRg70SdobY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Plots"
      ],
      "metadata": {
        "id": "qINEVzl52lDl"
      },
      "id": "qINEVzl52lDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createPlots (df_j):\n",
        "    df_j.dtypes\n",
        "    plotByDay (df_j)\n",
        "    # plotByHour (df_j)\n",
        "    # PlotApneaEventsGrid (df_j)"
      ],
      "metadata": {
        "id": "AGgoCri491oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f715965d-0889-4f77-dbfc-a49e5616dea4"
      },
      "id": "AGgoCri491oc",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 631 µs (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Summary Tables"
      ],
      "metadata": {
        "id": "N_4X5RS92tGl"
      },
      "id": "N_4X5RS92tGl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def createSummaryTables (df,df_s):\n",
        "  \n",
        "  df_s_columns_dropped = df_s.drop(['Settings Date','Settings Time','Alarm intensity'], axis=1)\n",
        "  \n",
        "  reportApneaCountBySetting (df,df_s_columns_dropped)\n",
        "  reportIndividualActualApneas (df)"
      ],
      "metadata": {
        "id": "Ihvpi8G2ze28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8767ddd0-6f95-4aee-ebab-315d9176e3f0"
      },
      "id": "Ihvpi8G2ze28",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 717 µs (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Summary"
      ],
      "metadata": {
        "id": "c1_bNt0BWjOt"
      },
      "id": "c1_bNt0BWjOt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "spo2_list = [85, 80, 75, 70, 65]\n",
        "hr_list = [110, 100, 90, 80]\n",
        "spo2_col_time_name_list = []\n",
        "hr_col_time_name_list = []\n",
        "\n",
        "spo2_col_percent_name_list = []\n",
        "hr_col_percent_name_list = []\n",
        "\n",
        "for spo2 in spo2_list:\n",
        "    spo2_col_time_name_list.append(\"Time SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "    spo2_col_percent_name_list.append(\"% SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "for hr in hr_list:\n",
        "    hr_col_time_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "    hr_col_percent_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "        \n",
        "\n",
        "\n",
        "def createClinicalSummaryTable (df_j, record_name):\n",
        "    num_seconds_per_data_point = 1;\n",
        "    if (AB_Model == \"M1\"):\n",
        "        num_seconds_per_data_point = 2; # Tuhin's model M1 measured every 2 seconds. \n",
        "    # df_j[\"Is_Valid_Data\"] = GetIsValidColumn (df_j)\n",
        "    df_is_valid_data = df_j[df_j[\"Is_Valid_Data\"] == True]\n",
        "    df_clinical_summary = pd.DataFrame ()\n",
        "    df_clinical_summary [\"Name\"] = [record_name]\n",
        "    df_clinical_summary [\"Time ApneBoot System Was On (hrs)\"] = round (len(df_j.index) / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"Time with valid vital and status readings (hrs)\"] = round (df_j[\"Is_Valid_Data\"].sum()/60/60 * num_seconds_per_data_point,1)\n",
        "    df_clinical_summary [\"SPO2 - Avg\"] = round (df_is_valid_data['SPO2'].mean(),1)\n",
        "    df_clinical_summary [\"SPO2 - Std\"] = round (df_is_valid_data['SPO2'].std(),2)\n",
        "    df_clinical_summary [\"HR - Avg\"] = round (df_is_valid_data['HR'].mean(),1)\n",
        "    df_clinical_summary [\"HR - Std\"] = round (df_is_valid_data['HR'].std(),2)\n",
        "    df_clinical_summary ['Num Events (Preset Threshold)'] = countApneas (df_is_valid_data[Duration_Preset])\n",
        "    df_clinical_summary ['Cumulative Event Duration (Preset Threshold)'] = sumApneaTime (df_is_valid_data[Duration_Preset])\n",
        "    \n",
        "    for spo2 in spo2_list:\n",
        "        # spo2_col_time_name_list.append([\"Time SPO2 < \"+str(spo2)+\" (hrs)\"])\n",
        "        # spo2_col_percent_name_list = spo2_col_percent_name_list.append(\"% SPO2 < \"+str(spo2)+\" (hrs)\")\n",
        "        \n",
        "        df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"] = round(df_is_valid_data.query ('SPO2 < '+str(spo2))['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "        df_clinical_summary [\"% SPO2 < \"+str(spo2)+\" (hrs)\"] = round(df_clinical_summary [\"Time SPO2 < \"+str(spo2)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "    # df_clinical_summary [\"Time SPO2 < 85 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 85')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 80 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 80')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 75 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 75')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 70 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 70')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "    # df_clinical_summary [\"Time SPO2 < 65 (hrs)\"] = round(df_is_valid_data.query ('SPO2 < 65')['SPO2'].count() / 60 / 60 * num_seconds_per_data_point,1)\n",
        "\n",
        "    for hr in hr_list:\n",
        "        # hr_col_time_name_list.append([\"Time HR < \"+str(spo2)+\" (hrs)\"])\n",
        "        # hr_col_percent_name_list.append(\"Time HR < \"+str(spo2)+\" (hrs)\")\n",
        "        df_clinical_summary [\"Time HR < \"+str(spo2)+\" (hrs)\"] = round(df_is_valid_data.query ('HR < '+str(hr))['HR'].count() / 60 / 60 * num_seconds_per_data_point,1)    \n",
        "        df_clinical_summary [\"% HR < \"+str(spo2)+\" (hrs)\"] = round(df_clinical_summary [\"Time HR < \"+str(spo2)+\" (hrs)\"]/ df_clinical_summary [\"Time with valid vital and status readings (hrs)\"],3)\n",
        "\n",
        "    return df_clinical_summary\n",
        "#   df_s.insert(loc = 3, column=\"Preset mode\", value = 1)"
      ],
      "metadata": {
        "id": "uRiSHGwMw5XT",
        "outputId": "f67694ac-c062-4a71-c9fe-2dfe0f3e5903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uRiSHGwMw5XT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.31 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R0eILh2iyWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1260e2-144e-4be4-910b-9e449429e001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 427 µs (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# df_j stands for df_joined\n",
        "# display (df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"] !=0])\n",
        "#df[\"Time (hours)\"]={len(df)*1/60/60)\n",
        "# df_j.to_csv (folder_name + \" All_Data_Joined_Table.csv\")\n",
        "# df_s.to_csv (folder_name + \" Settings_Index_Table.csv\")"
      ],
      "id": "R0eILh2iyWqc"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# display(df_j[df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]==1])\n",
        "# display(df_j[df_j[\"Stimulation Triggered (New Formula for Actual Settings)\"]!= df_j[\"Stimulation Triggered (Old Formula for Actual Settings)\"]])\n",
        "# display(df_j[df_j[\"Preset Threshold - Apnea Duration (s)\"]==0])"
      ],
      "metadata": {
        "id": "k7sHLvRYA10J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a84532-28a5-494f-a0c4-ae437e2a10bc"
      },
      "id": "k7sHLvRYA10J",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 704 µs (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkSqcl_eQfV_",
        "outputId": "4bf0e228-38bc-4b99-e009-ba54cd8d36b5"
      },
      "id": "YkSqcl_eQfV_",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.66 ms (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aCjiZ7l3Qfyv"
      },
      "id": "aCjiZ7l3Qfyv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main FOR LOOP Code**\n",
        "\n"
      ],
      "metadata": {
        "id": "Nniyp_1baQUg"
      },
      "id": "Nniyp_1baQUg"
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_paths = [\n",
        "\"ation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha\",\n",
        "\"Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New\",\n",
        "\"dation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1\",\n",
        "\"ion/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data\",\n",
        "\"ion/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo\",\n",
        "\" Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha\",\n",
        "\"dation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma\",\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGid3lyQ7Y2",
        "outputId": "2112be54-c0e5-4e69-8bd8-cc11d2c56029"
      },
      "id": "BbGid3lyQ7Y2",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 769 µs (started: 2023-03-27 16:26:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# folder_name = \"Geetha\"\n",
        "startpath = \"\" \n",
        "analysis_path = \"\"\n",
        "analysis_folder = \"\"\n",
        "folder_name = \"\"\n",
        "Data_Cleanup_SP02_LowCutOff = 50  #If the SPO2 value at the time of APnea is below 60, it must be a bad data point. \n",
        "Data_Cleanup_HR_LowCutOff = 50\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "# # Custom Callback To Include in Callbacks List At Training Time\n",
        "# class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "def main_function ():\n",
        "    global startpath\n",
        "    global analysis_path\n",
        "    global analysis_folder\n",
        "    global folder_name\n",
        "    startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data\"\n",
        "    # startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai\"\n",
        "\n",
        "    time = pd.Timestamp.now(tz=None)\n",
        "    import traceback\n",
        "\n",
        "    AB_Model = \" \"\n",
        "\n",
        "    paths, folder_names = list_folders(startpath)\n",
        "    print (paths)\n",
        "    print (folder_names)\n",
        "\n",
        "    PRINT_TABLES = False\n",
        "    SAVE_DFJ = False\n",
        "    READ_SAVED_DFJ = True\n",
        "\n",
        "    os.chdir(startpath)\n",
        "    # os.makedirs(str(time) + \" - Analysis_Files\", exist_ok=True)\n",
        "    # analysis_path = startpath + \"/\" + str(time) + \" - Analysis_Files\"\n",
        "\n",
        "    os.makedirs(\"Analysis_Files\", exist_ok=True)\n",
        "    analysis_path = startpath + \"/\" + \"Analysis_Files\"\n",
        "\n",
        "    os.chdir(analysis_path)\n",
        "    # errors = pd.DataFrame (columns = ['Folder Name',\"Model\",'Exception', \"filename\", \"lineno\", \"funcname\", \"text\"])\n",
        "    errors = pd.DataFrame ()\n",
        "    df_overall_clinical_summary = pd.DataFrame ()\n",
        "    df_overall_clinical_summary_detailed = pd.DataFrame ()\n",
        "\n",
        "    i = 0;\n",
        "    for path in paths:\n",
        "        folder_name = folder_names[i]\n",
        "        \n",
        "        i += 1            \n",
        "        print (\"on file \" + str(i) + ' of ' + str(len(paths)))\n",
        "        print (\"Working on \" + folder_name)\n",
        "        print (\"free mem start:\",end = \" \")\n",
        "        !free -h --si | awk  '/Mem:/{print $4}'\n",
        "        \n",
        "        # This code ignores the paths in the folder that are not worth analyzing - saves anaysis time.\n",
        "        short_path = path[-100:]\n",
        "        ignore = False;\n",
        "\n",
        "        for badpath in ignore_paths:\n",
        "            if short_path == badpath:\n",
        "                ignore = True\n",
        "        \n",
        "        if ignore == True:\n",
        "            print (\"Ignoring\" + folder_name)\n",
        "            continue\n",
        "        \n",
        "\n",
        "        try:\n",
        "            \n",
        "            \n",
        "            os.chdir(analysis_path)\n",
        "            analysis_folder = \"Analysis - \" + folder_name\n",
        "            \n",
        "            os.makedirs(analysis_folder, exist_ok=True)\n",
        "            current_analysis_folder_path = analysis_path+ '/' + analysis_folder\n",
        "            \n",
        "            os.chdir(current_analysis_folder_path)\n",
        "\n",
        "            # This code to save future time in creating df_j masterfile\n",
        "            if (READ_SAVED_DFJ == False):\n",
        "                df_j, df_d, df_s = createDataTables (path)\n",
        "            else:\n",
        "                os.chdir(current_analysis_folder_path)\n",
        "                # print (current_analysis_folder_path)\n",
        "                print (os.getcwd)\n",
        "                print ('files:')\n",
        "                print (os.listdir() )\n",
        "                df_j = pd.read_csv(folder_name + ' - df_j.csv')\n",
        "                # display(df_j)\n",
        "                # print (df_j.dtypes)\n",
        "                # print (\"a\")\n",
        "                # display (df_j)\n",
        "            \n",
        "            \n",
        "            # print(df_j.columns)\n",
        "            if 'Settings Date-Time' not in df_j.columns:\n",
        "                print (\"1\")\n",
        "                df_j['Settings Date-Time'] = getDateTimeColumn (df_j[[\"Settings Date-Time\"]])\n",
        "            if 'Data Date-Time' not in df_j.columns:\n",
        "                print (\"2\")\n",
        "                df_j['Data Date-Time'] = getDateTimeColumn (df_j[[\"Data Date-Time\"]])\n",
        "            else: # assumes both settings and date are both in or out. \n",
        "                print (\"3\")\n",
        "                df_j['Settings Date-Time']= pd.to_datetime(df_j['Settings Date-Time'])\n",
        "                df_j['Data Date-Time']= pd.to_datetime(df_j['Data Date-Time'])\n",
        " \n",
        "            if \"Is_Valid_Data\" not in df_j.columns:\n",
        "                df_j[\"Is_Valid_Data\"] = GetIsValidColumn(df_j)\n",
        "            if Duration_Preset not in df_j.columns:\n",
        "                AnalyzeWithPresetThresholds (df_j)\n",
        "            if (SAVE_DFJ == True):\n",
        "                os.chdir(current_analysis_folder_path)                \n",
        "                df_j.to_csv (folder_name + ' - df_j.csv')\n",
        "            \n",
        "            # print (df_j.dtypes)\n",
        "            # plotByDay (df_j)\n",
        "            # plotByHour (df_j)\n",
        "            # PlotApneaEventsGrid (df_j)\n",
        "            # createSummaryTables (df_j,df_s)\n",
        "            \n",
        "            df_current_clinical_summary = pd.DataFrame ()\n",
        "            df_current_clinical_summary = createClinicalSummaryTable (df_j, folder_name)\n",
        "            df_current_clinical_summary[\"path\"] = path[-100:]\n",
        "            df_overall_clinical_summary = pd.concat([df_overall_clinical_summary, df_current_clinical_summary])\n",
        "            os.chdir(analysis_path)\n",
        "            \n",
        "            \n",
        "            #####\n",
        "            df_current_clinical_summary_detailed = df_current_clinical_summary\n",
        "            # df_current_clinical_summary_detailed[\"file_list\"] = file_list\n",
        "            df_current_clinical_summary_detailed[\"model\"] = AB_Model;\n",
        "            df_current_clinical_summary_detailed[\"data date-time\"] = df_j[\"Data Date-Time\"].iloc[0];\n",
        "            df_overall_clinical_summary_detailed = pd.concat([df_overall_clinical_summary_detailed, df_current_clinical_summary_detailed])\n",
        "\n",
        "            print (folder_name + \" success!\")\n",
        "\n",
        "        except Exception as exc: \n",
        "            print (\"ERROR FOR \" + folder_name + \":\")\n",
        "            filename, lineno, funcname, text = traceback.extract_tb(exc.__traceback__)[-1]\n",
        "            print (exc)\n",
        "            print(filename, lineno, funcname, text)\n",
        "            short_path = path[-100:]\n",
        "            current_error = pd.DataFrame (data = {'short_path': [short_path], 'Folder Name':[folder_name], \"Model\": [AB_Model], 'Exception':[exc], \"filename\": [filename], \"lineno\": [lineno], \"funcname\": [funcname], \"text\": [text], 'data header': [header], 'settings header': [settings_header], 'numcommas':[number_of_commas]})\n",
        "            errors = errors.append (current_error,ignore_index = True);\n",
        "            os.chdir(analysis_path)\n",
        "            errors.to_excel (\"Error Summary.xlsx\")\n",
        "        \n",
        "        print (\"free mem end before gc:\",end = \" \")\n",
        "        !free -h --si | awk  '/Mem:/{print $4}'\n",
        "        gc.collect()\n",
        "        print (\"free mem end after gc:\",end = \" \")\n",
        "        !free -h --si | awk  '/Mem:/{print $4}'\n",
        "\n",
        "        \n",
        "\n",
        "    df_overall_clinical_summary.to_excel (\"Overall Clinical Summary.xlsx\")\n",
        "    df_overall_clinical_summary_detailed.to_excel (\"Overall Clinical Summary - Detailed.xlsx\")\n",
        "    print (\"errors table:\")\n",
        "    display (errors)\n",
        "        \n",
        "main_function()\n",
        "# GPUtil.getGPUs()[0].load and GPUtil.getGPUs()[0].memoryUsed\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "RtVUyZ_9ZcLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e21f86-65e8-46c7-8c14-b9984640a83a"
      },
      "id": "RtVUyZ_9ZcLO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Parvati_intervention/Parvathi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Johnsi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Surya/surya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Suma/suma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sravani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sayeda', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Baby of Geetha/Geetha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Santoshini', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya New', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Soniya Mary', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Shobha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Vaishali', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Sudha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Remi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of  Sujatha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Humera', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Bhagya', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Sushma/Sushma', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Aruna', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Anitha_/Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Anusha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/placebo/Baby of Pavithra_placebo', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Intervention_Unclear data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Hemabindu 2/BO Hemabindu 2 data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 1/BO Tadamarri twin 1 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Shwetha 2', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Anitha', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Ayesha Banu', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Manjula', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Prema/BO Prema Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /stj70221oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701/stj703_21oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st701', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702/stj70121oct', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /st702', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Stj03_01-sep', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ702_Intervention_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /STJ701_Placebo_Clinical data_24_July-2020_4PM', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/Extracted data /Baby 1', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Tadamari twin 2/BO Tadamari twin 2 Raw data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St.Johns Phase 2 Data( >june 30,2020)/BO Chandrakala Twin 1/BO Chandrakala Twin 1 Raw Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Noor Fathima/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Asmath /Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sravanthi/AB Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/VaraLaxmi/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Sunitha/Apneboot device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Uma Bai/Raw data of AB device', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Tehseen', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Vani/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ramanamma/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Saraswati/AB device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Hafsa/AB Device data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Mounika/Apneboot data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Bhavani', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Heena/ApneBoot Data', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Ahmedi', '/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/Niloufer/Jyothi/Apneboot data']\n",
            "['Parvathi', 'Johnsi', 'surya', 'suma', 'Sravani', 'Sayeda', 'Sneha', 'Geetha', 'Santoshini', 'Mary', 'Bhagya New', 'Soniya Mary', 'Shobha', 'Vaishali', 'Sujatha', 'Sudha', 'Remi', 'Sushma', 'Anitha', 'Baby of  Sujatha', 'Baby of Pavithra_placebo', 'Humera', 'Bhagya', 'Sushma', 'Aruna', 'Anitha', 'Anusha', 'Baby of Pavithra_placebo', 'Intervention_Unclear data', 'BO Hemabindu 2 data', 'BO Tadamarri twin 1 Raw data', 'BO Shwetha 2', 'BO Anitha', 'BO Ayesha Banu', 'BO Manjula', 'BO Prema Raw data', 'stj70221oct', 'stj703_21oct', 'st701', 'stj70121oct', 'st702', 'Stj03_01-sep', 'STJ702_Intervention_Clinical data_24_July-2020_4PM', 'STJ701_Placebo_Clinical data_24_July-2020_4PM', 'Baby 1', 'BO Tadamari twin 2 Raw data', 'BO Chandrakala Twin 1 Raw Data', 'Apneboot device data', 'Apneboot data', 'AB Data', 'AB device data', 'Apneboot device data', 'Raw data of AB device', 'Tehseen', 'AB device data', 'Apneboot data', 'AB device data', 'AB Device data', 'Apneboot data', 'Bhavani', 'ApneBoot Data', 'Ahmedi', 'Apneboot data']\n",
            "on file 1 of 63\n",
            "Working on Parvathi\n",
            "free mem start: 3.0G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Overall Clinical Summary.xlsx', 'Overall Clinical Summary - Detailed.xlsx', 'Parvathi plot_by_hour.pdf', 'Parvathi plot_individual_events.pdf', 'Parvathi - df_j.csv', 'Parvathi plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 2.9G\n",
            "1 / 2.8G\n",
            "2 / 2.8G\n",
            "3 / 2.8G\n",
            "Num Apneas is:44\n",
            "Sum Apnea Time is:392.0\n",
            "Parvathi success!\n",
            "free mem end before gc: 2.7G\n",
            "free mem end after gc: 2.7G\n",
            "on file 2 of 63\n",
            "Working on Johnsi\n",
            "free mem start: 2.7G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Johnsi plot_by_hour.pdf', 'Johnsi plot_individual_events.pdf', 'Johnsi - df_j.csv', 'Johnsi plot_by_day.pdf']\n",
            "3\n",
            "Number of days is10\n",
            "Working on / free mem: \n",
            "0 / 2.4G\n",
            "1 / 2.2G\n",
            "2 / 2.1G\n",
            "3 / 2.1G\n",
            "4 / 2.0G\n",
            "5 / 1.9G\n",
            "6 / 1.9G\n",
            "7 / 1.8G\n",
            "8 / 1.7G\n",
            "9 / 1.7G\n",
            "Num Apneas is:567\n",
            "Sum Apnea Time is:7716.0\n",
            "Johnsi success!\n",
            "free mem end before gc: 1.7G\n",
            "free mem end after gc: 1.7G\n",
            "on file 3 of 63\n",
            "Working on surya\n",
            "free mem start: 1.7G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['surya plot_by_hour.pdf', 'surya plot_individual_events.pdf', 'surya - df_j.csv', 'surya plot_by_day.pdf']\n",
            "3\n",
            "Number of days is7\n",
            "Working on / free mem: \n",
            "0 / 1.6G\n",
            "1 / 1.5G\n",
            "2 / 1.5G\n",
            "3 / 1.5G\n",
            "4 / 1.5G\n",
            "5 / 1.4G\n",
            "6 / 1.4G\n",
            "Num Apneas is:5\n",
            "Sum Apnea Time is:36.0\n",
            "surya success!\n",
            "free mem end before gc: 1.5G\n",
            "free mem end after gc: 1.5G\n",
            "on file 4 of 63\n",
            "Working on suma\n",
            "free mem start: 1.5G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['suma plot_by_hour.pdf', 'suma - df_j.csv', 'suma plot_by_day.pdf']\n",
            "3\n",
            "Number of days is8\n",
            "Working on / free mem: \n",
            "0 / 1.4G\n",
            "1 / 1.4G\n",
            "2 / 1.3G\n",
            "3 / 1.3G\n",
            "4 / 1.3G\n",
            "5 / 1.2G\n",
            "6 / 1.2G\n",
            "7 / 1.2G\n",
            "Num Apneas is:179\n",
            "Sum Apnea Time is:1632.0\n",
            "suma success!\n",
            "free mem end before gc: 1.1G\n",
            "free mem end after gc: 1.1G\n",
            "on file 5 of 63\n",
            "Working on Sravani\n",
            "free mem start: 1.1G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sravani - df_j.csv', 'Sravani plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 1.1G\n",
            "1 / 1.1G\n",
            "2 / 1.1G\n",
            "Num Apneas is:64\n",
            "Sum Apnea Time is:537.0\n",
            "Sravani success!\n",
            "free mem end before gc: 1.1G\n",
            "free mem end after gc: 1.0G\n",
            "on file 6 of 63\n",
            "Working on Sayeda\n",
            "free mem start: 1.0G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sayeda - df_j.csv', 'Sayeda plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 997M\n",
            "1 / 978M\n",
            "2 / 952M\n",
            "3 / 928M\n",
            "Num Apneas is:83\n",
            "Sum Apnea Time is:823.0\n",
            "Sayeda success!\n",
            "free mem end before gc: 906M\n",
            "free mem end after gc: 890M\n",
            "on file 7 of 63\n",
            "Working on Sneha\n",
            "free mem start: 890M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sneha plot_by_hour.pdf', 'Sneha plot_individual_events.pdf', 'Sneha - df_j.csv', 'Sneha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is5\n",
            "Working on / free mem: \n",
            "0 / 789M\n",
            "1 / 787M\n",
            "2 / 758M\n",
            "3 / 727M\n",
            "4 / 694M\n",
            "Num Apneas is:5\n",
            "Sum Apnea Time is:36.0\n",
            "Sneha success!\n",
            "free mem end before gc: 670M\n",
            "free mem end after gc: 670M\n",
            "on file 8 of 63\n",
            "Working on Geetha\n",
            "free mem start: 642M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Geetha - df_j.csv', 'Geetha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is8\n",
            "Working on / free mem: \n",
            "0 / 266M\n",
            "1 / 212M\n",
            "2 / 181M\n",
            "3 / 169M\n",
            "4 / 154M\n",
            "5 / 168M\n",
            "6 / 163M\n",
            "7 / 165M\n",
            "Num Apneas is:378\n",
            "Sum Apnea Time is:4650.0\n",
            "Geetha success!\n",
            "free mem end before gc: 197M\n",
            "free mem end after gc: 196M\n",
            "on file 9 of 63\n",
            "Working on Santoshini\n",
            "free mem start: 194M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Santoshini - df_j.csv', 'Santoshini plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 159M\n",
            "1 / 157M\n",
            "2 / 157M\n",
            "Num Apneas is:228\n",
            "Sum Apnea Time is:1936.0\n",
            "Santoshini success!\n",
            "free mem end before gc: 199M\n",
            "free mem end after gc: 198M\n",
            "on file 10 of 63\n",
            "Working on Mary\n",
            "free mem start: 198M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Mary - df_j.csv', 'Mary plot_by_day.pdf']\n",
            "3\n",
            "Number of days is2\n",
            "Working on / free mem: \n",
            "0 / 176M\n",
            "1 / 2.6G\n",
            "Num Apneas is:20\n",
            "Sum Apnea Time is:146.0\n",
            "Mary success!\n",
            "free mem end before gc: 2.6G\n",
            "free mem end after gc: 2.6G\n",
            "on file 11 of 63\n",
            "Working on Bhagya New\n",
            "free mem start: 2.6G\n",
            "IgnoringBhagya New\n",
            "on file 12 of 63\n",
            "Working on Soniya Mary\n",
            "free mem start: 2.6G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Soniya Mary plot_by_day.pdf', 'Soniya Mary - df_j.csv']\n",
            "3\n",
            "ERROR FOR Soniya Mary:\n",
            "second must be in 0..59: 6/12/2018   10:54:60\n",
            "<string> 3 raise_from \n",
            "free mem end before gc: 2.3G\n",
            "free mem end after gc: 2.3G\n",
            "on file 13 of 63\n",
            "Working on Shobha\n",
            "free mem start: 2.3G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Shobha - df_j.csv', 'Shobha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 2.1G\n",
            "1 / 2.1G\n",
            "2 / 2.0G\n",
            "3 / 1.9G\n",
            "Num Apneas is:226\n",
            "Sum Apnea Time is:3555.0\n",
            "Shobha success!\n",
            "free mem end before gc: 1.9G\n",
            "free mem end after gc: 1.9G\n",
            "on file 14 of 63\n",
            "Working on Vaishali\n",
            "free mem start: 1.9G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Vaishali - df_j.csv', 'Vaishali plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 1.8G\n",
            "1 / 1.8G\n",
            "2 / 1.8G\n",
            "3 / 1.8G\n",
            "Num Apneas is:36\n",
            "Sum Apnea Time is:319.0\n",
            "Vaishali success!\n",
            "free mem end before gc: 1.8G\n",
            "free mem end after gc: 1.8G\n",
            "on file 15 of 63\n",
            "Working on Sujatha\n",
            "free mem start: 1.8G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sujatha - df_j.csv', 'Sujatha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is8\n",
            "Working on / free mem: \n",
            "0 / 1.5G\n",
            "1 / 1.4G\n",
            "2 / 1.3G\n",
            "3 / 1.3G\n",
            "4 / 1.2G\n",
            "5 / 1.1G\n",
            "6 / 994M\n",
            "7 / 955M\n",
            "Num Apneas is:326\n",
            "Sum Apnea Time is:3854.0\n",
            "Sujatha success!\n",
            "free mem end before gc: 955M\n",
            "free mem end after gc: 954M\n",
            "on file 16 of 63\n",
            "Working on Sudha\n",
            "free mem start: 954M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sudha - df_j.csv', 'Sudha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 928M\n",
            "1 / 926M\n",
            "2 / 903M\n",
            "Num Apneas is:87\n",
            "Sum Apnea Time is:767.0\n",
            "Sudha success!\n",
            "free mem end before gc: 1.0G\n",
            "free mem end after gc: 1.0G\n",
            "on file 17 of 63\n",
            "Working on Remi\n",
            "free mem start: 1.0G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Remi - df_j.csv', 'Remi plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 834M\n",
            "1 / 792M\n",
            "2 / 757M\n",
            "3 / 710M\n",
            "Num Apneas is:440\n",
            "Sum Apnea Time is:4841.0\n",
            "Remi success!\n",
            "free mem end before gc: 657M\n",
            "free mem end after gc: 656M\n",
            "on file 18 of 63\n",
            "Working on Sushma\n",
            "free mem start: 655M\n",
            "IgnoringSushma\n",
            "on file 19 of 63\n",
            "Working on Anitha\n",
            "free mem start: 656M\n",
            "IgnoringAnitha\n",
            "on file 20 of 63\n",
            "Working on Baby of  Sujatha\n",
            "free mem start: 657M\n",
            "IgnoringBaby of  Sujatha\n",
            "on file 21 of 63\n",
            "Working on Baby of Pavithra_placebo\n",
            "free mem start: 655M\n",
            "IgnoringBaby of Pavithra_placebo\n",
            "on file 22 of 63\n",
            "Working on Humera\n",
            "free mem start: 657M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Humera - df_j.csv', 'Humera plot_by_day.pdf']\n",
            "3\n",
            "Number of days is14\n",
            "Working on / free mem: \n",
            "0 / 609M\n",
            "1 / 523M\n",
            "2 / 484M\n",
            "3 / 411M\n",
            "4 / 380M\n",
            "5 / 299M\n",
            "6 / 250M\n",
            "7 / 207M\n",
            "8 / 185M\n",
            "9 / 218M\n",
            "10 / 216M\n",
            "11 / 170M\n",
            "12 / 171M\n",
            "13 / 167M\n",
            "Num Apneas is:743\n",
            "Sum Apnea Time is:7621.0\n",
            "Humera success!\n",
            "free mem end before gc: 194M\n",
            "free mem end after gc: 194M\n",
            "on file 23 of 63\n",
            "Working on Bhagya\n",
            "free mem start: 195M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Bhagya - df_j.csv', 'Bhagya plot_by_day.pdf']\n",
            "3\n",
            "Number of days is11\n",
            "Working on / free mem: \n",
            "0 / 218M\n",
            "1 / 197M\n",
            "2 / 165M\n",
            "3 / 166M\n",
            "4 / 154M\n",
            "5 / 176M\n",
            "6 / 177M\n",
            "7 / 1.9G\n",
            "8 / 1.9G\n",
            "9 / 1.8G\n",
            "10 / 1.8G\n",
            "Num Apneas is:240\n",
            "Sum Apnea Time is:3237.0\n",
            "Bhagya success!\n",
            "free mem end before gc: 1.9G\n",
            "free mem end after gc: 1.9G\n",
            "on file 24 of 63\n",
            "Working on Sushma\n",
            "free mem start: 1.9G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Sushma - df_j.csv', 'Sushma plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 1.8G\n",
            "1 / 1.8G\n",
            "2 / 1.8G\n",
            "Num Apneas is:10\n",
            "Sum Apnea Time is:73.0\n",
            "Sushma success!\n",
            "free mem end before gc: 1.9G\n",
            "free mem end after gc: 1.9G\n",
            "on file 25 of 63\n",
            "Working on Aruna\n",
            "free mem start: 1.9G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Aruna - df_j.csv', 'Aruna plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 1.9G\n",
            "1 / 1.9G\n",
            "2 / 1.9G\n",
            "Num Apneas is:0\n",
            "Sum Apnea Time is:0.0\n",
            "Aruna success!\n",
            "free mem end before gc: 1.9G\n",
            "free mem end after gc: 1.9G\n",
            "on file 26 of 63\n",
            "Working on Anitha\n",
            "free mem start: 1.9G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Anitha - df_j.csv', 'Anitha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is5\n",
            "Working on / free mem: \n",
            "0 / 1.8G\n",
            "1 / 1.8G\n",
            "2 / 1.8G\n",
            "3 / 1.8G\n",
            "4 / 1.7G\n",
            "Num Apneas is:70\n",
            "Sum Apnea Time is:680.0\n",
            "Anitha success!\n",
            "free mem end before gc: 1.7G\n",
            "free mem end after gc: 1.7G\n",
            "on file 27 of 63\n",
            "Working on Anusha\n",
            "free mem start: 1.7G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Anusha - df_j.csv', 'Anusha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 1.7G\n",
            "1 / 1.7G\n",
            "2 / 1.6G\n",
            "3 / 1.6G\n",
            "Num Apneas is:60\n",
            "Sum Apnea Time is:540.0\n",
            "Anusha success!\n",
            "free mem end before gc: 1.6G\n",
            "free mem end after gc: 1.6G\n",
            "on file 28 of 63\n",
            "Working on Baby of Pavithra_placebo\n",
            "free mem start: 1.6G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Baby of Pavithra_placebo - df_j.csv', 'Baby of Pavithra_placebo plot_by_day.pdf']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 1.5G\n",
            "1 / 1.5G\n",
            "2 / 1.5G\n",
            "Num Apneas is:0\n",
            "Sum Apnea Time is:0.0\n",
            "Baby of Pavithra_placebo success!\n",
            "free mem end before gc: 1.5G\n",
            "free mem end after gc: 1.5G\n",
            "on file 29 of 63\n",
            "Working on Intervention_Unclear data\n",
            "free mem start: 1.5G\n",
            "IgnoringIntervention_Unclear data\n",
            "on file 30 of 63\n",
            "Working on BO Hemabindu 2 data\n",
            "free mem start: 1.5G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Hemabindu 2 data - df_j.csv', 'BO Hemabindu 2 data plot_by_day.pdf']\n",
            "3\n",
            "Number of days is6\n",
            "Working on / free mem: \n",
            "0 / 1.1G\n",
            "1 / 1.0G\n",
            "2 / 1.0G\n",
            "3 / 971M\n",
            "4 / 887M\n",
            "5 / 834M\n",
            "Num Apneas is:112\n",
            "Sum Apnea Time is:2001.0\n",
            "BO Hemabindu 2 data success!\n",
            "free mem end before gc: 813M\n",
            "free mem end after gc: 812M\n",
            "on file 31 of 63\n",
            "Working on BO Tadamarri twin 1 Raw data\n",
            "free mem start: 812M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Tadamarri twin 1 Raw data - df_j.csv', 'BO Tadamarri twin 1 Raw data plot_by_day.pdf']\n",
            "3\n",
            "Number of days is9\n",
            "Working on / free mem: \n",
            "0 / 377M\n",
            "1 / 326M\n",
            "2 / 284M\n",
            "3 / 258M\n",
            "4 / 252M\n",
            "5 / 247M\n",
            "6 / 197M\n",
            "7 / 165M\n",
            "8 / 168M\n",
            "Num Apneas is:137\n",
            "Sum Apnea Time is:2213.0\n",
            "BO Tadamarri twin 1 Raw data success!\n",
            "free mem end before gc: 243M\n",
            "free mem end after gc: 243M\n",
            "on file 32 of 63\n",
            "Working on BO Shwetha 2\n",
            "free mem start: 242M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Shwetha 2 - df_j.csv', 'BO Shwetha 2 plot_by_day.pdf']\n",
            "3\n",
            "Number of days is12\n",
            "Working on / free mem: \n",
            "0 / 529M\n",
            "1 / 477M\n",
            "2 / 399M\n",
            "3 / 373M\n",
            "4 / 1.6G\n",
            "5 / 1.5G\n",
            "6 / 1.5G\n",
            "7 / 1.4G\n",
            "8 / 1.3G\n",
            "9 / 1.3G\n",
            "10 / 1.2G\n",
            "11 / 1.2G\n",
            "Num Apneas is:692\n",
            "Sum Apnea Time is:11666.0\n",
            "BO Shwetha 2 success!\n",
            "free mem end before gc: 1.2G\n",
            "free mem end after gc: 1.2G\n",
            "on file 33 of 63\n",
            "Working on BO Anitha\n",
            "free mem start: 1.2G\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Anitha - df_j.csv', 'BO Anitha plot_by_day.pdf']\n",
            "3\n",
            "Number of days is15\n",
            "Working on / free mem: \n",
            "0 / 708M\n",
            "1 / 637M\n",
            "2 / 554M\n",
            "3 / 482M\n",
            "4 / 457M\n",
            "5 / 370M\n",
            "6 / 304M\n",
            "7 / 245M\n",
            "8 / 183M\n",
            "9 / 177M\n",
            "10 / 174M\n",
            "11 / 177M\n",
            "12 / 168M\n",
            "13 / 183M\n",
            "14 / 169M\n",
            "Num Apneas is:467\n",
            "Sum Apnea Time is:7541.0\n",
            "BO Anitha success!\n",
            "free mem end before gc: 435M\n",
            "free mem end after gc: 436M\n",
            "on file 34 of 63\n",
            "Working on BO Ayesha Banu\n",
            "free mem start: 436M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Ayesha Banu - df_j.csv', 'BO Ayesha Banu plot_by_day.pdf']\n",
            "3\n",
            "Number of days is6\n",
            "Working on / free mem: \n",
            "0 / 189M\n",
            "1 / 179M\n",
            "2 / 168M\n",
            "3 / 171M\n",
            "4 / 188M\n",
            "5 / 188M\n",
            "Num Apneas is:160\n",
            "Sum Apnea Time is:5049.0\n",
            "BO Ayesha Banu success!\n",
            "free mem end before gc: 429M\n",
            "free mem end after gc: 430M\n",
            "on file 35 of 63\n",
            "Working on BO Manjula\n",
            "free mem start: 431M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Manjula - df_j.csv', 'BO Manjula plot_by_day.pdf']\n",
            "3\n",
            "Number of days is20\n",
            "Working on / free mem: \n",
            "0 / 903M\n",
            "1 / 791M\n",
            "2 / 740M\n",
            "3 / 717M\n",
            "4 / 618M\n",
            "5 / 540M\n",
            "6 / 469M\n",
            "7 / 400M\n",
            "8 / 327M\n",
            "9 / 269M\n",
            "10 / 202M\n",
            "11 / 168M\n",
            "12 / 179M\n",
            "13 / 193M\n",
            "14 / 176M\n",
            "15 / 171M\n",
            "16 / 205M\n",
            "17 / 199M\n",
            "18 / 182M\n",
            "19 / 184M\n",
            "Num Apneas is:962\n",
            "Sum Apnea Time is:19013.0\n",
            "BO Manjula success!\n",
            "free mem end before gc: 437M\n",
            "free mem end after gc: 435M\n",
            "on file 36 of 63\n",
            "Working on BO Prema Raw data\n",
            "free mem start: 435M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Prema Raw data - df_j.csv', 'BO Prema Raw data plot_by_day.pdf']\n",
            "3\n",
            "Number of days is6\n",
            "Working on / free mem: \n",
            "0 / 194M\n",
            "1 / 172M\n",
            "2 / 175M\n",
            "3 / 167M\n",
            "4 / 174M\n",
            "5 / 172M\n",
            "Num Apneas is:133\n",
            "Sum Apnea Time is:3285.0\n",
            "BO Prema Raw data success!\n",
            "free mem end before gc: 499M\n",
            "free mem end after gc: 501M\n",
            "on file 37 of 63\n",
            "Working on stj70221oct\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR stj70221oct:\n",
            "[Errno 2] No such file or directory: 'stj70221oct - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 501M\n",
            "free mem end after gc: 499M\n",
            "on file 38 of 63\n",
            "Working on stj703_21oct\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR stj703_21oct:\n",
            "[Errno 2] No such file or directory: 'stj703_21oct - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 499M\n",
            "free mem end after gc: 498M\n",
            "on file 39 of 63\n",
            "Working on st701\n",
            "free mem start: 498M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR st701:\n",
            "[Errno 2] No such file or directory: 'st701 - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 497M\n",
            "free mem end after gc: 502M\n",
            "on file 40 of 63\n",
            "Working on stj70121oct\n",
            "free mem start: 502M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR stj70121oct:\n",
            "[Errno 2] No such file or directory: 'stj70121oct - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 501M\n",
            "free mem end after gc: 500M\n",
            "on file 41 of 63\n",
            "Working on st702\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR st702:\n",
            "[Errno 2] No such file or directory: 'st702 - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 500M\n",
            "free mem end after gc: 501M\n",
            "on file 42 of 63\n",
            "Working on Stj03_01-sep\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR Stj03_01-sep:\n",
            "[Errno 2] No such file or directory: 'Stj03_01-sep - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 501M\n",
            "free mem end after gc: 500M\n",
            "on file 43 of 63\n",
            "Working on STJ702_Intervention_Clinical data_24_July-2020_4PM\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR STJ702_Intervention_Clinical data_24_July-2020_4PM:\n",
            "[Errno 2] No such file or directory: 'STJ702_Intervention_Clinical data_24_July-2020_4PM - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 501M\n",
            "free mem end after gc: 501M\n",
            "on file 44 of 63\n",
            "Working on STJ701_Placebo_Clinical data_24_July-2020_4PM\n",
            "free mem start: 501M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "[]\n",
            "ERROR FOR STJ701_Placebo_Clinical data_24_July-2020_4PM:\n",
            "[Errno 2] No such file or directory: 'STJ701_Placebo_Clinical data_24_July-2020_4PM - df_j.csv'\n",
            "/usr/local/lib/python3.9/dist-packages/pandas/io/common.py 786 get_handle handle = open(\n",
            "free mem end before gc: 500M\n",
            "free mem end after gc: 501M\n",
            "on file 45 of 63\n",
            "Working on Baby 1\n",
            "free mem start: 501M\n",
            "IgnoringBaby 1\n",
            "on file 46 of 63\n",
            "Working on BO Tadamari twin 2 Raw data\n",
            "free mem start: 500M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Tadamari twin 2 Raw data - df_j.csv', 'BO Tadamari twin 2 Raw data plot_by_day.pdf']\n",
            "3\n",
            "Number of days is10\n",
            "Working on / free mem: \n",
            "0 / 503M\n",
            "1 / 445M\n",
            "2 / 356M\n",
            "3 / 335M\n",
            "4 / 201M\n",
            "5 / 170M\n",
            "6 / 176M\n",
            "7 / 169M\n",
            "8 / 166M\n",
            "9 / 175M\n",
            "Num Apneas is:690\n",
            "Sum Apnea Time is:17636.0\n",
            "BO Tadamari twin 2 Raw data success!\n",
            "free mem end before gc: 293M\n",
            "free mem end after gc: 290M\n",
            "on file 47 of 63\n",
            "Working on BO Chandrakala Twin 1 Raw Data\n",
            "free mem start: 288M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['BO Chandrakala Twin 1 Raw Data - df_j.csv']\n",
            "3\n",
            "Number of days is4\n",
            "Working on / free mem: \n",
            "0 / 175M\n",
            "1 / 174M\n",
            "2 / 178M\n",
            "3 / 162M\n",
            "Num Apneas is:57\n",
            "Sum Apnea Time is:995.0\n",
            "BO Chandrakala Twin 1 Raw Data success!\n",
            "free mem end before gc: 292M\n",
            "free mem end after gc: 293M\n",
            "on file 48 of 63\n",
            "Working on Apneboot device data\n",
            "free mem start: 293M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Apneboot device data - df_j.csv']\n",
            "3\n",
            "Number of days is3\n",
            "Working on / free mem: \n",
            "0 / 245M\n",
            "1 / 246M\n",
            "2 / 204M\n",
            "Num Apneas is:86\n",
            "Sum Apnea Time is:898.0\n",
            "Apneboot device data success!\n",
            "free mem end before gc: 193M\n",
            "free mem end after gc: 194M\n",
            "on file 49 of 63\n",
            "Working on Apneboot data\n",
            "free mem start: 192M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['Apneboot data - df_j.csv']\n",
            "3\n",
            "Number of days is2\n",
            "Working on / free mem: \n",
            "0 / 169M\n",
            "1 / 219M\n",
            "Num Apneas is:0\n",
            "Sum Apnea Time is:0.0\n",
            "Apneboot data success!\n",
            "free mem end before gc: 203M\n",
            "free mem end after gc: 200M\n",
            "on file 50 of 63\n",
            "Working on AB Data\n",
            "free mem start: 200M\n",
            "<built-in function getcwd>\n",
            "files:\n",
            "['AB Data - df_j.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clinical Analysis**"
      ],
      "metadata": {
        "id": "GXKhxms5QiML"
      },
      "id": "GXKhxms5QiML"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Match Table"
      ],
      "metadata": {
        "id": "PZ_oJn6SQmSJ"
      },
      "id": "PZ_oJn6SQmSJ"
    },
    {
      "cell_type": "code",
      "source": [
        "### Match Table\n",
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/\"\n",
        "lookup_fn = \"230310 AB RCT - Data Collection Summary RNv1 - Data Analysis Summary_Ratul.csv\"\n",
        "clinical_fn = \"Overall Clinical Summary - Detailed.xlsx\"\n",
        "# createClinicalSummaryTable()\n",
        "os.chdir(startpath)\n",
        "df_lookup = pd.read_csv(lookup_fn)\n",
        "os.chdir(analysis_path)\n",
        "df_clinical = pd.read_excel(clinical_fn)\n",
        "\n",
        "df_match = df_lookup.set_index('shortpath').join(df_clinical.set_index('path'))\n",
        "columns_to_keep = [\n",
        "# \"Order\",\n",
        "\"Unnamed: 1\",\n",
        "\"Baby of\",\n",
        "\"Start date of enrollment\",\n",
        "\"End date of enrollment\",\n",
        "\"Device_type\",\n",
        "\"Number of days of enrollment\",\n",
        "\"Birth weight (grams)\",\n",
        "\"GA\",\n",
        "\"Sub-Group\",\n",
        "# \"Total hypoxia duration (in secs)\",\n",
        "# \"Total hypoxia duration (in hh:mm:ss)\",\n",
        "\"Ventilation\",\n",
        "# \"86,400\",\n",
        "# \"Time Enrolled (S)\",\n",
        "# \"#Seconds in a day\",\n",
        "# \"% seconds in Hypoxia\",\n",
        "# \"Notes\",\n",
        "# \"Notes 2\",\n",
        "# \"Unnamed: 0\",\n",
        "# \"Name\",\n",
        "\"Time ApneBoot System Was On (hrs)\",\n",
        "\"Time with valid vital and status readings (hrs)\",\n",
        "\"SPO2 - Avg\",\n",
        "\"SPO2 - Std\",\n",
        "\"HR - Avg\",\n",
        "\"HR - Std\",\n",
        "\"model\",\n",
        "'Num Events (Preset Threshold)',\n",
        "'Cumulative Event Duration (Preset Threshold)'\n",
        "# \"data date-time\",\n",
        "]\n",
        "\n",
        "columns_to_keep = columns_to_keep + spo2_col_time_name_list + hr_col_time_name_list + spo2_col_percent_name_list + hr_col_percent_name_list\n",
        "print (columns_to_keep)\n",
        "df_match = df_match [columns_to_keep]\n",
        "for col in spo2_col_time_name_list:\n",
        "    df_match ['% ' + col] = df_match[col] / df_match [\"Time with valid vital and status readings (hrs)\"]\n",
        "display (df_match)\n",
        "\n",
        "\n",
        "df_match.to_excel (\"4 - Matched Table Summary.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7SYrEoQoApav"
      },
      "id": "7SYrEoQoApav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Clinical Plots"
      ],
      "metadata": {
        "id": "mOMYLLGgQ2pK"
      },
      "id": "mOMYLLGgQ2pK"
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "plot_opts = {\n",
        "    \"cutoff_val\": 5,\n",
        "    \"cutoff_type\": \"abs\",\n",
        "    \"label_fontsize\": \"small\",\n",
        "    \"label_rotation\": 30,\n",
        "}\n",
        "\n",
        "# exclude certain babies\n",
        "df_match = df_match[df_match['Baby of']!= 'Ramanamma']\n",
        "drop_babies = [\n",
        "'Ramanamma',\n",
        "'Manjula',\n",
        "'Shwetha 2',\n",
        "'Noor Fathima T-1',\n",
        "]\n",
        "\n",
        "for baby in drop_babies:\n",
        "    df_match.drop ((df_match['Baby of'] == baby).index, inplace = True)\n",
        "\n",
        "\n",
        "#  display (df_match)\n",
        "df_melt = df_match.melt (id_vars = ['Device_type'],value_vars= spo2_col_percent_name_list, var_name = 'Group', value_name = 'SPO2 Level')\n",
        "# display (df_melt)\n",
        "# fig = plt.figure(10,10)\n",
        "# ax = fig.add_subplot(111)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.boxplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "# sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', ax=ax)\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
        "sns.catplot(data=df_melt, col = 'SPO2 Level', x = 'Group', y = 'SPO2 Level', hue = 'Device_type', aspect=.5, ax = ax2)\n",
        "\n",
        "for col in spo2_col_percent_name_list:\n",
        "    df = df_match\n",
        "    placebo = df[df['Device_type']=='Placebo']\n",
        "    intervention = df[df['Device_type']=='Intervention']\n",
        "    print (\"col: \" + col)\n",
        "    print(ttest_ind(placebo[col], intervention[col]))\n",
        "\n",
        "#perform independent two sample t-test\n",
        "\n",
        "# sns.stripplot(data=df_melt, x = 'Group', y = 'SPO2 Level', hue = 'Device_type', color = 'red')\n",
        "# sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# df_beanplot = pd.DataFrame ()\n",
        "# df_beanplot ['Baby of'] = df_match['Baby of']\n",
        "# # df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'][df_match['Device_type'] == 'Intervention']\n",
        "# df_beanplot['Intervention'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Intervention')\n",
        "# df_beanplot['Placebo'] = df_match ['Time SPO2 < 85(hrs)'].where(df_match['Device_type'] == 'Placebo')\n",
        "# # plt.boxplot(df_match['Time SPO2 < 85(hrs)'])\n",
        "# # display (df_beanplot)\n",
        "# df_intervention = pd.DataFrame ()\n",
        "# df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "# # df_intervention['Intervention'] = df_beanplot['Intervention'].dropna();\n",
        "# # df_intervention = df_intervention.dropna ()\n",
        "# # df_placebo = pd.DataFrame ()\n",
        "# # df_intervention['Intervention'] = df_beanplot['Intervention']\n",
        "# # df_intervention = df_intervention.dropna ()\n",
        "# # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "# # sns.stripplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type', color = 'red')\n",
        "# display (df_match)\n",
        "# df_stack = df_match.stack()\n",
        "# display (df_stack)\n",
        "# # sns.boxplot(data=df_match, y = 'Time SPO2 < 85(hrs)', x = 'Device_type')\n",
        "\n",
        "# # df_intervention = df_intervention [df_intervention['Intervention'].]\n",
        "# # display (df_intervention)\n",
        "# # plt.boxplot(df_intervention['Intervention'])\n",
        "\n",
        "# # plt.show()\n",
        "# # display (df_beanplot)\n",
        "# # data = sm.load_pandas()\n",
        "# # data = sm.load()\n",
        "\n",
        "# # sm.graphics.beanplot (df_beanplot., ax=ax, labels = ['Intervention', 'Placebo'], plot_opts=plot_opts)\n",
        "\n",
        "# # sm.graphics.beanplot(age, ax=ax, labels=labels, plot_opts=plot_opts)\n"
      ],
      "metadata": {
        "id": "hq6gb8jmW4af"
      },
      "id": "hq6gb8jmW4af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Calc Stats"
      ],
      "metadata": {
        "id": "ClRUJ1FstCgD"
      },
      "id": "ClRUJ1FstCgD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4fmuhFuf5k"
      },
      "source": [
        "# DRAFT - New Section"
      ],
      "id": "5E4fmuhFuf5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdo3Bol12w2"
      },
      "source": [
        "## ** Not Used Code**"
      ],
      "id": "Ntdo3Bol12w2"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #fname = \"Report.pdf\"\n",
        "# with PdfPages(fname) as pdf:\n",
        "#   print(\"This is a test of the print function\")\n",
        "#   pdf.savefig()"
      ],
      "metadata": {
        "id": "0EU2cARS1Lsy"
      },
      "id": "0EU2cARS1Lsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# usage_pv_data_table = pd.pivot_table(data_table, index =['Data Date',\"Settings Index\"],\n",
        "#                          aggfunc = 'count')\n",
        "\n",
        "# print(usage_pv_data_table)\n",
        "# usage_pv_data_table.to_csv('Usage_pv_data_table.csv',index=True)\n",
        "# usage_pv_data_table.to_excel(\"Usage_pv_data_table.xlsx\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "d74561dc-a0a4-449c-b420-66f9a7f9fa38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJ1x3Bq8bbc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pd.reset_option(\"all\")\n",
        "#df = stimulation_results_table_with_all_thresholds\n",
        "#print(df)\n",
        "#pivot = pd.pivot_table(stimulation_results_table_with_all_thresholds,\n",
        "                       #values=[\"Status\"], \n",
        "#                       index=['Status'])\n",
        "                       #aggfunc={'Status': np.count,\n",
        "                       # 'HR': [min, max, np.mean]})\n",
        "\n",
        "#df = df.Status.value_counts()\n",
        "#print(pivot)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "# pd.set_option(\"precision\", 4)\n",
        "\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#print(len (stimulation_results_table_with_all_thresholds))\n",
        "#filtered_results_table_all = df[(df[\"Status\"]==129) | (df[\"Status\"]==131)]\n",
        "#print(len (filtered_results_table_all))\n",
        "\n",
        "#data_table = filtered_results_table_all\n",
        "\n",
        "# pivot = pd.pivot_table(data_table,\n",
        "#                        values=['SPO2','HR'], \n",
        "#                        index=['Data Date'],\n",
        "#                        aggfunc={'SPO2': np.mean,\n",
        "#                         'HR': [min, max, np.mean]})\n",
        "\n",
        "#print(pivot)\n",
        "#filtered_results_table_all.to_csv(\"Filtered_Results_Table_All.csv\")\n",
        "\n",
        "# 129    91112\n",
        "# 153    49477\n",
        "# 131    32220\n"
      ],
      "id": "WYJ1x3Bq8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBwS6cI9JH6"
      },
      "source": [
        "\n",
        "Want \n",
        "- Date\n",
        "- Setting Index\n",
        "- \n",
        "\n"
      ],
      "id": "qlBwS6cI9JH6"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # !sudo apt-get install wkhtmltopdf\n",
        "# # !yum install wkhtmltopdf\n",
        "# !apt-get install wkhtmltopdf\n",
        "# import pandas as pd \n",
        "# df_apnea_summary_table.to_html('HTMLTest.html')  \n",
        "\n",
        "# import pdfkit \n",
        "\n",
        "# pdfkit.from_url('HTMLTest.html', 'HTMLTest.pdf')"
      ],
      "metadata": {
        "id": "k08O7_OMVpRX"
      },
      "id": "k08O7_OMVpRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df = pd.DataFrame({'Col': [1,4,5,6,7],\n",
        "                   'Col2': [1,4,5,6,7],\n",
        "                   })\n",
        "display (df)\n",
        "New_Col = \"Col3\"\n",
        "df [New_Col] = df[\"Col\"] +1\n",
        "\n",
        "display (df)\n",
        "display (df[New_Col])"
      ],
      "metadata": {
        "id": "1gwuIXkd74XG"
      },
      "id": "1gwuIXkd74XG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Create a pandas dataframe with demo data:\n",
        "#!pip install -e git+https://github.com/mindee/doctr.git#egg=python-doctr[torch]\n",
        "#!pip install weasyprint\n",
        "!pip install django-weasyprint\n",
        "import pandas as pd\n",
        "demodata_csv = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
        "df = pd.read_csv(demodata_csv)\n",
        "\n",
        "def dfToPDF (df):\n",
        "  # Pretty print the dataframe as an html table to a file\n",
        "  intermediate_html = '/tmp/intermediate.html'\n",
        "  to_html_pretty(df,intermediate_html,'Iris Data')\n",
        "  # if you do not want pretty printing, just use pandas:\n",
        "  # df.to_html(intermediate_html)\n",
        "\n",
        "  # Convert the html file to a pdf file using weasyprint\n",
        "  import weasyprint\n",
        "  out_pdf= '/tmp/demo.pdf'\n",
        "  weasyprint.HTML(intermediate_html).write_pdf(out_pdf)\n",
        "\n",
        "  # This is the table pretty printer used above:\n",
        "\n",
        "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
        "    '''\n",
        "    Write an entire dataframe to an HTML file\n",
        "    with nice formatting.\n",
        "    Thanks to @stackoverflowuser2010 for the\n",
        "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
        "    '''\n",
        "    ht = ''\n",
        "    if title != '':\n",
        "        ht += '<h2> %s </h2>\\n' % title\n",
        "    ht += df.to_html(classes='wide', escape=False)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)\n",
        "\n",
        "HTML_TEMPLATE1 = '''\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "  h2 {\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "  }\n",
        "  table { \n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "  }\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "    font-family: Helvetica, Arial, sans-serif;\n",
        "    font-size: 90%;\n",
        "  }\n",
        "  table tbody tr:hover {\n",
        "    background-color: #dddddd;\n",
        "  }\n",
        "  .wide {\n",
        "    width: 90%; \n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "'''\n",
        "\n",
        "HTML_TEMPLATE2 = '''\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "_4nxBzcnuBex"
      },
      "id": "_4nxBzcnuBex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# # PRINT TABLES & DATA\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# #https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
        "# #df_apnea_summary_table.plot()\n",
        "# #dfToPDF (df)\n",
        "# # fig = convertDataframeToFigure (apnea_summary_table)\n",
        "# # pdf = PdfPages(\"foo.pdf\")\n",
        "# # pdf.savefig(fig, bbox_inches='tight')\n",
        "# # pdf.close()\n",
        "# # !pip install -c conda-forge python-pdfkit\n",
        "# !pip3 install wkhtmltopdf\n",
        "# !pip3 install pdfkit\n",
        "\n",
        "# import pandas as pd\n",
        "# import pdfkit as pdf\n",
        "# import sqlite3\n",
        "\n",
        "# # con=sqlite3.connect(\"baza.db\")\n",
        "\n",
        "# # df=pd.read_sql_query(\"select * from dobit\", con)\n",
        "# #df_apnea_summary_table.datetime = pd.to_datetime(apnea_summary_table.datetime)\n",
        "# display(df_apnea_summary_table)\n",
        "\n",
        "# df_apnea_summary_table.to_html('apnea_summary_table.html')\n",
        "# nazivFajla='test.pdf'\n",
        "# config = pdf.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "# pdf.from_url('apnea_summary_table.html', nazivFajla, configuration=config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kb94aQAehXxh"
      },
      "id": "Kb94aQAehXxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startpath = \"/content/drive/MyDrive/Improve World Health/BEMPU Quality Management System Folder (Created by RN 211005)/3 - Product Specific Documents (TCF, etc)/BHPL-DHF – Design and Development/3)DHF-APNEBOOT_Rev 00/4. Design Verification _ Validation/DHF-01-28 - Design Validation Report/Product Validation/Clinical Validation/RCT ApneBoot/St. Johns Phase 1 Data/intervention/Sneha\"\n",
        "os.chdir(startpath)\n",
        "file_name = '12log5 - made from mona xls file.csv'\n",
        "file_name = 'Book2.csv'\n",
        "df = pd.read_csv(file_name, header=None)"
      ],
      "metadata": {
        "id": "Qmiv2ryWUynD"
      },
      "id": "Qmiv2ryWUynD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "3FuNu9FnVX5F"
      },
      "id": "3FuNu9FnVX5F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTpOGQud6Max",
        "7VpeZHhf7O2V",
        "T3dPG9_2xoX3",
        "c9pqOw4FnVYA",
        "Ff704C-MwEsw",
        "4C39qoDxEcnt",
        "vFvsiREGpJ-8",
        "1uadoNfrjZUt",
        "bHJA2jljjdc-",
        "eoiLSOJ3jfmj",
        "kPbeaF7WOonR",
        "Y7x2w8JT2a_D",
        "qINEVzl52lDl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}